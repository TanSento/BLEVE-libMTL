{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import timeit\n",
    "#import shap\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.010208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.012350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.014577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.016878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.019250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0  B1                         24.5          0.519805             2.2   \n",
       "1  B1                         24.5          0.519805             2.2   \n",
       "2  B1                         24.5          0.519805             2.2   \n",
       "3  B1                         24.5          0.519805             2.2   \n",
       "4  B1                         24.5          0.519805             2.2   \n",
       "\n",
       "   Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0              6.0              1.0                  1.6   \n",
       "1              6.0              1.0                  1.6   \n",
       "2              6.0              1.0                  1.6   \n",
       "3              6.0              1.0                  1.6   \n",
       "4              6.0              1.0                  1.6   \n",
       "\n",
       "   Tank Height with Gas (m)   Vapour Temerature (K)   Liquid Temerature (K)  \\\n",
       "0                       0.4                   307.8                   339.0   \n",
       "1                       0.4                   307.8                   339.0   \n",
       "2                       0.4                   307.8                   339.0   \n",
       "3                       0.4                   307.8                   339.0   \n",
       "4                       0.4                   307.8                   339.0   \n",
       "\n",
       "      Status  Stand-off Distance    Target  \n",
       "0  Subcooled                 5.0  0.010208  \n",
       "1  Subcooled                 6.0  0.012350  \n",
       "2  Subcooled                 7.0  0.014577  \n",
       "3  Subcooled                 8.0  0.016878  \n",
       "4  Subcooled                 9.0  0.019250  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"../data/arrival_time_COMPLETE.csv\")\n",
    "df2 = pd.read_csv(\"../data/negative_duration_COMPLETE.csv\")\n",
    "df3 = pd.read_csv(\"../data/negative_peak_time_COMPLETE.csv\")\n",
    "df4 = pd.read_csv(\"../data/negative_pressure_COMPLETE.csv\")\n",
    "df5 = pd.read_csv(\"../data/positive_duration_COMPLETE.csv\")\n",
    "df6 = pd.read_csv(\"../data/positive_impulse_COMPLETE.csv\")\n",
    "df7 = pd.read_csv(\"../data/positive_peak_time_COMPLETE.csv\")\n",
    "df8 = pd.read_csv(\"../data/positive_pressure_COMPLETE.csv\")\n",
    "\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.007302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.007816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.008817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0        B1                     24.50000          0.519805             2.2   \n",
       "1        B1                     24.50000          0.519805             2.2   \n",
       "2        B1                     24.50000          0.519805             2.2   \n",
       "3        B1                     24.50000          0.519805             2.2   \n",
       "4        B1                     24.50000          0.519805             2.2   \n",
       "...     ...                          ...               ...             ...   \n",
       "35995  P500                     11.40239          0.442321             1.4   \n",
       "35996  P500                     11.40239          0.442321             1.4   \n",
       "35997  P500                     11.40239          0.442321             1.4   \n",
       "35998  P500                     11.40239          0.442321             1.4   \n",
       "35999  P500                     11.40239          0.442321             1.4   \n",
       "\n",
       "       Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                  6.0              1.0                  1.6   \n",
       "1                  6.0              1.0                  1.6   \n",
       "2                  6.0              1.0                  1.6   \n",
       "3                  6.0              1.0                  1.6   \n",
       "4                  6.0              1.0                  1.6   \n",
       "...                ...              ...                  ...   \n",
       "35995              2.8              1.2                  1.4   \n",
       "35996              2.8              1.2                  1.4   \n",
       "35997              2.8              1.2                  1.4   \n",
       "35998              2.8              1.2                  1.4   \n",
       "35999              2.8              1.2                  1.4   \n",
       "\n",
       "       Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                           0.4                   307.8   \n",
       "1                           0.4                   307.8   \n",
       "2                           0.4                   307.8   \n",
       "3                           0.4                   307.8   \n",
       "4                           0.4                   307.8   \n",
       "...                         ...                     ...   \n",
       "35995                       0.8                   388.2   \n",
       "35996                       0.8                   388.2   \n",
       "35997                       0.8                   388.2   \n",
       "35998                       0.8                   388.2   \n",
       "35999                       0.8                   388.2   \n",
       "\n",
       "        Liquid Temerature (K)  Status  Stand-off Distance    Target  \n",
       "0                       339.0       0                 5.0  0.006817  \n",
       "1                       339.0       0                 6.0  0.007302  \n",
       "2                       339.0       0                 7.0  0.007816  \n",
       "3                       339.0       0                 8.0  0.008326  \n",
       "4                       339.0       0                 9.0  0.008817  \n",
       "...                       ...     ...                 ...       ...  \n",
       "35995                   366.7       1                36.0       NaN  \n",
       "35996                   366.7       1                37.0       NaN  \n",
       "35997                   366.7       1                38.0       NaN  \n",
       "35998                   366.7       1                39.0       NaN  \n",
       "35999                   366.7       1                40.0       NaN  \n",
       "\n",
       "[36000 rows x 13 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding 'Status' feature into 0 and 1 \n",
    "# 0 for Subcooled and 1 for Superheated\n",
    "# Doing Similarly for ID (Do we need dummy encoding ??)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "df5['Status'] = LE.fit_transform(df5['Status'])\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28798</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0                         24.50000          0.519805             2.2   \n",
       "1                         24.50000          0.519805             2.2   \n",
       "2                         24.50000          0.519805             2.2   \n",
       "3                         24.50000          0.519805             2.2   \n",
       "4                         24.50000          0.519805             2.2   \n",
       "...                            ...               ...             ...   \n",
       "28795                     33.17377          0.372041             1.0   \n",
       "28796                     33.17377          0.372041             1.0   \n",
       "28797                     33.17377          0.372041             1.0   \n",
       "28798                     33.17377          0.372041             1.0   \n",
       "28799                     33.17377          0.372041             1.0   \n",
       "\n",
       "       Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                  6.0              1.0                  1.6   \n",
       "1                  6.0              1.0                  1.6   \n",
       "2                  6.0              1.0                  1.6   \n",
       "3                  6.0              1.0                  1.6   \n",
       "4                  6.0              1.0                  1.6   \n",
       "...                ...              ...                  ...   \n",
       "28795              2.2              0.6                  0.2   \n",
       "28796              2.2              0.6                  0.2   \n",
       "28797              2.2              0.6                  0.2   \n",
       "28798              2.2              0.6                  0.2   \n",
       "28799              2.2              0.6                  0.2   \n",
       "\n",
       "       Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                           0.4                   307.8   \n",
       "1                           0.4                   307.8   \n",
       "2                           0.4                   307.8   \n",
       "3                           0.4                   307.8   \n",
       "4                           0.4                   307.8   \n",
       "...                         ...                     ...   \n",
       "28795                       0.4                   312.7   \n",
       "28796                       0.4                   312.7   \n",
       "28797                       0.4                   312.7   \n",
       "28798                       0.4                   312.7   \n",
       "28799                       0.4                   312.7   \n",
       "\n",
       "        Liquid Temerature (K)  Status  Stand-off Distance  \n",
       "0                       339.0       0                 5.0  \n",
       "1                       339.0       0                 6.0  \n",
       "2                       339.0       0                 7.0  \n",
       "3                       339.0       0                 8.0  \n",
       "4                       339.0       0                 9.0  \n",
       "...                       ...     ...                 ...  \n",
       "28795                   318.2       0                36.0  \n",
       "28796                   318.2       0                37.0  \n",
       "28797                   318.2       0                38.0  \n",
       "28798                   318.2       0                39.0  \n",
       "28799                   318.2       0                40.0  \n",
       "\n",
       "[28800 rows x 11 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df5.drop(['ID','Target'], axis=1)[:28800]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.006817\n",
       "1        0.007302\n",
       "2        0.007816\n",
       "3        0.008326\n",
       "4        0.008817\n",
       "           ...   \n",
       "28795    0.012178\n",
       "28796    0.012275\n",
       "28797    0.012374\n",
       "28798    0.012477\n",
       "28799    0.012573\n",
       "Name: Target, Length: 28800, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y5 = df5['Target'][:28800]\n",
    "y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df1['Target'][:28800]\n",
    "y2 = df2['Target'][:28800]\n",
    "y3 = df3['Target'][:28800]\n",
    "y4 = df4['Target'][:28800]\n",
    "y6 = df6['Target'][:28800]\n",
    "y7 = df7['Target'][:28800]\n",
    "y8 = df8['Target'][:28800]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 11)\n",
      "(7200, 11)\n"
     ]
    }
   ],
   "source": [
    "X_traindf, X_testdf, y1_train, y1_test = train_test_split(X, y1, test_size=0.25, random_state=42)\n",
    "print(X_traindf.shape)\n",
    "print(X_testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_train, y2_test = train_test_split(y2, test_size=0.25, random_state=42)\n",
    "y3_train, y3_test = train_test_split(y3, test_size=0.25, random_state=42)\n",
    "y4_train, y4_test = train_test_split(y4, test_size=0.25, random_state=42)\n",
    "y5_train, y5_test = train_test_split(y5, test_size=0.25, random_state=42)\n",
    "y6_train, y6_test = train_test_split(y6, test_size=0.25, random_state=42)\n",
    "y7_train, y7_test = train_test_split(y7, test_size=0.25, random_state=42)\n",
    "y8_train, y8_test = train_test_split(y8, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01284534, 0.01444022, 0.10035855, ..., 0.10251021, 0.07990494,\n",
       "       0.01143898])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y7_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1268162 , 0.62633157, 0.04595783, ..., 0.02130297, 0.13602383,\n",
       "       2.3361142 ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y8_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y1_train.values.reshape(-1,1), y2_train.values.reshape(-1,1), y3_train.values.reshape(-1,1), \n",
    "                          y4_train.values.reshape(-1,1), y5_train.values.reshape(-1,1), y6_train.values.reshape(-1,1),\n",
    "                          y7_train.values.reshape(-1,1), y8_train.values.reshape(-1,1)), axis=1)\n",
    "\n",
    "y_test = np.concatenate((y1_test.values.reshape(-1,1), y2_test.values.reshape(-1,1), y3_test.values.reshape(-1,1), \n",
    "                          y4_test.values.reshape(-1,1), y5_test.values.reshape(-1,1), y6_test.values.reshape(-1,1),\n",
    "                          y7_test.values.reshape(-1,1), y8_test.values.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 8)\n",
      "(7200, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.11694350e-02, 1.56393350e-02, 2.44314220e-02, ...,\n",
       "        2.86203890e+02, 1.28453400e-02, 1.12681620e+00],\n",
       "       [1.24119570e-02, 1.88029450e-02, 2.82499930e-02, ...,\n",
       "        1.80425900e+02, 1.44402250e-02, 6.26331570e-01],\n",
       "       [9.50448220e-02, 1.51018300e-02, 1.09446822e-01, ...,\n",
       "        1.49908640e+01, 1.00358550e-01, 4.59578340e-02],\n",
       "       ...,\n",
       "       [9.67233260e-02, 9.91223000e-03, 1.08929812e-01, ...,\n",
       "        7.44885020e+00, 1.02510210e-01, 2.13029660e-02],\n",
       "       [7.58939240e-02, 2.09730370e-02, 9.80206378e-02, ...,\n",
       "        6.19014550e+01, 7.99049360e-02, 1.36023830e-01],\n",
       "       [1.00712810e-02, 3.38855160e-02, 3.30022184e-02, ...,\n",
       "        7.96478820e+02, 1.14389770e-02, 2.33611420e+00]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.36676340e-02, 1.85481800e-02, 1.16362342e-01, ...,\n",
       "        3.87540700e+01, 9.85093640e-02, 8.02679810e-02],\n",
       "       [1.88341180e-02, 1.49853250e-02, 3.32267860e-02, ...,\n",
       "        1.10768800e+02, 2.12428740e-02, 3.99188070e-01],\n",
       "       [4.82065450e-02, 2.26087420e-02, 7.29268908e-02, ...,\n",
       "        9.14076770e+01, 5.16740420e-02, 1.84897880e-01],\n",
       "       ...,\n",
       "       [7.48656170e-02, 1.68266440e-02, 9.27517236e-02, ...,\n",
       "        3.51032030e+01, 7.93257060e-02, 9.26706940e-02],\n",
       "       [1.48923780e-02, 2.82288120e-02, 3.50396958e-02, ...,\n",
       "        3.61880250e+02, 1.65773410e-02, 1.17031230e+00],\n",
       "       [4.29282640e-02, 7.86490400e-03, 5.24556696e-02, ...,\n",
       "        1.25165350e+01, 4.73894250e-02, 4.77122370e-02]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and Power Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing both X_train and X_test using standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_traindf)\n",
    "X_test = scaler.transform(X_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if it succeeded\n",
    "# df_stdscal = pd.DataFrame(X_train)\n",
    "# df_stdscal.hist(figsize = (20,20), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = PowerTransformer()\n",
    "\n",
    "y_train_normal = power.fit_transform(y_train)\n",
    "y_test_normal = power.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.2307336 ,  0.24910146, -0.831784  ,  2.0508611 ,  1.9587778 ,\n",
       "       -0.85284084, -0.62470907, -0.40038356, -0.8631201 , -1.5778222 ,\n",
       "       -0.7038771 ,  0.84154063, -0.19823122,  0.15150616,  1.9936589 ,\n",
       "        0.01610001,  0.52095824, -0.8711013 ,  0.52445894, -0.40326974,\n",
       "       -0.31851378,  0.34941995,  1.7080039 ,  0.05973712, -0.53792906,\n",
       "       -0.9154755 ,  1.6244624 , -1.2966477 , -1.6152964 , -0.60622245,\n",
       "       -0.86146295,  1.4496433 ,  0.91446096,  0.5323532 ,  0.2408684 ,\n",
       "        2.0028303 ,  1.8498372 , -0.6878157 ,  0.27277493,  2.0596213 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_normal[1:41, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39918816, 0.1848979 , 0.07076788, 1.6035292 , 1.08061   ,\n",
       "       0.06908131, 0.08818352, 0.1089704 , 0.06826329, 0.01860523,\n",
       "       0.08134043, 0.28987968, 0.12975073, 0.17156982, 1.2115376 ,\n",
       "       0.15436816, 0.22705913, 0.06763053, 0.22765863, 0.10868871,\n",
       "       0.11713052, 0.19952142, 0.6662189 , 0.15975928, 0.0959686 ,\n",
       "       0.06414998, 0.5972092 , 0.03660977, 0.01633275, 0.08981633,\n",
       "       0.0683949 , 0.4912349 , 0.30692577, 0.22901654, 0.18374074,\n",
       "       1.2546518 , 0.837906  , 0.08270955, 0.1882602 , 1.7111793 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_check = power.inverse_transform(y_test_normal)\n",
    "y_test_check[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if it succeeded\n",
    "# df_stdscal = pd.DataFrame(y_train)\n",
    "# df_stdscal.hist(figsize = (20,20), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.backends.cudnn.version() , torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1781, -0.9747, -1.5140,  ..., -0.7230, -0.7424, -1.4851],\n",
      "        [-0.5207,  0.5219,  0.0684,  ..., -0.3853,  1.3470, -1.4851],\n",
      "        [ 1.3911,  1.5275, -0.7228,  ...,  1.1182, -0.7424,  1.3998],\n",
      "        ...,\n",
      "        [-1.6514,  0.5764, -1.2503,  ...,  0.7199,  1.3470,  1.3998],\n",
      "        [ 0.9835,  0.0136, -0.7228,  ..., -0.4908, -0.7424,  0.9190],\n",
      "        [ 1.3715,  0.0745,  0.3321,  ...,  0.5537,  1.3470, -1.4851]])\n"
     ]
    }
   ],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "X_train_torch = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_torch = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "\n",
    "\n",
    "y_train_torch = torch.from_numpy(y_train_normal.astype(np.float32))\n",
    "y_test_torch = torch.from_numpy(y_test_normal.astype(np.float32))\n",
    "\n",
    "\n",
    "print(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5635, -0.2529, -1.5952,  ...,  1.7208, -1.5793,  1.9725],\n",
       "        [-1.5141,  0.3007, -1.4643,  ...,  1.2496, -1.5188,  1.6621],\n",
       "        [ 1.4719, -0.3562,  1.2563,  ..., -1.2607,  1.4767, -1.1610],\n",
       "        ...,\n",
       "        [ 1.5271, -1.5180,  1.2393,  ..., -1.9253,  1.5457, -1.5339],\n",
       "        [ 0.8278,  0.6314,  0.8805,  ...,  0.1587,  0.8070, -0.1412],\n",
       "        [-1.6072,  1.9910, -1.3017,  ...,  2.7645, -1.6327,  2.0861]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4265,  0.2594,  1.4827,  ..., -0.3158,  1.4172, -0.7165],\n",
       "        [-1.2615, -0.3790, -1.2941,  ...,  0.7514, -1.2632,  1.2307],\n",
       "        [-0.1525,  0.8573,  0.0472,  ...,  0.5555, -0.1603,  0.2491],\n",
       "        ...,\n",
       "        [ 0.7925, -0.0344,  0.7064,  ..., -0.4155,  0.7877, -0.5743],\n",
       "        [-1.4161,  1.5036, -1.2322,  ...,  1.9603, -1.4382,  1.9839],\n",
       "        [-0.3464, -2.0699, -0.6408,  ..., -1.4356, -0.3117, -1.1363]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(X_train_torch)):\n",
    "   train_data.append([X_train_torch[i],\n",
    "                      y_train_torch[i] \n",
    "                     ])\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(X_test_torch)):\n",
    "   test_data.append([X_test_torch[i], \n",
    "                     y_test_torch[i]\n",
    "                     ])\n",
    "\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=512,               # batch_size could be smaller\n",
    "    num_workers=6)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=512,\n",
    "    num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5635, -0.2529, -1.5952,  ...,  1.7208, -1.5793,  1.9725],\n",
      "        [-1.5141,  0.3007, -1.4643,  ...,  1.2496, -1.5188,  1.6621],\n",
      "        [ 1.4719, -0.3562,  1.2563,  ..., -1.2607,  1.4767, -1.1610],\n",
      "        ...,\n",
      "        [ 1.0281, -0.1669,  1.0810,  ..., -0.7466,  1.0396, -1.0728],\n",
      "        [-1.0301,  0.9327, -0.8796,  ...,  1.3335, -1.0448,  1.4747],\n",
      "        [ 0.3898,  1.2137,  0.5566,  ...,  0.6684,  0.3636,  0.3594]])\n",
      "tensor([[-0.7113, -1.9940, -0.9887,  ..., -0.9161, -0.6854, -0.5824],\n",
      "        [-1.1060, -1.5817, -1.3096,  ..., -0.1370, -1.0971,  0.5569],\n",
      "        [ 1.4573, -0.1274,  1.5225,  ..., -0.8556,  1.4695, -1.2327],\n",
      "        ...,\n",
      "        [ 1.4257,  0.5992,  1.5349,  ..., -0.4649,  1.4292, -0.9813],\n",
      "        [ 1.7834, -0.6894,  1.5641,  ..., -2.1419,  1.8068, -1.6319],\n",
      "        [-0.2402,  0.8010, -0.1060,  ...,  0.8753, -0.2588,  0.7318]])\n",
      "tensor([[ 0.2848, -0.7753,  0.1801,  ..., -0.6132,  0.2967, -0.7336],\n",
      "        [-0.0029, -0.2827, -0.0884,  ..., -0.0484, -0.0044, -0.1006],\n",
      "        [-1.2915, -0.5788, -1.3531,  ...,  0.3988, -1.2827,  0.8415],\n",
      "        ...,\n",
      "        [-1.1328, -0.3514, -1.2029,  ...,  1.0721, -1.1492,  1.5860],\n",
      "        [ 0.1524,  0.2406,  0.2024,  ..., -0.0182,  0.1564, -0.3741],\n",
      "        [-1.6857,  0.3569, -1.6855,  ...,  1.7950, -1.7064,  2.0357]])\n",
      "tensor([[-0.4684,  1.7872, -0.1472,  ...,  1.3625, -0.4921,  1.1904],\n",
      "        [ 1.3839,  1.8909,  1.8495,  ...,  0.7928,  1.3462,  0.0533],\n",
      "        [-0.9058,  1.6803, -0.6347,  ...,  1.8347, -0.9356,  1.7876],\n",
      "        ...,\n",
      "        [ 1.2278,  1.0892,  1.3896,  ...,  0.1360,  1.2062, -0.3499],\n",
      "        [-1.5323,  0.6023, -1.4700,  ...,  1.2910, -1.5403,  1.7662],\n",
      "        [-1.0300, -1.0642, -1.1418,  ..., -0.1322, -1.0130,  0.1558]])\n",
      "tensor([[-0.2616,  0.0567, -0.2762,  ...,  0.3634, -0.2706,  0.3618],\n",
      "        [-1.6073, -1.6128, -1.7937,  ..., -0.2187, -1.5886,  0.5686],\n",
      "        [ 1.5546, -1.6928,  1.2655,  ..., -2.3513,  1.5791, -1.6836],\n",
      "        ...,\n",
      "        [ 0.1783, -0.1791,  0.1212,  ..., -0.5953,  0.1895, -0.7136],\n",
      "        [-1.2662, -0.6295, -1.4219,  ..., -0.8268, -1.2312, -0.4123],\n",
      "        [-1.6606, -1.0545, -1.7795,  ...,  0.9482, -1.6651,  1.7174]])\n",
      "tensor([[-1.3795, -1.3165, -1.4806,  ..., -0.4216, -1.3535,  0.1189],\n",
      "        [ 0.3765, -0.1780,  0.3619,  ..., -0.3284,  0.3801, -0.5673],\n",
      "        [ 0.1113, -0.8964, -0.1231,  ..., -1.2279,  0.1383, -1.0910],\n",
      "        ...,\n",
      "        [ 1.3259,  1.0605,  1.4600,  ..., -0.0302,  1.3096, -0.5201],\n",
      "        [ 1.2701,  0.7341,  1.3971,  ..., -0.1528,  1.2598, -0.6632],\n",
      "        [-1.3092,  1.3904, -1.1325,  ...,  2.0080, -1.3359,  1.9870]])\n",
      "tensor([[ 1.4353, -0.2615,  1.3490,  ..., -0.6258,  1.4283, -0.8364],\n",
      "        [-1.5293, -1.1294, -1.6666,  ...,  0.6465, -1.5312,  1.4839],\n",
      "        [ 0.6143, -0.7177,  0.4934,  ..., -0.7704,  0.6239, -0.8753],\n",
      "        ...,\n",
      "        [-0.4884,  0.7127, -0.3599,  ...,  0.3701, -0.4878,  0.2803],\n",
      "        [ 0.8246, -0.3723,  0.8617,  ..., -0.6942,  0.8360, -0.9876],\n",
      "        [ 1.7861, -0.4750,  1.7256,  ..., -1.0649,  1.7927, -1.2379]])\n",
      "tensor([[ 1.8673, -0.7216,  1.6511,  ..., -1.8177,  1.8868, -1.5154],\n",
      "        [ 0.2672,  0.0744,  0.2837,  ..., -0.1376,  0.2701, -0.4399],\n",
      "        [ 0.2248, -1.0505,  0.1109,  ..., -0.7309,  0.2365, -0.6808],\n",
      "        ...,\n",
      "        [ 1.4681,  1.0591,  1.6193,  ...,  0.2063,  1.4397, -0.2859],\n",
      "        [ 1.3805, -1.2534,  1.1006,  ..., -1.5586,  1.3949, -1.3415],\n",
      "        [-1.6816, -0.0091, -1.6890,  ...,  2.0551, -1.7032,  2.0597]])\n",
      "tensor([[ 1.5698, -0.5538,  1.4752,  ..., -0.9523,  1.5711, -1.0751],\n",
      "        [-0.2063,  0.5738, -0.0951,  ...,  0.1679, -0.2036, -0.0691],\n",
      "        [ 1.0033,  0.8147,  1.0991,  ...,  0.1678,  0.9825, -0.2414],\n",
      "        ...,\n",
      "        [-1.4538,  0.6551, -1.3739,  ...,  1.4566, -1.4656,  1.7992],\n",
      "        [-0.6570, -0.0627, -0.6769,  ...,  0.5711, -0.6654,  0.7527],\n",
      "        [-0.0781,  1.4118,  0.1948,  ...,  0.8055, -0.0914,  0.3911]])\n",
      "tensor([[ 0.3460,  1.3431,  0.5873,  ...,  0.7169,  0.3253,  0.2805],\n",
      "        [ 0.0832,  0.4013,  0.1069,  ...,  0.2502,  0.0724,  0.1031],\n",
      "        [ 0.4160,  0.7929,  0.5372,  ...,  0.2513,  0.4055, -0.1239],\n",
      "        ...,\n",
      "        [ 1.7812, -0.4043,  1.5828,  ..., -1.7936,  1.8019, -1.5290],\n",
      "        [-1.2906, -1.7410, -1.4834,  ...,  0.0414, -1.2808,  0.8160],\n",
      "        [-0.4780,  0.9587, -0.3445,  ...,  0.7738, -0.4890,  0.7147]])\n",
      "tensor([[ 1.0125, -0.8951,  0.7648,  ..., -1.6621,  1.0367, -1.4173],\n",
      "        [-0.2627,  1.3595, -0.0210,  ...,  0.9171, -0.2796,  0.7059],\n",
      "        [-1.6267, -0.8851, -1.7289,  ...,  0.7778, -1.6275,  1.5623],\n",
      "        ...,\n",
      "        [-1.5495,  0.5094, -1.4957,  ...,  1.5804, -1.5620,  1.8928],\n",
      "        [-0.1454, -0.3799, -0.2436,  ..., -0.1758, -0.1437, -0.1477],\n",
      "        [ 0.2194, -0.2402,  0.2892,  ..., -0.4946,  0.2376, -0.8664]])\n",
      "tensor([[-0.4585, -0.0328, -0.5210,  ...,  0.1303, -0.4602,  0.2776],\n",
      "        [-0.9848, -0.5379, -1.0610,  ...,  0.1904, -0.9764,  0.4714],\n",
      "        [-0.4900, -0.4356, -0.5635,  ...,  0.2016, -0.4880,  0.2829],\n",
      "        ...,\n",
      "        [ 0.7434, -0.5593,  0.7510,  ..., -0.7334,  0.7562, -1.0058],\n",
      "        [ 1.3683,  2.1870,  1.8947,  ...,  0.7564,  1.3353, -0.0455],\n",
      "        [ 1.1454,  0.2285,  1.2580,  ..., -0.5336,  1.1524, -1.0211]])\n",
      "tensor([[-1.4216, -0.8966, -1.5103,  ...,  1.0154, -1.4254,  1.5984],\n",
      "        [-1.1717, -0.1533, -1.1763,  ...,  0.6762, -1.1718,  1.0673],\n",
      "        [ 1.4389, -1.0368,  1.1933,  ..., -2.3159,  1.4658, -1.6798],\n",
      "        ...,\n",
      "        [ 0.2402, -0.0046,  0.1996,  ...,  0.1334,  0.2270,  0.0266],\n",
      "        [ 1.4326,  1.6556,  1.7381,  ...,  0.4238,  1.4044, -0.2313],\n",
      "        [-0.0451, -0.6833, -0.2538,  ..., -0.9831, -0.0165, -0.9459]])\n",
      "tensor([[-0.4103,  0.5602, -0.3459,  ...,  0.6846, -0.4230,  0.6742],\n",
      "        [ 0.3933,  1.1092,  0.5461,  ...,  0.3444,  0.3812, -0.0551],\n",
      "        [-0.8890, -1.2115, -1.0206,  ..., -0.1381, -0.8741,  0.2137],\n",
      "        ...,\n",
      "        [ 1.2907,  1.4345,  1.5929,  ...,  0.2998,  1.2737, -0.4427],\n",
      "        [ 1.1859,  0.6653,  1.2584,  ...,  0.0150,  1.1657, -0.3790],\n",
      "        [ 0.9552,  0.2562,  0.9797,  ..., -0.2299,  0.9474, -0.5716]])\n",
      "tensor([[ 0.4937,  1.6399,  0.7716,  ...,  0.7165,  0.4713,  0.2062],\n",
      "        [-1.4584,  1.0908, -1.3172,  ...,  1.8914, -1.4777,  1.9670],\n",
      "        [-0.8186, -0.7258, -0.9108,  ...,  0.2143, -0.8129,  0.5103],\n",
      "        ...,\n",
      "        [ 1.1418,  0.0683,  1.1771,  ..., -0.3773,  1.1389, -0.7879],\n",
      "        [-1.2447,  0.4911, -1.1760,  ...,  1.1767, -1.2524,  1.4873],\n",
      "        [-1.4068, -1.7698, -1.5718,  ...,  0.6151, -1.4037,  1.3450]])\n",
      "tensor([[ 0.0194, -0.6200, -0.1932,  ..., -0.9174,  0.0399, -0.8626],\n",
      "        [-0.8301,  0.2492, -0.8067,  ...,  0.5843, -0.8323,  0.7557],\n",
      "        [-0.1279, -0.6383, -0.3375,  ..., -1.4881, -0.0907, -1.2689],\n",
      "        ...,\n",
      "        [-0.7409, -0.5004, -0.8149,  ...,  0.5027, -0.7479,  0.8179],\n",
      "        [ 0.2378,  0.6353,  0.3643,  ...,  0.1390,  0.2366, -0.2781],\n",
      "        [ 1.2610,  2.2622,  1.6887,  ...,  0.8611,  1.2207,  0.2066]])\n",
      "tensor([[-1.4222, -2.2473, -1.6733,  ..., -0.2540, -1.4053,  0.5192],\n",
      "        [-0.8921,  0.2864, -0.7864,  ...,  0.2518, -0.8784,  0.1890],\n",
      "        [-0.1329, -0.5999, -0.2354,  ..., -0.1803, -0.1313, -0.1197],\n",
      "        ...,\n",
      "        [ 1.2240,  0.1580,  1.2175,  ..., -0.4919,  1.2216, -0.8177],\n",
      "        [-0.9916,  0.1391, -0.9821,  ...,  0.9903, -1.0019,  1.2914],\n",
      "        [ 0.7491,  0.7789,  0.9551,  ...,  0.1995,  0.7404, -0.3771]])\n",
      "tensor([[-1.6983,  1.2023, -1.5607,  ...,  2.4345, -1.7195,  2.0795],\n",
      "        [-0.9465,  0.7893, -0.7719,  ...,  0.8553, -0.9482,  0.8994],\n",
      "        [ 1.7362, -1.7572,  1.4393,  ..., -1.8710,  1.7518, -1.5131],\n",
      "        ...,\n",
      "        [-1.2443, -0.3109, -1.2481,  ...,  0.2705, -1.2321,  0.6451],\n",
      "        [-0.0518, -1.3811, -0.2194,  ..., -0.7136, -0.0419, -0.5276],\n",
      "        [-0.7766, -0.5189, -0.9542,  ..., -1.1344, -0.7399, -0.8720]])\n",
      "tensor([[-1.5920, -1.4781, -1.7396,  ...,  1.1543, -1.6008,  1.8556],\n",
      "        [-0.6471, -0.8713, -0.7709,  ...,  0.0414, -0.6457,  0.3373],\n",
      "        [-0.0487,  0.7870,  0.0341,  ...,  0.6750, -0.0696,  0.5765],\n",
      "        ...,\n",
      "        [ 1.0625,  0.9047,  1.2316,  ...,  0.0090,  1.0526, -0.5560],\n",
      "        [-1.3628, -0.4006, -1.3975,  ...,  0.7079, -1.3623,  1.2432],\n",
      "        [-0.2092, -1.8367, -0.5049,  ..., -0.9847, -0.1880, -0.7259]])\n",
      "tensor([[-1.6081, -0.0369, -1.6389,  ...,  0.8922, -1.6107,  1.6000],\n",
      "        [ 0.8803, -0.1400,  0.8013,  ..., -0.5381,  0.8811, -0.7650],\n",
      "        [ 0.4272, -0.1162,  0.4135,  ..., -0.2173,  0.4284, -0.4661],\n",
      "        ...,\n",
      "        [-0.2990, -0.5835, -0.2863,  ..., -0.7563, -0.2691, -0.9064],\n",
      "        [-0.4245, -0.6733, -0.5370,  ..., -0.2870, -0.4152, -0.1627],\n",
      "        [ 0.4360, -1.0294,  0.2917,  ..., -0.9014,  0.4497, -0.9212]])\n",
      "tensor([[-1.5268, -1.0608, -1.6683,  ...,  1.1927, -1.5412,  1.8851],\n",
      "        [ 0.9129, -0.4148,  0.6894,  ..., -0.9973,  0.9143, -0.8834],\n",
      "        [-0.3116, -0.8241, -0.2987,  ..., -0.8723, -0.2796, -1.0023],\n",
      "        ...,\n",
      "        [ 0.7712, -0.3348,  0.6716,  ..., -0.5870,  0.7726, -0.7622],\n",
      "        [-1.4892, -0.5960, -1.6374,  ..., -0.5301, -1.4635,  0.1436],\n",
      "        [-1.0627,  0.1231, -1.0268,  ...,  0.7644, -1.0662,  1.0825]])\n",
      "tensor([[-0.0255, -0.1226,  0.0495,  ..., -0.6318,  0.0025, -0.9856],\n",
      "        [ 1.1658,  0.4029,  1.1974,  ..., -0.3380,  1.1570, -0.6604],\n",
      "        [ 1.3745,  0.2382,  1.3456,  ..., -0.5257,  1.3707, -0.8355],\n",
      "        ...,\n",
      "        [-1.6060, -0.5593, -1.6580,  ...,  1.1875, -1.6095,  1.7081],\n",
      "        [-1.2172, -1.4488, -1.3829,  ...,  0.3226, -1.2157,  1.0617],\n",
      "        [ 1.2662,  1.2959,  1.5189,  ...,  0.3727,  1.2378, -0.1674]])\n",
      "tensor([[ 0.1906,  1.1641,  0.3588,  ...,  0.5712,  0.1729,  0.2593],\n",
      "        [-0.9731,  2.5223, -0.4275,  ...,  2.3011, -1.0051,  1.9169],\n",
      "        [ 1.8005,  0.2024,  1.6444,  ..., -1.5645,  1.8156, -1.4448],\n",
      "        ...,\n",
      "        [-0.9194, -0.4066, -0.9546,  ..., -0.0320, -0.9070,  0.1968],\n",
      "        [-0.9497, -0.3547, -0.9288,  ...,  0.1244, -0.9381,  0.3055],\n",
      "        [-1.0438,  1.5347, -0.7599,  ...,  1.4440, -1.0564,  1.4499]])\n",
      "tensor([[ 0.0394, -1.4609, -0.2357,  ..., -2.6652,  0.0763, -1.7247],\n",
      "        [-0.6914, -0.2445, -0.6668,  ...,  0.0368, -0.6759, -0.0640],\n",
      "        [ 0.3625, -0.5363,  0.1404,  ..., -1.8982,  0.3965, -1.4898],\n",
      "        ...,\n",
      "        [-0.1624,  0.7665, -0.0647,  ...,  0.8149, -0.1838,  0.7263],\n",
      "        [-0.9069, -0.0311, -0.9072,  ...,  0.7586, -0.9136,  1.0131],\n",
      "        [-0.9398,  1.4190, -0.7203,  ...,  1.5539, -0.9620,  1.6204]])\n",
      "tensor([[ 1.3803, -0.4975,  1.1480,  ..., -1.2540,  1.3848, -1.1326],\n",
      "        [-0.7219,  0.7232, -0.6021,  ...,  0.8033, -0.7279,  0.8039],\n",
      "        [-1.0470, -0.7826, -1.1032,  ...,  0.0458, -1.0344,  0.3497],\n",
      "        ...,\n",
      "        [ 1.3407,  0.0049,  1.2780,  ..., -0.5769,  1.3540, -0.8147],\n",
      "        [-1.4128, -0.6077, -1.4469,  ..., -0.3894, -1.3848, -0.0421],\n",
      "        [-0.6446,  0.7931, -0.4824,  ...,  0.7235, -0.6503,  0.6963]])\n",
      "tensor([[-0.6170,  0.8001, -0.4764,  ...,  1.0313, -0.6308,  1.0072],\n",
      "        [ 0.8083,  0.3225,  0.6408,  ..., -1.0026,  0.8183, -0.9932],\n",
      "        [-1.6035,  1.3420, -1.4583,  ...,  2.5429, -1.6343,  2.0908],\n",
      "        ...,\n",
      "        [ 0.1424, -0.2257,  0.0549,  ..., -0.3102,  0.1458, -0.4239],\n",
      "        [-1.1121, -0.8347, -1.2084,  ...,  0.3537, -1.1073,  0.7919],\n",
      "        [ 1.6741,  0.4706,  1.7506,  ..., -0.2566,  1.6587, -0.6936]])\n",
      "tensor([[-0.8596,  0.3521, -0.7857,  ...,  0.6196, -0.8572,  0.6470],\n",
      "        [-1.1244, -1.0329, -1.1995,  ..., -0.5258, -1.0966, -0.2554],\n",
      "        [ 0.6402,  1.9187,  1.0777,  ...,  1.0349,  0.6068,  0.4255],\n",
      "        ...,\n",
      "        [ 0.9446, -0.9188,  0.8114,  ..., -1.0092,  0.9563, -1.0757],\n",
      "        [ 1.0820,  0.2241,  1.0359,  ..., -0.2859,  1.0684, -0.5347],\n",
      "        [-1.3985,  0.1055, -1.4027,  ...,  1.0770, -1.4063,  1.5995]])\n",
      "tensor([[-1.2991,  2.2206, -0.9227,  ...,  2.2617, -1.3278,  2.0139],\n",
      "        [ 1.4940, -0.2312,  1.3070,  ..., -1.4630,  1.5132, -1.4084],\n",
      "        [-0.5010,  0.4375, -0.4062,  ...,  0.6174, -0.5082,  0.5854],\n",
      "        ...,\n",
      "        [-1.3325, -1.0842, -1.4239,  ...,  0.3080, -1.3204,  0.8214],\n",
      "        [ 0.9881,  0.5945,  1.0396,  ...,  0.1901,  0.9623, -0.1221],\n",
      "        [-0.0088,  1.6960,  0.2852,  ...,  1.0586, -0.0362,  0.7848]])\n",
      "tensor([[ 1.3459,  1.5009,  1.6168,  ...,  0.5222,  1.3110, -0.0363],\n",
      "        [-0.4694, -0.6065, -0.4431,  ..., -0.3581, -0.4489, -0.4911],\n",
      "        [ 0.4824, -1.4440,  0.1835,  ..., -1.1897,  0.4956, -0.9945],\n",
      "        ...,\n",
      "        [ 0.0952,  0.6843,  0.2257,  ...,  0.2734,  0.0910, -0.0883],\n",
      "        [-1.2178,  0.0752, -1.2115,  ...,  1.0834, -1.2278,  1.4929],\n",
      "        [ 1.6544, -0.3569,  1.4429,  ..., -1.3154,  1.6589, -1.2046]])\n",
      "tensor([[-0.5162,  1.8545, -0.1603,  ...,  1.4480, -0.5401,  1.2413],\n",
      "        [ 0.6965,  0.1601,  0.7413,  ..., -0.4606,  0.7003, -0.7708],\n",
      "        [ 1.7393, -1.4549,  1.4555,  ..., -1.7088,  1.7517, -1.4345],\n",
      "        ...,\n",
      "        [ 0.6007, -0.2833,  0.6120,  ..., -0.5758,  0.6116, -0.8942],\n",
      "        [ 1.4112, -0.4542,  1.1759,  ..., -1.1162,  1.4084, -1.0042],\n",
      "        [-1.6131,  0.6404, -1.5612,  ...,  1.7322, -1.6303,  1.9867]])\n",
      "tensor([[-1.3714,  1.0559, -1.2396,  ...,  1.8475, -1.3927,  1.9456],\n",
      "        [-0.1120, -1.3533, -0.2617,  ..., -0.8812, -0.0892, -0.8375],\n",
      "        [ 0.1684, -1.5542, -0.1134,  ..., -1.5813,  0.2007, -1.2984],\n",
      "        ...,\n",
      "        [ 0.9383,  1.0276,  1.0729,  ...,  0.1573,  0.9191, -0.2520],\n",
      "        [ 0.3579,  1.4224,  0.6021,  ...,  0.6500,  0.3354,  0.2714],\n",
      "        [ 1.1677,  1.3052,  1.4223,  ...,  0.5719,  1.1332,  0.0596]])\n",
      "tensor([[-1.2682,  2.1503, -0.8563,  ...,  2.1058, -1.2903,  1.9124],\n",
      "        [-1.2425,  0.0753, -1.1829,  ..., -0.1210, -1.2180,  0.0693],\n",
      "        [-0.1600, -0.6072, -0.2805,  ...,  0.0301, -0.1695,  0.2171],\n",
      "        ...,\n",
      "        [ 1.3607,  0.8810,  1.5417,  ...,  0.1611,  1.3397, -0.4213],\n",
      "        [-1.6279,  0.2915, -1.5727,  ...,  1.0292, -1.6218,  1.5350],\n",
      "        [-1.0076, -2.1767, -1.2696,  ..., -2.3112, -0.9624, -1.5665]])\n",
      "tensor([[ 1.0965, -1.0701,  0.8344,  ..., -2.5072,  1.1246, -1.7150],\n",
      "        [-0.6549, -0.6793, -0.7246,  ..., -0.4122, -0.6319, -0.4275],\n",
      "        [ 0.1182,  0.8786,  0.3210,  ...,  0.2880,  0.1165, -0.1952],\n",
      "        ...,\n",
      "        [ 0.4950,  1.4210,  0.7575,  ...,  0.5645,  0.4773,  0.0465],\n",
      "        [-0.3990, -1.4544, -0.5369,  ..., -0.9246, -0.3689, -0.8567],\n",
      "        [ 1.1189,  0.3231,  1.2080,  ..., -0.1416,  1.1111, -0.6381]])\n",
      "tensor([[ 0.7480, -0.2658,  0.6708,  ..., -0.6149,  0.7541, -0.8495],\n",
      "        [-0.0778, -1.1084, -0.2365,  ..., -0.3123, -0.0810, -0.0942],\n",
      "        [-0.4229, -0.2504, -0.4084,  ...,  0.0886, -0.4152, -0.0555],\n",
      "        ...,\n",
      "        [-0.7655, -0.6254, -0.9472,  ..., -0.9080, -0.7315, -0.7322],\n",
      "        [ 0.2812,  1.1881,  0.4581,  ...,  0.7159,  0.2566,  0.4082],\n",
      "        [-1.0708,  1.6123, -0.7880,  ...,  1.6837, -1.0912,  1.7012]])\n",
      "tensor([[ 1.0845,  0.2208,  1.0252,  ..., -0.5459,  1.0781, -0.7210],\n",
      "        [ 1.4237,  1.4074,  1.7047,  ...,  0.3328,  1.3971, -0.3020],\n",
      "        [-0.7393, -0.9947, -0.9409,  ..., -0.9535, -0.7088, -0.6779],\n",
      "        ...,\n",
      "        [-1.4138,  1.6643, -1.1916,  ...,  2.1317, -1.4378,  2.0194],\n",
      "        [ 0.8079, -0.1264,  0.7360,  ..., -0.2379,  0.7973, -0.4621],\n",
      "        [-1.7057, -1.3177, -1.8605,  ...,  1.2793, -1.7219,  1.9614]])\n",
      "tensor([[-1.0822,  0.5340, -0.9888,  ...,  1.2334, -1.0935,  1.4422],\n",
      "        [ 0.3555, -0.0259,  0.3047,  ..., -0.5237,  0.3658, -0.7372],\n",
      "        [-0.0164, -1.0200, -0.2615,  ..., -1.1914,  0.0086, -0.9932],\n",
      "        ...,\n",
      "        [ 0.0751, -0.9029, -0.1617,  ..., -0.9722,  0.0903, -0.7818],\n",
      "        [-0.3787,  0.6775, -0.2324,  ...,  0.5363, -0.3807,  0.2902],\n",
      "        [-1.3418,  1.4754, -1.1118,  ...,  1.9249, -1.3612,  1.9084]])\n",
      "tensor([[-1.4004, -0.4723, -1.4781,  ...,  1.4883, -1.4226,  1.9302],\n",
      "        [ 0.5779,  0.7389,  0.6604,  ...,  0.3677,  0.5560,  0.0603],\n",
      "        [ 0.2886, -0.9466,  0.0371,  ..., -1.0798,  0.3049, -0.9087],\n",
      "        ...,\n",
      "        [ 1.4656, -2.2514,  1.1375,  ..., -2.2162,  1.4872, -1.6319],\n",
      "        [-0.8331, -1.5234, -1.0057,  ...,  0.0540, -0.8304,  0.5681],\n",
      "        [ 1.3447, -0.3796,  1.3934,  ..., -0.6955,  1.3481, -1.0405]])\n",
      "tensor([[ 1.6090, -1.2197,  1.3350,  ..., -1.6587,  1.6212, -1.4054],\n",
      "        [ 1.0137, -0.2690,  0.9176,  ..., -0.6542,  1.0115, -0.7930],\n",
      "        [ 0.1985,  0.8587,  0.3932,  ...,  0.3223,  0.1960, -0.1889],\n",
      "        ...,\n",
      "        [ 0.4425, -1.8534,  0.1285,  ..., -1.4380,  0.4640, -1.2000],\n",
      "        [ 0.5807, -0.9513,  0.3122,  ..., -1.0968,  0.5903, -0.9305],\n",
      "        [ 0.7641, -0.2654,  0.6684,  ..., -0.5095,  0.7636, -0.7064]])\n",
      "tensor([[ 0.7296, -2.3364,  0.3935,  ..., -2.0227,  0.7568, -1.5428],\n",
      "        [ 1.5648,  0.6794,  1.6620,  ..., -0.4219,  1.5627, -0.9097],\n",
      "        [-0.6769,  2.2023, -0.2340,  ...,  1.4988, -0.6958,  1.2648],\n",
      "        ...,\n",
      "        [-0.9052,  1.2142, -0.7426,  ...,  1.3988, -0.9259,  1.5331],\n",
      "        [ 1.0187, -0.1952,  0.9280,  ..., -0.6937,  1.0213, -0.8984],\n",
      "        [-1.3363, -1.3541, -1.4788,  ...,  0.2485, -1.3296,  0.9477]])\n",
      "tensor([[ 0.6887,  0.5188,  0.7429,  ..., -0.1121,  0.6844, -0.5008],\n",
      "        [-1.4544,  0.5341, -1.3858,  ...,  1.2901, -1.4615,  1.6822],\n",
      "        [-1.5634,  0.6875, -1.4968,  ...,  1.2761, -1.5735,  1.7910],\n",
      "        ...,\n",
      "        [-1.2459, -0.3445, -1.3096,  ...,  1.1341, -1.2607,  1.6552],\n",
      "        [-1.4684, -1.7784, -1.6834,  ..., -0.9187, -1.4337, -0.4089],\n",
      "        [-1.7008,  0.1085, -1.7102,  ...,  1.9384, -1.7171,  2.0422]])\n",
      "tensor([[-1.4378, -1.3771, -1.5941,  ...,  0.6174, -1.4400,  1.4438],\n",
      "        [-1.5410,  1.5597, -1.2812,  ...,  1.8854, -1.5525,  1.9183],\n",
      "        [ 0.9246,  1.8526,  1.2526,  ...,  0.7777,  0.8910,  0.2173],\n",
      "        ...,\n",
      "        [-0.6033, -0.3700, -0.6570,  ...,  0.0962, -0.5989,  0.2908],\n",
      "        [ 1.6843, -0.0761,  1.6268,  ..., -0.7354,  1.6820, -1.0161],\n",
      "        [-1.1231, -1.6046, -1.2915,  ...,  0.3113, -1.1199,  0.9509]])\n",
      "tensor([[ 0.9073,  1.4696,  1.2157,  ...,  0.6619,  0.8791,  0.0673],\n",
      "        [-0.7296, -0.4700, -0.7621,  ...,  0.0423, -0.7203,  0.1551],\n",
      "        [-0.5339,  1.4377, -0.2050,  ...,  1.0403, -0.5438,  0.7758],\n",
      "        ...,\n",
      "        [-1.2557,  2.0204, -0.8890,  ...,  2.4951, -1.2799,  1.9258],\n",
      "        [ 1.5916, -0.1382,  1.5376,  ..., -0.7598,  1.5910, -1.0297],\n",
      "        [-0.1756, -1.9444, -0.4837,  ..., -0.8678, -0.1607, -0.5820]])\n",
      "tensor([[ 6.1688e-01, -7.5865e-01,  3.5937e-01,  8.8971e-01, -1.2173e+00,\n",
      "         -9.1412e-01,  6.1864e-01, -7.4044e-01],\n",
      "        [ 6.9197e-01, -3.2252e-02,  6.1058e-01,  6.2620e-01,  3.1477e-02,\n",
      "         -2.8879e-01,  6.8119e-01, -4.0311e-01],\n",
      "        [-4.4035e-01, -1.0466e+00, -5.7491e-01,  1.0910e-01, -5.4577e-01,\n",
      "         -3.2010e-01, -4.2990e-01, -2.0403e-01],\n",
      "        [-4.1174e-03,  2.5394e-01,  4.9290e-02, -3.2554e-01,  6.2802e-01,\n",
      "          1.5658e-01, -8.3549e-03, -4.8081e-02],\n",
      "        [ 4.1330e-01,  1.4157e+00,  6.8839e-01, -1.2827e-01,  1.6161e+00,\n",
      "          6.5510e-01,  3.9141e-01,  2.0501e-01],\n",
      "        [ 1.2488e+00,  1.4121e+00,  1.4626e+00,  3.3474e-01,  1.4340e+00,\n",
      "          3.5494e-01,  1.2203e+00, -1.6718e-01],\n",
      "        [ 1.4426e+00, -1.2371e+00,  1.1789e+00,  1.9058e+00, -7.9020e-01,\n",
      "         -2.2182e+00,  1.4684e+00, -1.6468e+00],\n",
      "        [-9.6975e-01,  8.3641e-01, -8.4897e-01, -1.2472e+00, -3.1516e-02,\n",
      "          1.2140e+00, -9.8340e-01,  1.3900e+00],\n",
      "        [ 1.2391e+00,  1.1332e+00,  1.4083e+00,  8.3392e-02,  1.3471e+00,\n",
      "          4.0406e-01,  1.2073e+00, -7.2006e-02],\n",
      "        [ 1.1699e+00,  1.2999e+00,  1.4275e+00,  4.9133e-01,  1.8207e+00,\n",
      "          3.5146e-01,  1.1491e+00, -3.0163e-01],\n",
      "        [ 6.4267e-01,  2.2534e-01,  6.3890e-01,  8.5582e-02,  5.0589e-01,\n",
      "          2.1356e-02,  6.2823e-01, -2.1293e-01],\n",
      "        [-1.1458e+00,  2.8424e-01, -1.1033e+00, -1.1996e+00, -4.6408e-01,\n",
      "          8.3492e-01, -1.1492e+00,  1.1750e+00],\n",
      "        [ 7.5557e-01,  7.1931e-02,  7.6138e-01,  4.4160e-01,  7.2233e-01,\n",
      "         -2.8159e-01,  7.5145e-01, -5.8592e-01],\n",
      "        [-6.3737e-01,  1.5569e+00, -3.4999e-01, -9.8778e-01,  9.3101e-01,\n",
      "          1.3411e+00, -6.5652e-01,  1.2208e+00],\n",
      "        [ 1.5910e-02,  8.0709e-02,  1.1375e-01,  1.8829e-01,  1.0909e+00,\n",
      "         -1.5725e-01,  2.3436e-02, -4.3777e-01],\n",
      "        [ 1.4732e+00,  1.6890e+00,  1.7964e+00,  6.2872e-01,  1.9567e+00,\n",
      "          4.5983e-01,  1.4461e+00, -2.7131e-01],\n",
      "        [ 2.8652e-01, -1.0018e+00,  2.3708e-02,  1.0132e+00, -1.2977e+00,\n",
      "         -1.0978e+00,  3.0132e-01, -9.0843e-01],\n",
      "        [-1.5084e+00, -1.4890e+00, -1.6447e+00, -8.4055e-01, -1.5039e+00,\n",
      "          9.5978e-02, -1.4942e+00,  8.1142e-01],\n",
      "        [ 1.5521e+00,  8.8634e-01,  1.6732e+00,  8.5645e-01,  1.2151e+00,\n",
      "         -1.3010e-01,  1.5361e+00, -6.1702e-01],\n",
      "        [-4.3990e-02,  1.2911e+00,  1.7181e-01, -5.7902e-01,  1.0681e+00,\n",
      "          1.0356e+00, -7.1019e-02,  8.2166e-01],\n",
      "        [ 1.4254e+00, -4.5745e-01,  1.3290e+00,  1.0471e+00,  3.2656e-01,\n",
      "         -7.6293e-01,  1.4201e+00, -8.9820e-01],\n",
      "        [ 1.2492e-01, -2.2195e-01,  1.7592e-01,  1.8720e-01,  9.6691e-01,\n",
      "         -4.3196e-01,  1.3745e-01, -6.7770e-01],\n",
      "        [-1.4304e+00, -1.9886e+00, -1.6662e+00, -2.9607e-01, -2.1894e+00,\n",
      "         -4.0398e-01, -1.4105e+00,  3.0090e-01],\n",
      "        [ 5.9633e-01,  4.7789e-01,  6.6951e-01,  2.7140e-01,  9.3415e-01,\n",
      "         -1.2182e-01,  5.9516e-01, -5.4220e-01],\n",
      "        [ 4.9272e-01,  1.2437e+00,  7.3051e-01, -8.0847e-02,  1.5361e+00,\n",
      "          5.3051e-01,  4.7481e-01,  3.0988e-02],\n",
      "        [ 7.1374e-02,  5.0873e-01,  1.1207e-01, -3.8160e-01,  3.9238e-01,\n",
      "          4.6277e-01,  5.4561e-02,  3.3721e-01],\n",
      "        [ 7.4321e-01,  1.2208e+00,  9.4576e-01,  1.1956e-01,  1.3964e+00,\n",
      "          3.7112e-01,  7.2296e-01, -9.2487e-02],\n",
      "        [-5.8633e-01, -9.5479e-01, -7.1480e-01, -2.1157e-01, -6.6991e-01,\n",
      "         -3.7012e-02, -5.8305e-01,  2.0833e-01],\n",
      "        [-4.3870e-02,  1.1883e+00,  1.7909e-01, -2.8323e-01,  1.2116e+00,\n",
      "          5.5297e-01, -4.9799e-02,  1.1061e-01],\n",
      "        [-6.1726e-01, -3.7719e-02, -6.0758e-01, -4.2680e-01, -4.2271e-04,\n",
      "          2.6247e-01, -6.1205e-01,  2.5515e-01],\n",
      "        [ 1.8526e-01, -5.7019e-02,  1.7633e-01,  2.0729e-01,  4.2766e-01,\n",
      "         -2.0746e-01,  1.9014e-01, -4.5955e-01],\n",
      "        [ 8.3602e-01, -1.0707e+00,  6.9100e-01,  1.2749e+00,  1.1499e-01,\n",
      "         -1.1636e+00,  8.5166e-01, -1.1394e+00],\n",
      "        [ 4.6709e-01, -1.4071e+00,  1.8921e-01,  1.7899e+00, -1.1175e+00,\n",
      "         -2.1077e+00,  5.0059e-01, -1.5779e+00],\n",
      "        [ 1.1348e+00, -4.0321e-02,  1.0612e+00,  8.0776e-01,  2.3329e-01,\n",
      "         -5.2454e-01,  1.1298e+00, -7.7576e-01],\n",
      "        [-1.5729e+00, -2.2459e+00, -1.8170e+00, -5.1219e-01, -2.3544e+00,\n",
      "         -3.7516e-01, -1.5521e+00,  4.5414e-01],\n",
      "        [-9.3897e-01,  1.0732e+00, -7.7913e-01, -1.0804e+00,  1.1873e-01,\n",
      "          1.1926e+00, -9.5260e-01,  1.3304e+00],\n",
      "        [-9.6102e-01,  1.4525e+00, -7.1159e-01, -1.3980e+00,  4.5960e-01,\n",
      "          1.5080e+00, -9.7823e-01,  1.5024e+00],\n",
      "        [ 9.3764e-01,  1.1835e+00,  1.1061e+00,  2.7852e-01,  1.2363e+00,\n",
      "          2.9405e-01,  9.1576e-01, -1.7244e-01],\n",
      "        [-8.5971e-01, -1.7118e+00, -1.1131e+00,  3.3901e-01, -1.7966e+00,\n",
      "         -8.6104e-01, -8.3163e-01, -4.8844e-01],\n",
      "        [-9.5884e-01,  2.6594e-01, -9.2135e-01, -9.2867e-01, -2.9406e-01,\n",
      "          7.7192e-01, -9.6285e-01,  9.8538e-01],\n",
      "        [-1.0933e+00,  1.5240e+00, -8.3106e-01, -1.3725e+00,  3.5441e-01,\n",
      "          1.4026e+00, -1.1063e+00,  1.5080e+00],\n",
      "        [ 1.3736e+00,  4.2076e-01,  1.4105e+00,  5.4388e-01,  8.8173e-01,\n",
      "         -2.0437e-01,  1.3547e+00, -5.2071e-01],\n",
      "        [ 1.0228e+00,  7.7908e-01,  1.1017e+00,  3.2521e-01,  8.9780e-01,\n",
      "          1.3890e-01,  1.0001e+00, -2.2948e-01],\n",
      "        [ 1.5037e+00, -5.8036e-01,  1.2678e+00,  1.3554e+00, -8.9638e-01,\n",
      "         -1.3240e+00,  1.5092e+00, -1.1932e+00],\n",
      "        [ 1.8240e-01, -1.3506e+00, -9.9063e-02,  1.0862e+00, -1.3534e+00,\n",
      "         -1.2032e+00,  2.0129e-01, -9.9291e-01],\n",
      "        [-1.4249e+00, -1.0419e+00, -1.5347e+00, -9.5520e-01, -1.3787e+00,\n",
      "          2.8356e-01, -1.4149e+00,  9.0744e-01],\n",
      "        [ 7.2461e-01,  1.6466e+00,  1.0010e+00, -1.8191e-01,  1.5256e+00,\n",
      "          8.5275e-01,  6.8853e-01,  4.1322e-01],\n",
      "        [ 2.3395e-01, -1.2517e+00, -2.9617e-02,  1.4021e+00, -1.1910e+00,\n",
      "         -1.5382e+00,  2.6440e-01, -1.2852e+00],\n",
      "        [ 3.5395e-01, -1.6514e-01,  3.0878e-01,  6.1347e-01,  2.7923e-01,\n",
      "         -5.5208e-01,  3.6707e-01, -7.9385e-01],\n",
      "        [-9.1174e-01, -1.3187e+00, -1.1365e+00,  1.3196e-01, -1.7748e+00,\n",
      "         -5.6328e-01, -8.9160e-01, -1.0203e-01],\n",
      "        [ 1.5983e+00, -1.7560e-01,  1.5241e+00,  1.0310e+00,  3.5881e-01,\n",
      "         -7.6345e-01,  1.5953e+00, -9.9007e-01],\n",
      "        [ 7.7045e-01,  1.4832e+00,  1.0321e+00,  2.2909e-01,  1.5941e+00,\n",
      "          4.9208e-01,  7.5158e-01, -1.2586e-01],\n",
      "        [ 1.4970e-01, -1.0515e+00,  1.5203e-02,  8.5254e-01, -1.1414e-01,\n",
      "         -8.5401e-01,  1.7139e-01, -9.3300e-01],\n",
      "        [ 1.1704e-01, -8.5038e-01, -1.2698e-01,  1.1131e+00, -1.3067e+00,\n",
      "         -1.2854e+00,  1.4087e-01, -1.0737e+00],\n",
      "        [-1.5441e+00, -2.6940e-01, -1.5970e+00, -1.9909e+00, -1.4756e+00,\n",
      "          1.7554e+00, -1.5661e+00,  2.0147e+00],\n",
      "        [-7.5358e-01,  3.2165e-01, -7.0845e-01, -6.6719e-01, -6.5442e-02,\n",
      "          2.8302e-01, -7.4996e-01,  4.3021e-01],\n",
      "        [ 1.0306e+00,  1.0556e+00,  1.1644e+00,  5.1730e-01,  1.1064e+00,\n",
      "          1.2768e-01,  1.0110e+00, -2.9476e-01],\n",
      "        [ 8.6592e-01,  1.6408e-01,  8.4615e-01,  6.2445e-01,  4.9067e-01,\n",
      "         -1.6634e-01,  8.5261e-01, -4.2000e-01],\n",
      "        [-6.2046e-01, -1.8746e-01, -5.9891e-01, -4.1890e-01,  1.9414e-01,\n",
      "          1.9331e-01, -6.1258e-01,  1.2826e-01],\n",
      "        [ 1.6575e+00,  1.2289e-01,  1.6117e+00,  6.7987e-01,  4.1338e-01,\n",
      "         -4.5071e-01,  1.6426e+00, -7.4483e-01],\n",
      "        [-1.1806e+00,  4.0358e-02, -1.0972e+00, -5.8595e-01,  3.7806e-02,\n",
      "          1.3051e-01, -1.1625e+00,  3.0282e-01],\n",
      "        [-1.1994e+00,  7.6399e-01, -1.0896e+00, -1.4807e+00, -3.1035e-01,\n",
      "          1.4069e+00, -1.2142e+00,  1.6512e+00],\n",
      "        [ 6.8421e-01,  4.8284e-01,  7.0839e-01, -1.0957e-01,  5.7435e-01,\n",
      "          2.1292e-01,  6.6173e-01, -1.5421e-02],\n",
      "        [ 7.3961e-01,  1.0105e+00,  8.8071e-01,  3.6322e-01,  1.1144e+00,\n",
      "          5.7343e-02,  7.3241e-01, -4.2675e-01],\n",
      "        [-5.4448e-01,  6.9903e-01, -4.1002e-01, -7.1733e-01,  5.8098e-01,\n",
      "          6.6834e-01, -5.4816e-01,  5.5567e-01],\n",
      "        [ 7.1590e-01, -9.9190e-02,  6.9209e-01,  3.1080e-01,  5.7221e-01,\n",
      "         -3.2088e-01,  7.1512e-01, -5.9740e-01],\n",
      "        [-1.5732e+00,  5.9662e-01, -1.4776e+00, -1.3923e+00, -7.4770e-01,\n",
      "          9.3705e-01, -1.5722e+00,  1.4629e+00],\n",
      "        [-1.1377e+00, -1.4444e+00, -1.3334e+00, -2.9456e-02, -1.6643e+00,\n",
      "         -5.0696e-01, -1.1144e+00, -2.7356e-02],\n",
      "        [ 5.7279e-01, -1.0853e-01,  4.8519e-01,  3.9005e-01, -2.2599e-02,\n",
      "         -2.8343e-01,  5.6782e-01, -4.3913e-01],\n",
      "        [-1.6698e+00,  4.8872e-01, -1.6087e+00, -2.0936e+00, -1.1171e+00,\n",
      "          2.0855e+00, -1.6851e+00,  2.0293e+00],\n",
      "        [-6.1725e-01,  1.0136e+00, -4.0486e-01, -8.0492e-01,  8.8305e-01,\n",
      "          8.8510e-01, -6.2333e-01,  7.0254e-01],\n",
      "        [-7.0571e-01,  7.0648e-01, -4.9355e-01, -6.2847e-01,  1.0476e+00,\n",
      "          7.6445e-01, -7.0583e-01,  6.0800e-01],\n",
      "        [ 1.0992e-01,  4.8079e-01,  3.0061e-01,  1.4332e-01,  1.5715e+00,\n",
      "          2.4810e-01,  1.1178e-01, -2.4413e-01],\n",
      "        [ 4.6422e-01, -1.3834e+00,  2.8593e-01,  7.4085e-01, -1.7330e-01,\n",
      "         -8.1176e-01,  4.6881e-01, -6.9427e-01],\n",
      "        [-1.2895e+00,  1.6775e+00, -1.0217e+00, -1.6585e+00,  4.4382e-03,\n",
      "          1.8121e+00, -1.3086e+00,  1.8570e+00],\n",
      "        [-1.3086e+00, -9.8306e-01, -1.3491e+00,  6.5087e-02, -5.8959e-01,\n",
      "         -6.7185e-01, -1.2732e+00, -4.5125e-01],\n",
      "        [-3.9515e-01, -1.3788e+00, -5.7092e-01,  3.0227e-01, -7.2030e-01,\n",
      "         -4.6181e-01, -3.8931e-01, -1.0038e-01],\n",
      "        [ 1.0694e+00,  6.6290e-01,  1.1816e+00,  1.2887e-01,  1.2459e+00,\n",
      "          9.2265e-02,  1.0529e+00, -3.9024e-01],\n",
      "        [-9.7330e-01, -9.6933e-01, -1.1656e+00,  1.6269e-01, -1.7156e+00,\n",
      "         -7.4697e-01, -9.4034e-01, -4.6684e-01],\n",
      "        [-1.3810e+00,  7.0165e-01, -1.2960e+00, -1.4390e+00, -6.9652e-01,\n",
      "          1.1234e+00, -1.3866e+00,  1.5362e+00],\n",
      "        [ 8.8596e-01,  8.0884e-01,  1.0052e+00,  2.3181e-01,  1.1497e+00,\n",
      "          1.0038e-01,  8.7242e-01, -3.5278e-01],\n",
      "        [ 3.6145e-01,  1.2416e+00,  5.6416e-01,  7.4374e-02,  1.2300e+00,\n",
      "          5.5935e-01,  3.4461e-01,  1.1449e-01],\n",
      "        [-5.8517e-01,  1.4727e+00, -3.0408e-01, -8.2619e-01,  1.0116e+00,\n",
      "          9.1816e-01, -5.9146e-01,  6.7698e-01],\n",
      "        [ 7.3378e-01, -2.0707e-01,  5.2551e-01,  1.5195e+00, -1.0353e+00,\n",
      "         -1.8473e+00,  7.6118e-01, -1.4799e+00],\n",
      "        [-1.4348e+00, -2.4289e-01, -1.4262e+00, -2.5930e-01, -7.4019e-01,\n",
      "         -1.9441e-01, -1.4104e+00,  1.8368e-01],\n",
      "        [ 1.4766e+00,  4.5086e-01,  1.4558e+00,  7.7508e-01,  3.9687e-01,\n",
      "         -4.3957e-01,  1.4639e+00, -7.2586e-01],\n",
      "        [-1.3744e+00, -1.1811e+00, -1.4911e+00, -1.2821e+00, -1.2991e+00,\n",
      "          4.7437e-01, -1.3655e+00,  1.1334e+00],\n",
      "        [-1.5289e+00,  1.6141e-01, -1.5250e+00, -1.7622e+00, -1.2125e+00,\n",
      "          1.3210e+00, -1.5374e+00,  1.7975e+00],\n",
      "        [-1.5552e-01, -2.3873e+00, -4.7310e-01,  1.4181e+00, -1.4451e+00,\n",
      "         -1.7598e+00, -1.2055e-01, -1.3676e+00],\n",
      "        [-4.9520e-02, -7.2546e-01, -7.1779e-02,  2.8919e-01,  5.5293e-01,\n",
      "         -3.9501e-01, -3.8359e-02, -5.1917e-01],\n",
      "        [-4.9511e-01, -3.6260e-01, -4.9887e-01, -6.3336e-02,  1.8918e-01,\n",
      "         -1.3162e-01, -4.8019e-01, -2.5426e-01],\n",
      "        [-7.0280e-01,  1.0458e+00, -5.5344e-01, -8.6216e-01,  2.7753e-01,\n",
      "          9.4159e-01, -7.1454e-01,  9.8567e-01],\n",
      "        [ 8.7525e-01, -5.0921e-01,  7.6670e-01,  1.0166e+00,  1.4711e-01,\n",
      "         -7.8255e-01,  8.8187e-01, -9.1803e-01],\n",
      "        [ 1.5271e+00, -1.5180e+00,  1.2393e+00,  1.8799e+00, -8.7937e-01,\n",
      "         -1.9253e+00,  1.5457e+00, -1.5339e+00],\n",
      "        [ 8.2784e-01,  6.3141e-01,  8.8049e-01,  2.2140e-01,  7.4633e-01,\n",
      "          1.5867e-01,  8.0704e-01, -1.4116e-01],\n",
      "        [-1.6072e+00,  1.9910e+00, -1.3017e+00, -2.1418e+00, -5.1279e-01,\n",
      "          2.7645e+00, -1.6327e+00,  2.0861e+00]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(y)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BleveNet(\n",
      "  (fc1): Linear(in_features=11, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (mish): Mish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Define the NN architecture\n",
    "## NN with 3 hidden layer, s=[26, 256, 256, 256, 8]\n",
    "\n",
    "class BleveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BleveNet, self).__init__()\n",
    "        # The first hidden layer has 256 neurons\n",
    "        self.fc1 = nn.Linear(X_train_torch.shape[1], 256)\n",
    "        # The second hidden layer has 256 neurons\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        # The third hidden layer has 256 neurons\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        # The final layer has 1 output neuron\n",
    "        self.fc4 = nn.Linear(256, 8)\n",
    "\n",
    "\n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Mish activation\n",
    "        self.mish = nn.Mish()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add third fully connected layer\n",
    "        x = self.fc3(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add final fully connected layers, separated in 8 different outputs\n",
    "        output = self.fc4(x)\n",
    "       \n",
    "        return output\n",
    "\n",
    "# initialize the NN\n",
    "model = BleveNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.HuberLoss()        # This is the best loss function for my model\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)     # This is the best optimizer for my model \n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200 \tTraining Loss: 0.061244\n",
      "Epoch: 2/200 \tTraining Loss: 0.016938\n",
      "Epoch: 3/200 \tTraining Loss: 0.014251\n",
      "Epoch: 4/200 \tTraining Loss: 0.012376\n",
      "Epoch: 5/200 \tTraining Loss: 0.011539\n",
      "Epoch: 6/200 \tTraining Loss: 0.011046\n",
      "Epoch: 7/200 \tTraining Loss: 0.009998\n",
      "Epoch: 8/200 \tTraining Loss: 0.009740\n",
      "Epoch: 9/200 \tTraining Loss: 0.009226\n",
      "Epoch: 10/200 \tTraining Loss: 0.009230\n",
      "Epoch: 11/200 \tTraining Loss: 0.008903\n",
      "Epoch: 12/200 \tTraining Loss: 0.008674\n",
      "Epoch: 13/200 \tTraining Loss: 0.008307\n",
      "Epoch: 14/200 \tTraining Loss: 0.008143\n",
      "Epoch: 15/200 \tTraining Loss: 0.008208\n",
      "Epoch: 16/200 \tTraining Loss: 0.007733\n",
      "Epoch: 17/200 \tTraining Loss: 0.007973\n",
      "Epoch: 18/200 \tTraining Loss: 0.007555\n",
      "Epoch: 19/200 \tTraining Loss: 0.007456\n",
      "Epoch: 20/200 \tTraining Loss: 0.007612\n",
      "Epoch: 21/200 \tTraining Loss: 0.007620\n",
      "Epoch: 22/200 \tTraining Loss: 0.007586\n",
      "Epoch: 23/200 \tTraining Loss: 0.007154\n",
      "Epoch: 24/200 \tTraining Loss: 0.007146\n",
      "Epoch: 25/200 \tTraining Loss: 0.007116\n",
      "Epoch: 26/200 \tTraining Loss: 0.007731\n",
      "Epoch: 27/200 \tTraining Loss: 0.007038\n",
      "Epoch: 28/200 \tTraining Loss: 0.006847\n",
      "Epoch: 29/200 \tTraining Loss: 0.006625\n",
      "Epoch: 30/200 \tTraining Loss: 0.006819\n",
      "Epoch: 31/200 \tTraining Loss: 0.006653\n",
      "Epoch: 32/200 \tTraining Loss: 0.006781\n",
      "Epoch: 33/200 \tTraining Loss: 0.006701\n",
      "Epoch: 34/200 \tTraining Loss: 0.006772\n",
      "Epoch: 35/200 \tTraining Loss: 0.006954\n",
      "Epoch: 36/200 \tTraining Loss: 0.006648\n",
      "Epoch: 37/200 \tTraining Loss: 0.006588\n",
      "Epoch: 38/200 \tTraining Loss: 0.006351\n",
      "Epoch: 39/200 \tTraining Loss: 0.006597\n",
      "Epoch: 40/200 \tTraining Loss: 0.006627\n",
      "Epoch: 41/200 \tTraining Loss: 0.006869\n",
      "Epoch: 42/200 \tTraining Loss: 0.007920\n",
      "Epoch: 43/200 \tTraining Loss: 0.006934\n",
      "Epoch: 44/200 \tTraining Loss: 0.006384\n",
      "Epoch: 45/200 \tTraining Loss: 0.006409\n",
      "Epoch: 46/200 \tTraining Loss: 0.006435\n",
      "Epoch: 47/200 \tTraining Loss: 0.006275\n",
      "Epoch: 48/200 \tTraining Loss: 0.006269\n",
      "Epoch: 49/200 \tTraining Loss: 0.006490\n",
      "Epoch: 50/200 \tTraining Loss: 0.006657\n",
      "Epoch: 51/200 \tTraining Loss: 0.006374\n",
      "Epoch: 52/200 \tTraining Loss: 0.006918\n",
      "Epoch: 53/200 \tTraining Loss: 0.006636\n",
      "Epoch: 54/200 \tTraining Loss: 0.006582\n",
      "Epoch: 55/200 \tTraining Loss: 0.005997\n",
      "Epoch: 56/200 \tTraining Loss: 0.006177\n",
      "Epoch: 57/200 \tTraining Loss: 0.006312\n",
      "Epoch: 58/200 \tTraining Loss: 0.006387\n",
      "Epoch: 59/200 \tTraining Loss: 0.006358\n",
      "Epoch: 60/200 \tTraining Loss: 0.006441\n",
      "Epoch: 61/200 \tTraining Loss: 0.006296\n",
      "Epoch: 62/200 \tTraining Loss: 0.006074\n",
      "Epoch: 63/200 \tTraining Loss: 0.006088\n",
      "Epoch: 64/200 \tTraining Loss: 0.005979\n",
      "Epoch: 65/200 \tTraining Loss: 0.006422\n",
      "Epoch: 66/200 \tTraining Loss: 0.006604\n",
      "Epoch: 67/200 \tTraining Loss: 0.006109\n",
      "Epoch: 68/200 \tTraining Loss: 0.006247\n",
      "Epoch: 69/200 \tTraining Loss: 0.005789\n",
      "Epoch: 70/200 \tTraining Loss: 0.006139\n",
      "Epoch: 71/200 \tTraining Loss: 0.006881\n",
      "Epoch: 72/200 \tTraining Loss: 0.006354\n",
      "Epoch: 73/200 \tTraining Loss: 0.006659\n",
      "Epoch: 74/200 \tTraining Loss: 0.006559\n",
      "Epoch: 75/200 \tTraining Loss: 0.006568\n",
      "Epoch: 76/200 \tTraining Loss: 0.006792\n",
      "Epoch: 77/200 \tTraining Loss: 0.005958\n",
      "Epoch: 78/200 \tTraining Loss: 0.005861\n",
      "Epoch: 79/200 \tTraining Loss: 0.005931\n",
      "Epoch: 80/200 \tTraining Loss: 0.006217\n",
      "Epoch: 81/200 \tTraining Loss: 0.006393\n",
      "Epoch: 82/200 \tTraining Loss: 0.005910\n",
      "Epoch: 83/200 \tTraining Loss: 0.005991\n",
      "Epoch: 84/200 \tTraining Loss: 0.006307\n",
      "Epoch: 85/200 \tTraining Loss: 0.006256\n",
      "Epoch: 86/200 \tTraining Loss: 0.006392\n",
      "Epoch: 87/200 \tTraining Loss: 0.006000\n",
      "Epoch: 88/200 \tTraining Loss: 0.006310\n",
      "Epoch: 89/200 \tTraining Loss: 0.005926\n",
      "Epoch: 90/200 \tTraining Loss: 0.005959\n",
      "Epoch: 91/200 \tTraining Loss: 0.005927\n",
      "Epoch: 92/200 \tTraining Loss: 0.006153\n",
      "Epoch: 93/200 \tTraining Loss: 0.006255\n",
      "Epoch: 94/200 \tTraining Loss: 0.006154\n",
      "Epoch: 95/200 \tTraining Loss: 0.006377\n",
      "Epoch: 96/200 \tTraining Loss: 0.005840\n",
      "Epoch: 97/200 \tTraining Loss: 0.005769\n",
      "Epoch: 98/200 \tTraining Loss: 0.006224\n",
      "Epoch: 99/200 \tTraining Loss: 0.006232\n",
      "Epoch: 100/200 \tTraining Loss: 0.005883\n",
      "Epoch: 101/200 \tTraining Loss: 0.006218\n",
      "Epoch: 102/200 \tTraining Loss: 0.006259\n",
      "Epoch: 103/200 \tTraining Loss: 0.006090\n",
      "Epoch: 104/200 \tTraining Loss: 0.005915\n",
      "Epoch: 105/200 \tTraining Loss: 0.006577\n",
      "Epoch: 106/200 \tTraining Loss: 0.006115\n",
      "Epoch: 107/200 \tTraining Loss: 0.005943\n",
      "Epoch: 108/200 \tTraining Loss: 0.006335\n",
      "Epoch: 109/200 \tTraining Loss: 0.005946\n",
      "Epoch: 110/200 \tTraining Loss: 0.006071\n",
      "Epoch: 111/200 \tTraining Loss: 0.006216\n",
      "Epoch: 112/200 \tTraining Loss: 0.006099\n",
      "Epoch: 113/200 \tTraining Loss: 0.006237\n",
      "Epoch: 114/200 \tTraining Loss: 0.006228\n",
      "Epoch: 115/200 \tTraining Loss: 0.005926\n",
      "Epoch: 116/200 \tTraining Loss: 0.005854\n",
      "Epoch: 117/200 \tTraining Loss: 0.005689\n",
      "Epoch: 118/200 \tTraining Loss: 0.006471\n",
      "Epoch: 119/200 \tTraining Loss: 0.006222\n",
      "Epoch: 120/200 \tTraining Loss: 0.006090\n",
      "Epoch: 121/200 \tTraining Loss: 0.005941\n",
      "Epoch: 122/200 \tTraining Loss: 0.006447\n",
      "Epoch: 123/200 \tTraining Loss: 0.006660\n",
      "Epoch: 124/200 \tTraining Loss: 0.006165\n",
      "Epoch: 125/200 \tTraining Loss: 0.006359\n",
      "Epoch: 126/200 \tTraining Loss: 0.006047\n",
      "Epoch: 127/200 \tTraining Loss: 0.005833\n",
      "Epoch: 128/200 \tTraining Loss: 0.005982\n",
      "Epoch: 129/200 \tTraining Loss: 0.005797\n",
      "Epoch: 130/200 \tTraining Loss: 0.005748\n",
      "Epoch: 131/200 \tTraining Loss: 0.006041\n",
      "Epoch: 132/200 \tTraining Loss: 0.006135\n",
      "Epoch: 133/200 \tTraining Loss: 0.006209\n",
      "Epoch: 134/200 \tTraining Loss: 0.005939\n",
      "Epoch: 135/200 \tTraining Loss: 0.005721\n",
      "Epoch: 136/200 \tTraining Loss: 0.005809\n",
      "Epoch: 137/200 \tTraining Loss: 0.005738\n",
      "Epoch: 138/200 \tTraining Loss: 0.007387\n",
      "Epoch: 139/200 \tTraining Loss: 0.006014\n",
      "Epoch: 140/200 \tTraining Loss: 0.005933\n",
      "Epoch: 141/200 \tTraining Loss: 0.005647\n",
      "Epoch: 142/200 \tTraining Loss: 0.006155\n",
      "Epoch: 143/200 \tTraining Loss: 0.005651\n",
      "Epoch: 144/200 \tTraining Loss: 0.005891\n",
      "Epoch: 145/200 \tTraining Loss: 0.005966\n",
      "Epoch: 146/200 \tTraining Loss: 0.006093\n",
      "Epoch: 147/200 \tTraining Loss: 0.005992\n",
      "Epoch: 148/200 \tTraining Loss: 0.005769\n",
      "Epoch: 149/200 \tTraining Loss: 0.005726\n",
      "Epoch: 150/200 \tTraining Loss: 0.006105\n",
      "Epoch: 151/200 \tTraining Loss: 0.006855\n",
      "Epoch: 152/200 \tTraining Loss: 0.005989\n",
      "Epoch: 153/200 \tTraining Loss: 0.005871\n",
      "Epoch: 154/200 \tTraining Loss: 0.006215\n",
      "Epoch: 155/200 \tTraining Loss: 0.005876\n",
      "Epoch: 156/200 \tTraining Loss: 0.006190\n",
      "Epoch: 157/200 \tTraining Loss: 0.006086\n",
      "Epoch: 158/200 \tTraining Loss: 0.005920\n",
      "Epoch: 159/200 \tTraining Loss: 0.005769\n",
      "Epoch: 160/200 \tTraining Loss: 0.005705\n",
      "Epoch: 161/200 \tTraining Loss: 0.006178\n",
      "Epoch: 162/200 \tTraining Loss: 0.006112\n",
      "Epoch: 163/200 \tTraining Loss: 0.005898\n",
      "Epoch: 164/200 \tTraining Loss: 0.006200\n",
      "Epoch: 165/200 \tTraining Loss: 0.005882\n",
      "Epoch: 166/200 \tTraining Loss: 0.005991\n",
      "Epoch: 167/200 \tTraining Loss: 0.005821\n",
      "Epoch: 168/200 \tTraining Loss: 0.005510\n",
      "Epoch: 169/200 \tTraining Loss: 0.005653\n",
      "Epoch: 170/200 \tTraining Loss: 0.006084\n",
      "Epoch: 171/200 \tTraining Loss: 0.005991\n",
      "Epoch: 172/200 \tTraining Loss: 0.006179\n",
      "Epoch: 173/200 \tTraining Loss: 0.006028\n",
      "Epoch: 174/200 \tTraining Loss: 0.006100\n",
      "Epoch: 175/200 \tTraining Loss: 0.006533\n",
      "Epoch: 176/200 \tTraining Loss: 0.006086\n",
      "Epoch: 177/200 \tTraining Loss: 0.005674\n",
      "Epoch: 178/200 \tTraining Loss: 0.006364\n",
      "Epoch: 179/200 \tTraining Loss: 0.005829\n",
      "Epoch: 180/200 \tTraining Loss: 0.006056\n",
      "Epoch: 181/200 \tTraining Loss: 0.005867\n",
      "Epoch: 182/200 \tTraining Loss: 0.005993\n",
      "Epoch: 183/200 \tTraining Loss: 0.005681\n",
      "Epoch: 184/200 \tTraining Loss: 0.005956\n",
      "Epoch: 185/200 \tTraining Loss: 0.005575\n",
      "Epoch: 186/200 \tTraining Loss: 0.005845\n",
      "Epoch: 187/200 \tTraining Loss: 0.005682\n",
      "Epoch: 188/200 \tTraining Loss: 0.006002\n",
      "Epoch: 189/200 \tTraining Loss: 0.005530\n",
      "Epoch: 190/200 \tTraining Loss: 0.005622\n",
      "Epoch: 191/200 \tTraining Loss: 0.005885\n",
      "Epoch: 192/200 \tTraining Loss: 0.006114\n",
      "Epoch: 193/200 \tTraining Loss: 0.005821\n",
      "Epoch: 194/200 \tTraining Loss: 0.005680\n",
      "Epoch: 195/200 \tTraining Loss: 0.006468\n",
      "Epoch: 196/200 \tTraining Loss: 0.005669\n",
      "Epoch: 197/200 \tTraining Loss: 0.005856\n",
      "Epoch: 198/200 \tTraining Loss: 0.006034\n",
      "Epoch: 199/200 \tTraining Loss: 0.005950\n",
      "Epoch: 200/200 \tTraining Loss: 0.005962\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200 \n",
    "\n",
    "model.to(device)    # bring the model to gpu\n",
    "model.train()       # prep model for training\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #bring data and target to gpu\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print('Epoch: {}/{} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1,\n",
    "        n_epochs, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "\n",
    "# Save the model  -- I already saved this and submitted\n",
    "torch.save(model.state_dict(), 'PyTorch_Model/NN_mish_Drop_L2_Huber_200Epoch_Vol.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the saved state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3419185   0.35157678  1.3956077  ... -0.35246992  1.3304638\n",
      "  -0.68985176]\n",
      " [-1.2606275  -0.31761965 -1.288682   ...  0.8197284  -1.2664359\n",
      "   1.2713753 ]\n",
      " [-0.17855293  0.9834371   0.0251878  ...  0.57652086 -0.18772097\n",
      "   0.28882495]\n",
      " ...\n",
      " [ 0.7846289  -0.14635831  0.70466614 ... -0.47137696  0.782771\n",
      "  -0.63114977]\n",
      " [-1.4689081   1.5421643  -1.2747688  ...  2.0490417  -1.496314\n",
      "   2.0510683 ]\n",
      " [-0.31857166 -1.8138261  -0.5870665  ... -1.2275565  -0.28610098\n",
      "  -0.95879877]]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('PyTorch_Model/NN_mish_Drop_L2_Huber_200Epoch_Vol.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval()           # prep model for *evaluation*\n",
    "model.to(device)\n",
    "with torch.no_grad():  # turn off gradient to save memory\n",
    "    y_predNN_torch = model(X_test_torch.to(device))\n",
    "\n",
    "y_predNN_normal = y_predNN_torch.cpu().numpy()     # convert to numpy array\n",
    "y_test_normal = y_test_torch.cpu().numpy()\n",
    "print(y_predNN_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network scores in normal distribution: r2 = 0.991845493561251, mape = 0.7107011079788208\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test_normal, y_predNN_normal)\n",
    "r2 = r2_score(y_test_normal, y_predNN_normal)\n",
    "print(f\"Neural Network scores in normal distribution: r2 = {r2}, mape = {mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.3667634e-02, 1.8548179e-02, 1.1636234e-01, ..., 3.8754070e+01,\n",
       "        9.8509364e-02, 8.0267981e-02],\n",
       "       [1.8834118e-02, 1.4985325e-02, 3.3226784e-02, ..., 1.1076880e+02,\n",
       "        2.1242874e-02, 3.9918807e-01],\n",
       "       [4.8206545e-02, 2.2608742e-02, 7.2926894e-02, ..., 9.1407677e+01,\n",
       "        5.1674042e-02, 1.8489788e-01],\n",
       "       ...,\n",
       "       [7.4865617e-02, 1.6826645e-02, 9.2751727e-02, ..., 3.5103203e+01,\n",
       "        7.9325706e-02, 9.2670694e-02],\n",
       "       [1.4892378e-02, 2.8228812e-02, 3.5039697e-02, ..., 3.6188025e+02,\n",
       "        1.6577341e-02, 1.1703123e+00],\n",
       "       [4.2928264e-02, 7.8649037e-03, 5.2455671e-02, ..., 1.2516535e+01,\n",
       "        4.7389425e-02, 4.7712237e-02]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_32 = y_test.astype('float32')\n",
    "y_test_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4,    7],\n",
       "       [  40,    7],\n",
       "       [  78,    7],\n",
       "       [ 128,    3],\n",
       "       [ 128,    7],\n",
       "       [ 161,    7],\n",
       "       [ 180,    7],\n",
       "       [ 295,    7],\n",
       "       [ 612,    7],\n",
       "       [ 636,    7],\n",
       "       [ 646,    7],\n",
       "       [ 708,    7],\n",
       "       [ 784,    7],\n",
       "       [ 937,    7],\n",
       "       [ 951,    7],\n",
       "       [1073,    7],\n",
       "       [1154,    7],\n",
       "       [1192,    7],\n",
       "       [1202,    7],\n",
       "       [1386,    7],\n",
       "       [1429,    7],\n",
       "       [1503,    7],\n",
       "       [1504,    7],\n",
       "       [1535,    7],\n",
       "       [1550,    7],\n",
       "       [1551,    7],\n",
       "       [1632,    7],\n",
       "       [1650,    7],\n",
       "       [1670,    7],\n",
       "       [1703,    7],\n",
       "       [1797,    3],\n",
       "       [1797,    7],\n",
       "       [1806,    7],\n",
       "       [1851,    7],\n",
       "       [1932,    7],\n",
       "       [1963,    7],\n",
       "       [2010,    7],\n",
       "       [2042,    7],\n",
       "       [2079,    7],\n",
       "       [2136,    7],\n",
       "       [2169,    7],\n",
       "       [2207,    7],\n",
       "       [2222,    7],\n",
       "       [2263,    7],\n",
       "       [2331,    7],\n",
       "       [2396,    7],\n",
       "       [2466,    7],\n",
       "       [2500,    7],\n",
       "       [2547,    7],\n",
       "       [2695,    7],\n",
       "       [2820,    7],\n",
       "       [2859,    7],\n",
       "       [2866,    7],\n",
       "       [3026,    7],\n",
       "       [3048,    7],\n",
       "       [3074,    7],\n",
       "       [3110,    7],\n",
       "       [3235,    7],\n",
       "       [3360,    7],\n",
       "       [3514,    7],\n",
       "       [3529,    7],\n",
       "       [3542,    7],\n",
       "       [3629,    7],\n",
       "       [3684,    7],\n",
       "       [3860,    7],\n",
       "       [3908,    7],\n",
       "       [3916,    7],\n",
       "       [4036,    7],\n",
       "       [4044,    7],\n",
       "       [4076,    7],\n",
       "       [4091,    7],\n",
       "       [4104,    7],\n",
       "       [4172,    7],\n",
       "       [4200,    7],\n",
       "       [4230,    7],\n",
       "       [4275,    7],\n",
       "       [4343,    7],\n",
       "       [4493,    7],\n",
       "       [4497,    7],\n",
       "       [4524,    7],\n",
       "       [4525,    7],\n",
       "       [4536,    7],\n",
       "       [4568,    7],\n",
       "       [4589,    7],\n",
       "       [4605,    7],\n",
       "       [4609,    7],\n",
       "       [4629,    7],\n",
       "       [4659,    7],\n",
       "       [4701,    7],\n",
       "       [4829,    7],\n",
       "       [4895,    7],\n",
       "       [5006,    7],\n",
       "       [5052,    7],\n",
       "       [5079,    7],\n",
       "       [5162,    7],\n",
       "       [5341,    7],\n",
       "       [5428,    7],\n",
       "       [5438,    7],\n",
       "       [5618,    7],\n",
       "       [5641,    7],\n",
       "       [5687,    7],\n",
       "       [5733,    7],\n",
       "       [5750,    7],\n",
       "       [5967,    7],\n",
       "       [6010,    7],\n",
       "       [6026,    7],\n",
       "       [6036,    7],\n",
       "       [6068,    7],\n",
       "       [6092,    7],\n",
       "       [6101,    7],\n",
       "       [6169,    7],\n",
       "       [6222,    3],\n",
       "       [6222,    7],\n",
       "       [6256,    7],\n",
       "       [6305,    7],\n",
       "       [6364,    7],\n",
       "       [6391,    7],\n",
       "       [6402,    7],\n",
       "       [6704,    7],\n",
       "       [6712,    7],\n",
       "       [7011,    7],\n",
       "       [7020,    7],\n",
       "       [7078,    7],\n",
       "       [7124,    7],\n",
       "       [7191,    7]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(y_predNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41398525, 0.19057024, 0.07022166,        nan, 1.3611119 ,\n",
       "       0.07738686, 0.08599842, 0.10823703, 0.06788445, 0.02410531,\n",
       "       0.07842994, 0.30146182, 0.15119481, 0.18803334, 1.4355588 ,\n",
       "       0.14433491, 0.23122919, 0.07023752, 0.231385  , 0.10801053,\n",
       "       0.11071312, 0.196836  , 0.7667458 , 0.17168367, 0.10047543,\n",
       "       0.06725502, 0.5704529 , 0.0394274 , 0.01899445, 0.08809388,\n",
       "       0.06571853, 0.50231683, 0.31495237, 0.23754072, 0.18424547,\n",
       "       1.8959973 , 0.9359857 , 0.10310471, 0.18972826,        nan],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.2713753 ,  0.28882495, -0.8385837 ,  2.1866858 ,  2.0217519 ,\n",
       "       -0.750896  , -0.64968836, -0.40790528, -0.86789644, -1.4890143 ,\n",
       "       -0.73839784,  0.8916608 , -0.01011739,  0.27118924,  2.0324287 ,\n",
       "       -0.06818043,  0.5451149 , -0.83838594,  0.5460082 , -0.41023454,\n",
       "       -0.38261923,  0.33150393,  1.8001761 ,  0.15236624, -0.48923042,\n",
       "       -0.87585044,  1.5863527 , -1.2550513 , -1.5714498 , -0.6257286 ,\n",
       "       -0.89537835,  1.4712195 ,  0.94701195,  0.58082664,  0.24446476,\n",
       "        2.0708477 ,  1.9030248 , -0.46132648,  0.28299537,  2.1624386 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN_normal[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39918807, 0.18489788, 0.07076792, 1.603528  , 1.0806105 ,\n",
       "       0.06908134, 0.08818348, 0.10897039, 0.06826332, 0.01860524,\n",
       "       0.08134046, 0.28987974, 0.12975076, 0.17156978, 1.2115381 ,\n",
       "       0.15436813, 0.22705919, 0.06763056, 0.22765867, 0.10868868,\n",
       "       0.11713055, 0.19952142, 0.66621888, 0.15975925, 0.09596858,\n",
       "       0.06414993, 0.59720933, 0.03660972, 0.01633277, 0.08981635,\n",
       "       0.06839496, 0.49123496, 0.30692583, 0.2290165 , 0.18374079,\n",
       "       1.2546521 , 0.83790588, 0.08270955, 0.18826026, 1.7111793 ])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21512\\2566741821.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_predNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpower\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predNN_normal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Neural Network scores in actual distribution: r2 = {r2}, mape = {mape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buita\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buita\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_absolute_percentage_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;36m112589990684262.48\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \"\"\"\n\u001b[1;32m--> 361\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    362\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\buita\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buita\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buita\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y_predNN = power.inverse_transform(y_predNN_normal)\n",
    "mape = mean_absolute_percentage_error(y_test, y_predNN.astype('float64'))\n",
    "r2 = r2_score(y_test, y_predNN)\n",
    "\n",
    "print(f\"Neural Network scores in actual distribution: r2 = {r2}, mape = {mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41398525, 0.19057024, 0.07022166,        nan, 1.3611119 ,\n",
       "       0.07738686, 0.08599842, 0.10823703, 0.06788445, 0.02410531,\n",
       "       0.07842994, 0.30146182, 0.15119481, 0.18803334, 1.4355588 ,\n",
       "       0.14433491, 0.23122919, 0.07023752, 0.231385  , 0.10801053,\n",
       "       0.11071312, 0.196836  , 0.7667458 , 0.17168367, 0.10047543,\n",
       "       0.06725502, 0.5704529 , 0.0394274 , 0.01899445, 0.08809388,\n",
       "       0.06571853, 0.50231683, 0.31495237, 0.23754072, 0.18424547,\n",
       "       1.8959973 , 0.9359857 , 0.10310471, 0.18972826,        nan],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39918807, 0.18489788, 0.07076792, 1.603528  , 1.0806105 ,\n",
       "       0.06908134, 0.08818348, 0.10897039, 0.06826332, 0.01860524,\n",
       "       0.08134046, 0.28987974, 0.12975076, 0.17156978, 1.2115381 ,\n",
       "       0.15436813, 0.22705919, 0.06763056, 0.22765867, 0.10868868,\n",
       "       0.11713055, 0.19952142, 0.66621888, 0.15975925, 0.09596858,\n",
       "       0.06414993, 0.59720933, 0.03660972, 0.01633277, 0.08981635,\n",
       "       0.06839496, 0.49123496, 0.30692583, 0.2290165 , 0.18374079,\n",
       "       1.2546521 , 0.83790588, 0.08270955, 0.18826026, 1.7111793 ])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4264572 ,  0.25943604,  1.4826803 , ..., -0.31575143,\n",
       "         1.4172286 , -0.71653765],\n",
       "       [-1.2615352 , -0.37904325, -1.2940732 , ...,  0.7514473 ,\n",
       "        -1.2632077 ,  1.2307336 ],\n",
       "       [-0.15251897,  0.85732245,  0.04723866, ...,  0.55549186,\n",
       "        -0.16029689,  0.24910146],\n",
       "       ...,\n",
       "       [ 0.79249597, -0.03439955,  0.7064419 , ..., -0.41549242,\n",
       "         0.7877065 , -0.5742728 ],\n",
       "       [-1.4161336 ,  1.5035548 , -1.2321873 , ...,  1.9603044 ,\n",
       "        -1.4381645 ,  1.9839134 ],\n",
       "       [-0.3463911 , -2.0699105 , -0.6407975 , ..., -1.4355813 ,\n",
       "        -0.31168935, -1.1362922 ]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.42645712,  0.25943604,  1.48268033, ..., -0.31575143,\n",
       "         1.41722856, -0.71653765],\n",
       "       [-1.26153516, -0.37904324, -1.29407324, ...,  0.75144733,\n",
       "        -1.26320771,  1.23073358],\n",
       "       [-0.15251897,  0.85732247,  0.04723866, ...,  0.55549186,\n",
       "        -0.16029688,  0.24910145],\n",
       "       ...,\n",
       "       [ 0.79249594, -0.03439955,  0.70644185, ..., -0.41549242,\n",
       "         0.78770649, -0.57427283],\n",
       "       [-1.41613359,  1.50355488, -1.23218724, ...,  1.96030433,\n",
       "        -1.43816449,  1.98391344],\n",
       "       [-0.34639111, -2.06991055, -0.6407975 , ..., -1.43558129,\n",
       "        -0.31168935, -1.13629226]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3419185 ,  0.35157678,  1.3956077 , ..., -0.35246992,\n",
       "         1.3304638 , -0.68985176],\n",
       "       [-1.2606275 , -0.31761965, -1.288682  , ...,  0.8197284 ,\n",
       "        -1.2664359 ,  1.2713753 ],\n",
       "       [-0.17855293,  0.9834371 ,  0.0251878 , ...,  0.57652086,\n",
       "        -0.18772097,  0.28882495],\n",
       "       ...,\n",
       "       [ 0.7846289 , -0.14635831,  0.70466614, ..., -0.47137696,\n",
       "         0.782771  , -0.63114977],\n",
       "       [-1.4689081 ,  1.5421643 , -1.2747688 , ...,  2.0490417 ,\n",
       "        -1.496314  ,  2.0510683 ],\n",
       "       [-0.31857166, -1.8138261 , -0.5870665 , ..., -1.2275565 ,\n",
       "        -0.28610098, -0.95879877]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
