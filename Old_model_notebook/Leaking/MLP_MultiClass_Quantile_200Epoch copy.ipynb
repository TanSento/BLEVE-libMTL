{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import timeit\n",
    "#import shap\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.010208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.012350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.014577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.016878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.019250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0  B1                         24.5          0.519805             2.2   \n",
       "1  B1                         24.5          0.519805             2.2   \n",
       "2  B1                         24.5          0.519805             2.2   \n",
       "3  B1                         24.5          0.519805             2.2   \n",
       "4  B1                         24.5          0.519805             2.2   \n",
       "\n",
       "   Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0              6.0              1.0                  1.6   \n",
       "1              6.0              1.0                  1.6   \n",
       "2              6.0              1.0                  1.6   \n",
       "3              6.0              1.0                  1.6   \n",
       "4              6.0              1.0                  1.6   \n",
       "\n",
       "   Tank Height with Gas (m)   Vapour Temerature (K)   Liquid Temerature (K)  \\\n",
       "0                       0.4                   307.8                   339.0   \n",
       "1                       0.4                   307.8                   339.0   \n",
       "2                       0.4                   307.8                   339.0   \n",
       "3                       0.4                   307.8                   339.0   \n",
       "4                       0.4                   307.8                   339.0   \n",
       "\n",
       "      Status  Stand-off Distance    Target  \n",
       "0  Subcooled                 5.0  0.010208  \n",
       "1  Subcooled                 6.0  0.012350  \n",
       "2  Subcooled                 7.0  0.014577  \n",
       "3  Subcooled                 8.0  0.016878  \n",
       "4  Subcooled                 9.0  0.019250  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/arrival_time_COMPLETE.csv\")\n",
    "df2 = pd.read_csv(\"data/negative_duration_COMPLETE.csv\")\n",
    "df3 = pd.read_csv(\"data/negative_peak_time_COMPLETE.csv\")\n",
    "df4 = pd.read_csv(\"data/negative_pressure_COMPLETE.csv\")\n",
    "df5 = pd.read_csv(\"data/positive_duration_COMPLETE.csv\")\n",
    "df6 = pd.read_csv(\"data/positive_impulse_COMPLETE.csv\")\n",
    "df7 = pd.read_csv(\"data/positive_peak_time_COMPLETE.csv\")\n",
    "df8 = pd.read_csv(\"data/positive_pressure_COMPLETE.csv\")\n",
    "\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.007302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.007816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.008817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>P500</td>\n",
       "      <td>11.40239</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>388.2</td>\n",
       "      <td>366.7</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0        B1                     24.50000          0.519805             2.2   \n",
       "1        B1                     24.50000          0.519805             2.2   \n",
       "2        B1                     24.50000          0.519805             2.2   \n",
       "3        B1                     24.50000          0.519805             2.2   \n",
       "4        B1                     24.50000          0.519805             2.2   \n",
       "...     ...                          ...               ...             ...   \n",
       "35995  P500                     11.40239          0.442321             1.4   \n",
       "35996  P500                     11.40239          0.442321             1.4   \n",
       "35997  P500                     11.40239          0.442321             1.4   \n",
       "35998  P500                     11.40239          0.442321             1.4   \n",
       "35999  P500                     11.40239          0.442321             1.4   \n",
       "\n",
       "       Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                  6.0              1.0                  1.6   \n",
       "1                  6.0              1.0                  1.6   \n",
       "2                  6.0              1.0                  1.6   \n",
       "3                  6.0              1.0                  1.6   \n",
       "4                  6.0              1.0                  1.6   \n",
       "...                ...              ...                  ...   \n",
       "35995              2.8              1.2                  1.4   \n",
       "35996              2.8              1.2                  1.4   \n",
       "35997              2.8              1.2                  1.4   \n",
       "35998              2.8              1.2                  1.4   \n",
       "35999              2.8              1.2                  1.4   \n",
       "\n",
       "       Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                           0.4                   307.8   \n",
       "1                           0.4                   307.8   \n",
       "2                           0.4                   307.8   \n",
       "3                           0.4                   307.8   \n",
       "4                           0.4                   307.8   \n",
       "...                         ...                     ...   \n",
       "35995                       0.8                   388.2   \n",
       "35996                       0.8                   388.2   \n",
       "35997                       0.8                   388.2   \n",
       "35998                       0.8                   388.2   \n",
       "35999                       0.8                   388.2   \n",
       "\n",
       "        Liquid Temerature (K)  Status  Stand-off Distance    Target  \n",
       "0                       339.0       0                 5.0  0.006817  \n",
       "1                       339.0       0                 6.0  0.007302  \n",
       "2                       339.0       0                 7.0  0.007816  \n",
       "3                       339.0       0                 8.0  0.008326  \n",
       "4                       339.0       0                 9.0  0.008817  \n",
       "...                       ...     ...                 ...       ...  \n",
       "35995                   366.7       1                36.0       NaN  \n",
       "35996                   366.7       1                37.0       NaN  \n",
       "35997                   366.7       1                38.0       NaN  \n",
       "35998                   366.7       1                39.0       NaN  \n",
       "35999                   366.7       1                40.0       NaN  \n",
       "\n",
       "[36000 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding 'Status' feature into 0 and 1 \n",
    "# 0 for Subcooled and 1 for Superheated\n",
    "# Doing Similarly for ID (Do we need dummy encoding ??)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "df5['Status'] = LE.fit_transform(df5['Status'])\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.519805</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>307.8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28798</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>33.17377</td>\n",
       "      <td>0.372041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>312.7</td>\n",
       "      <td>318.2</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0                         24.50000          0.519805             2.2   \n",
       "1                         24.50000          0.519805             2.2   \n",
       "2                         24.50000          0.519805             2.2   \n",
       "3                         24.50000          0.519805             2.2   \n",
       "4                         24.50000          0.519805             2.2   \n",
       "...                            ...               ...             ...   \n",
       "28795                     33.17377          0.372041             1.0   \n",
       "28796                     33.17377          0.372041             1.0   \n",
       "28797                     33.17377          0.372041             1.0   \n",
       "28798                     33.17377          0.372041             1.0   \n",
       "28799                     33.17377          0.372041             1.0   \n",
       "\n",
       "       Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                  6.0              1.0                  1.6   \n",
       "1                  6.0              1.0                  1.6   \n",
       "2                  6.0              1.0                  1.6   \n",
       "3                  6.0              1.0                  1.6   \n",
       "4                  6.0              1.0                  1.6   \n",
       "...                ...              ...                  ...   \n",
       "28795              2.2              0.6                  0.2   \n",
       "28796              2.2              0.6                  0.2   \n",
       "28797              2.2              0.6                  0.2   \n",
       "28798              2.2              0.6                  0.2   \n",
       "28799              2.2              0.6                  0.2   \n",
       "\n",
       "       Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                           0.4                   307.8   \n",
       "1                           0.4                   307.8   \n",
       "2                           0.4                   307.8   \n",
       "3                           0.4                   307.8   \n",
       "4                           0.4                   307.8   \n",
       "...                         ...                     ...   \n",
       "28795                       0.4                   312.7   \n",
       "28796                       0.4                   312.7   \n",
       "28797                       0.4                   312.7   \n",
       "28798                       0.4                   312.7   \n",
       "28799                       0.4                   312.7   \n",
       "\n",
       "        Liquid Temerature (K)  Status  Stand-off Distance  \n",
       "0                       339.0       0                 5.0  \n",
       "1                       339.0       0                 6.0  \n",
       "2                       339.0       0                 7.0  \n",
       "3                       339.0       0                 8.0  \n",
       "4                       339.0       0                 9.0  \n",
       "...                       ...     ...                 ...  \n",
       "28795                   318.2       0                36.0  \n",
       "28796                   318.2       0                37.0  \n",
       "28797                   318.2       0                38.0  \n",
       "28798                   318.2       0                39.0  \n",
       "28799                   318.2       0                40.0  \n",
       "\n",
       "[28800 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df5.drop(['ID','Target'], axis=1)[:28800]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.006817\n",
       "1        0.007302\n",
       "2        0.007816\n",
       "3        0.008326\n",
       "4        0.008817\n",
       "           ...   \n",
       "28795    0.012178\n",
       "28796    0.012275\n",
       "28797    0.012374\n",
       "28798    0.012477\n",
       "28799    0.012573\n",
       "Name: Target, Length: 28800, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y5 = df5['Target'][:28800]\n",
    "y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df1['Target'][:28800]\n",
    "y2 = df2['Target'][:28800]\n",
    "y3 = df3['Target'][:28800]\n",
    "y4 = df4['Target'][:28800]\n",
    "y6 = df6['Target'][:28800]\n",
    "y7 = df7['Target'][:28800]\n",
    "y8 = df8['Target'][:28800]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 11)\n",
      "(7200, 11)\n"
     ]
    }
   ],
   "source": [
    "X_traindf, X_testdf, y1_train, y1_test = train_test_split(X, y1, test_size=0.25, random_state=42)\n",
    "print(X_traindf.shape)\n",
    "print(X_testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_train, y2_test = train_test_split(y2, test_size=0.25, random_state=42)\n",
    "y3_train, y3_test = train_test_split(y3, test_size=0.25, random_state=42)\n",
    "y4_train, y4_test = train_test_split(y4, test_size=0.25, random_state=42)\n",
    "y5_train, y5_test = train_test_split(y5, test_size=0.25, random_state=42)\n",
    "y6_train, y6_test = train_test_split(y6, test_size=0.25, random_state=42)\n",
    "y7_train, y7_test = train_test_split(y7, test_size=0.25, random_state=42)\n",
    "y8_train, y8_test = train_test_split(y8, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01284534, 0.01444022, 0.10035855, ..., 0.10251021, 0.07990494,\n",
       "       0.01143898])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y7_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1268162 , 0.62633157, 0.04595783, ..., 0.02130297, 0.13602383,\n",
       "       2.3361142 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y8_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y1_train.values.reshape(-1,1), y2_train.values.reshape(-1,1), y3_train.values.reshape(-1,1), \n",
    "                          y4_train.values.reshape(-1,1), y5_train.values.reshape(-1,1), y6_train.values.reshape(-1,1),\n",
    "                          y7_train.values.reshape(-1,1), y8_train.values.reshape(-1,1)), axis=1)\n",
    "\n",
    "y_test = np.concatenate((y1_test.values.reshape(-1,1), y2_test.values.reshape(-1,1), y3_test.values.reshape(-1,1), \n",
    "                          y4_test.values.reshape(-1,1), y5_test.values.reshape(-1,1), y6_test.values.reshape(-1,1),\n",
    "                          y7_test.values.reshape(-1,1), y8_test.values.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 8)\n",
      "(7200, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.11694350e-02, 1.56393350e-02, 2.44314220e-02, ...,\n",
       "        2.86203890e+02, 1.28453400e-02, 1.12681620e+00],\n",
       "       [1.24119570e-02, 1.88029450e-02, 2.82499930e-02, ...,\n",
       "        1.80425900e+02, 1.44402250e-02, 6.26331570e-01],\n",
       "       [9.50448220e-02, 1.51018300e-02, 1.09446822e-01, ...,\n",
       "        1.49908640e+01, 1.00358550e-01, 4.59578340e-02],\n",
       "       ...,\n",
       "       [9.67233260e-02, 9.91223000e-03, 1.08929812e-01, ...,\n",
       "        7.44885020e+00, 1.02510210e-01, 2.13029660e-02],\n",
       "       [7.58939240e-02, 2.09730370e-02, 9.80206378e-02, ...,\n",
       "        6.19014550e+01, 7.99049360e-02, 1.36023830e-01],\n",
       "       [1.00712810e-02, 3.38855160e-02, 3.30022184e-02, ...,\n",
       "        7.96478820e+02, 1.14389770e-02, 2.33611420e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.36676340e-02, 1.85481800e-02, 1.16362342e-01, ...,\n",
       "        3.87540700e+01, 9.85093640e-02, 8.02679810e-02],\n",
       "       [1.88341180e-02, 1.49853250e-02, 3.32267860e-02, ...,\n",
       "        1.10768800e+02, 2.12428740e-02, 3.99188070e-01],\n",
       "       [4.82065450e-02, 2.26087420e-02, 7.29268908e-02, ...,\n",
       "        9.14076770e+01, 5.16740420e-02, 1.84897880e-01],\n",
       "       ...,\n",
       "       [7.48656170e-02, 1.68266440e-02, 9.27517236e-02, ...,\n",
       "        3.51032030e+01, 7.93257060e-02, 9.26706940e-02],\n",
       "       [1.48923780e-02, 2.82288120e-02, 3.50396958e-02, ...,\n",
       "        3.61880250e+02, 1.65773410e-02, 1.17031230e+00],\n",
       "       [4.29282640e-02, 7.86490400e-03, 5.24556696e-02, ...,\n",
       "        1.25165350e+01, 4.73894250e-02, 4.77122370e-02]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and Power Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing both X_train and X_test using standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_traindf)\n",
    "X_test = scaler.transform(X_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if it succeeded\n",
    "# df_stdscal = pd.DataFrame(X_train)\n",
    "# df_stdscal.hist(figsize = (20,20), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "y_train_normal = quantile.fit_transform(y_train)\n",
    "y_test_normal = quantile.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0197092 ,  0.33428349, -0.71517926,  2.24232066,  1.86359402,\n",
       "       -0.74523355, -0.4648274 , -0.2268882 , -0.75649043, -2.09079023,\n",
       "       -0.55463441,  0.75038709, -0.03604441,  0.25850177,  1.95536698,\n",
       "        0.14818542,  0.53428356, -0.76673673,  0.53672479, -0.23066606,\n",
       "       -0.14865688,  0.41007522,  1.43976542,  0.18550623, -0.37067758,\n",
       "       -0.82626052,  1.35012437, -1.40802512, -2.21909141, -0.44441688,\n",
       "       -0.75462019,  1.19340742,  0.80011561,  0.54253131,  0.33034992,\n",
       "        1.98874773,  1.62697118, -0.53849423,  0.35250048,  2.31339542])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_normal[1:41, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39918807, 0.18489788, 0.07076792, 1.603528  , 1.0806105 ,\n",
       "       0.06908134, 0.08818348, 0.10897039, 0.06826332, 0.01860524,\n",
       "       0.08134046, 0.28987974, 0.12975076, 0.17156978, 1.2115381 ,\n",
       "       0.15436813, 0.22705919, 0.06763056, 0.22765867, 0.10868868,\n",
       "       0.11713055, 0.19952142, 0.66621888, 0.15975925, 0.09596858,\n",
       "       0.06414993, 0.59720933, 0.03660972, 0.01633277, 0.08981635,\n",
       "       0.06839496, 0.49123496, 0.30692583, 0.2290165 , 0.18374079,\n",
       "       1.2546521 , 0.83790588, 0.08270955, 0.18826026, 1.7111793 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_check = quantile.inverse_transform(y_test_normal)\n",
    "y_test_check[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39918807, 0.18489788, 0.07076792, 1.603528  , 1.0806105 ,\n",
       "       0.06908134, 0.08818348, 0.10897039, 0.06826332, 0.01860524,\n",
       "       0.08134046, 0.28987974, 0.12975076, 0.17156978, 1.2115381 ,\n",
       "       0.15436813, 0.22705919, 0.06763056, 0.22765867, 0.10868868,\n",
       "       0.11713055, 0.19952142, 0.66621888, 0.15975925, 0.09596858,\n",
       "       0.06414993, 0.59720933, 0.03660972, 0.01633277, 0.08981635,\n",
       "       0.06839496, 0.49123496, 0.30692583, 0.2290165 , 0.18374079,\n",
       "       1.2546521 , 0.83790588, 0.08270955, 0.18826026, 1.7111793 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if it succeeded\n",
    "# df_stdscal = pd.DataFrame(y_train)\n",
    "# df_stdscal.hist(figsize = (20,20), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.backends.cudnn.version() , torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1781, -0.9747, -1.5140,  ..., -0.7230, -0.7424, -1.4851],\n",
      "        [-0.5207,  0.5219,  0.0684,  ..., -0.3853,  1.3470, -1.4851],\n",
      "        [ 1.3911,  1.5275, -0.7228,  ...,  1.1182, -0.7424,  1.3998],\n",
      "        ...,\n",
      "        [-1.6514,  0.5764, -1.2503,  ...,  0.7199,  1.3470,  1.3998],\n",
      "        [ 0.9835,  0.0136, -0.7228,  ..., -0.4908, -0.7424,  0.9190],\n",
      "        [ 1.3715,  0.0745,  0.3321,  ...,  0.5537,  1.3470, -1.4851]])\n"
     ]
    }
   ],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "X_train_torch = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_torch = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "\n",
    "\n",
    "y_train_torch = torch.from_numpy(y_train_normal.astype(np.float32))\n",
    "y_test_torch = torch.from_numpy(y_test_normal.astype(np.float32))\n",
    "\n",
    "\n",
    "print(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7290, -0.1825, -1.7822,  ...,  1.7153, -1.7731,  1.8945],\n",
       "        [-1.5605,  0.3168, -1.4323,  ...,  1.2409, -1.5663,  1.3875],\n",
       "        [ 1.4714, -0.2850,  1.1074,  ..., -1.2251,  1.4889, -1.1817],\n",
       "        ...,\n",
       "        [ 1.5913, -1.5754,  1.0800,  ..., -1.9514,  1.6349, -1.9590],\n",
       "        [ 0.6395,  0.5629,  0.6927,  ...,  0.1485,  0.6236,  0.0151],\n",
       "        [-1.9274,  2.0287, -1.1576,  ...,  2.8862, -2.0276,  2.6981]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3816,  0.2827,  1.4829,  ..., -0.3075,  1.3684, -0.5699],\n",
       "        [-1.0928, -0.3107, -1.1451,  ...,  0.7363, -1.0969,  1.0197],\n",
       "        [-0.1113,  0.7614,  0.0336,  ...,  0.5406, -0.1180,  0.3343],\n",
       "        ...,\n",
       "        [ 0.6086,  0.0336,  0.5384,  ..., -0.4086,  0.6064, -0.4105],\n",
       "        [-1.3440,  1.4611, -1.0647,  ...,  1.9779, -1.3778,  1.9265],\n",
       "        [-0.2490, -2.1335, -0.4783,  ..., -1.3961, -0.2252, -1.1426]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(X_train_torch)):\n",
    "   train_data.append([X_train_torch[i],\n",
    "                      y_train_torch[i] \n",
    "                     ])\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(X_test_torch)):\n",
    "   test_data.append([X_test_torch[i], \n",
    "                     y_test_torch[i]\n",
    "                     ])\n",
    "\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=512,               # batch_size could be smaller\n",
    "    num_workers=0)                                                                   # Increasing num_workers slow down the training because it does not use GPU at all\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=512,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7290, -0.1825, -1.7822,  ...,  1.7153, -1.7731,  1.8945],\n",
      "        [-1.5605,  0.3168, -1.4323,  ...,  1.2409, -1.5663,  1.3875],\n",
      "        [ 1.4714, -0.2850,  1.1074,  ..., -1.2251,  1.4889, -1.1817],\n",
      "        ...,\n",
      "        [ 0.8358, -0.0945,  0.8934,  ..., -0.7314,  0.8505, -1.0485],\n",
      "        [-0.8206,  0.8322, -0.6906,  ...,  1.3263, -0.8403,  1.2101],\n",
      "        [ 0.2861,  1.0838,  0.4119,  ...,  0.6527,  0.2623,  0.4181]])\n",
      "tensor([[-0.5300, -2.0834, -0.7918,  ..., -0.8972, -0.5132, -0.4180],\n",
      "        [-0.9009, -1.6717, -1.1690,  ..., -0.1349, -0.8938,  0.5568],\n",
      "        [ 1.4466, -0.0538,  1.5691,  ..., -0.8411,  1.4696, -1.2969],\n",
      "        ...,\n",
      "        [ 1.3805,  0.5386,  1.6099,  ..., -0.4543,  1.3940, -0.9163],\n",
      "        [ 2.4348, -0.6237,  1.6922,  ..., -2.1980,  2.4790, -2.2859],\n",
      "        [-0.1717,  0.7099, -0.0818,  ...,  0.8580, -0.1884,  0.6773]])\n",
      "tensor([[ 0.2020, -0.7115,  0.1271,  ..., -0.5994,  0.2110, -0.5918],\n",
      "        [-0.0059, -0.2115, -0.0668,  ..., -0.0512, -0.0085,  0.0518],\n",
      "        [-1.1355, -0.5121, -1.2322,  ...,  0.3827, -1.1245,  0.7504],\n",
      "        ...,\n",
      "        [-0.9340, -0.2810, -1.0251,  ...,  1.0621, -0.9535,  1.3148],\n",
      "        [ 0.1063,  0.2683,  0.1440,  ..., -0.0209,  0.1085, -0.2021],\n",
      "        [-2.6043,  0.3627, -2.1220,  ...,  1.7895, -2.6160,  2.1416]])\n",
      "tensor([[-0.3388,  1.8408, -0.1090,  ...,  1.3557, -0.3607,  0.9889],\n",
      "        [ 1.3040,  1.9205,  3.1201,  ...,  0.7790,  1.2458,  0.1796],\n",
      "        [-0.6991,  1.7344, -0.4734,  ...,  1.8379, -0.7287,  1.5371],\n",
      "        ...,\n",
      "        [ 1.0664,  0.9639,  1.3039,  ...,  0.1256,  1.0458, -0.1783],\n",
      "        [-1.6152,  0.5406, -1.4470,  ...,  1.2873, -1.6243,  1.5087],\n",
      "        [-0.8205, -1.0797, -0.9529,  ..., -0.1304, -0.8038,  0.2629]])\n",
      "tensor([[-0.1871,  0.1163, -0.2030,  ...,  0.3484, -0.1953,  0.4197],\n",
      "        [-1.9282, -1.7085, -2.7503,  ..., -0.2147, -1.8141,  0.5657],\n",
      "        [ 1.6561, -1.7856,  1.1190,  ..., -2.4656,  1.7176, -2.5107],\n",
      "        ...,\n",
      "        [ 0.1240, -0.1066,  0.0865,  ..., -0.5805,  0.1322, -0.5656],\n",
      "        [-1.1004, -0.5606, -1.3509,  ..., -0.8110, -1.0557, -0.2400],\n",
      "        [-2.3294, -1.0607, -2.6494,  ...,  0.9331, -2.2621,  1.4495]])\n",
      "tensor([[-1.2725, -1.3560, -1.4715,  ..., -0.4136, -1.2265,  0.2324],\n",
      "        [ 0.2726, -0.1055,  0.2604,  ..., -0.3200,  0.2767, -0.4037],\n",
      "        [ 0.0784, -0.8434, -0.0943,  ..., -1.1949,  0.0973, -1.0764],\n",
      "        ...,\n",
      "        [ 1.2081,  0.9339,  1.4344,  ..., -0.0339,  1.1875, -0.3515],\n",
      "        [ 1.1289,  0.6457,  1.3153,  ..., -0.1511,  1.1182, -0.5080],\n",
      "        [-1.1617,  1.2852, -0.9418,  ...,  2.0244, -1.2031,  1.9376]])\n",
      "tensor([[ 1.3987, -0.1906,  1.2403,  ..., -0.6114,  1.3924, -0.7222],\n",
      "        [-1.6078, -1.1778, -2.0383,  ...,  0.6294, -1.5989,  1.2185],\n",
      "        [ 0.4551, -0.6526,  0.3639,  ..., -0.7559,  0.4651, -0.7714],\n",
      "        ...,\n",
      "        [-0.3549,  0.6266, -0.2641,  ...,  0.3552, -0.3575,  0.3595],\n",
      "        [ 0.6362, -0.3029,  0.6720,  ..., -0.6820,  0.6502, -0.9269],\n",
      "        [ 2.4475, -0.4124,  2.3141,  ..., -1.0381,  2.4183, -1.3041]])\n",
      "tensor([[ 2.9108, -0.6557,  1.9890,  ..., -1.8382,  2.9180, -1.9071],\n",
      "        [ 0.1885,  0.1365,  0.2005,  ..., -0.1354,  0.1922, -0.2667],\n",
      "        [ 0.1587, -1.0545,  0.0785,  ..., -0.7173,  0.1676, -0.5293],\n",
      "        ...,\n",
      "        [ 1.4645,  0.9325,  1.8647,  ...,  0.1921,  1.4132, -0.1190],\n",
      "        [ 1.2970, -1.3034,  0.9128,  ..., -1.5339,  1.3310, -1.4931],\n",
      "        [-2.5630,  0.0574, -2.1333,  ...,  2.0786, -2.5857,  2.3142]])\n",
      "tensor([[ 1.6956, -0.4829,  1.4646,  ..., -0.9308,  1.6994, -1.0523],\n",
      "        [-0.1497,  0.5208, -0.0723,  ...,  0.1572, -0.1504,  0.0776],\n",
      "        [ 0.8126,  0.7227,  0.9107,  ...,  0.1571,  0.7949, -0.0750],\n",
      "        ...,\n",
      "        [-1.4106,  0.5814, -1.2664,  ...,  1.4496, -1.4338,  1.5557],\n",
      "        [-0.4861,  0.0064, -0.5092,  ...,  0.5575, -0.4952,  0.6921],\n",
      "        [-0.0593,  1.3126,  0.1377,  ...,  0.7906, -0.0698,  0.4424]])\n",
      "tensor([[ 0.2499,  1.2286,  0.4382,  ...,  0.7003,  0.2346,  0.3597],\n",
      "        [ 0.0554,  0.3985,  0.0756,  ...,  0.2358,  0.0460,  0.2188],\n",
      "        [ 0.3039,  0.7025,  0.3991,  ...,  0.2370,  0.2965,  0.0300],\n",
      "        ...,\n",
      "        [ 2.4251, -0.3371,  1.7513,  ..., -1.8156,  2.4546, -1.9481],\n",
      "        [-1.1340, -1.8389, -1.4767,  ...,  0.0348, -1.1220,  0.7326],\n",
      "        [-0.3463,  0.8507, -0.2517,  ...,  0.7581, -0.3583,  0.6651]])\n",
      "tensor([[ 0.8210, -0.8412,  0.5857,  ..., -1.6604,  0.8473, -1.6533],\n",
      "        [-0.1879,  1.2487, -0.0198,  ...,  0.8996, -0.2003,  0.6589],\n",
      "        [-2.0655, -0.8292, -2.3056,  ...,  0.7633, -1.9969,  1.2946],\n",
      "        ...,\n",
      "        [-1.6783,  0.4750, -1.5093,  ...,  1.5783, -1.7044,  1.7084],\n",
      "        [-0.1056, -0.3117, -0.1796,  ..., -0.1739, -0.1070,  0.0093],\n",
      "        [ 0.1554, -0.1702,  0.2061,  ..., -0.4836,  0.1682, -0.7610]])\n",
      "tensor([[-0.3311,  0.0352, -0.3874,  ...,  0.1207, -0.3339,  0.3569],\n",
      "        [-0.7734, -0.4677, -0.8631,  ...,  0.1763, -0.7687,  0.4988],\n",
      "        [-0.3564, -0.3715, -0.4202,  ...,  0.1869, -0.3576,  0.3620],\n",
      "        ...,\n",
      "        [ 0.5621, -0.4899,  0.5723,  ..., -0.7196,  0.5749, -0.9512],\n",
      "        [ 1.2769,  2.4338,  3.3132,  ...,  0.7417,  1.2302,  0.0962],\n",
      "        [ 0.9675,  0.2587,  1.1096,  ..., -0.5231,  0.9795, -0.9729]])\n",
      "tensor([[-1.3526, -0.8438, -1.5422,  ...,  1.0014, -1.3545,  1.3262],\n",
      "        [-0.9778, -0.0806, -0.9928,  ...,  0.6604, -0.9795,  0.9031],\n",
      "        [ 1.4065, -1.0322,  1.0220,  ..., -2.4085,  1.4624, -2.4920],\n",
      "        ...,\n",
      "        [ 0.1681,  0.0612,  0.1415,  ...,  0.1231,  0.1593,  0.1570],\n",
      "        [ 1.3938,  1.6960,  2.3638,  ...,  0.4070,  1.3454, -0.0662],\n",
      "        [-0.0358, -0.6146, -0.1862,  ..., -0.9617, -0.0163, -0.8670]])\n",
      "tensor([[-0.2956,  0.5126, -0.2530,  ...,  0.6693, -0.3073,  0.6376],\n",
      "        [ 0.2885,  0.9838,  0.4047,  ...,  0.3309,  0.2779,  0.0893],\n",
      "        [-0.6847, -1.2670, -0.8223,  ..., -0.1359, -0.6732,  0.3087],\n",
      "        ...,\n",
      "        [ 1.1546,  1.3612,  1.7817,  ...,  0.2849,  1.1379, -0.2696],\n",
      "        [ 1.0155,  0.5902,  1.1100,  ...,  0.0091,  0.9966, -0.2061],\n",
      "        [ 0.7617,  0.2805,  0.7904,  ..., -0.2251,  0.7570, -0.4078]])\n",
      "tensor([[ 0.3645,  1.6741,  0.5935,  ...,  0.6998,  0.3454,  0.3029],\n",
      "        [-1.4216,  0.9653, -1.1827,  ...,  1.8926, -1.4608,  1.8802],\n",
      "        [-0.6218, -0.6597, -0.7169,  ...,  0.2009, -0.6208,  0.5263],\n",
      "        ...,\n",
      "        [ 0.9638,  0.1302,  1.0033,  ..., -0.3687,  0.9630, -0.6595],\n",
      "        [-1.0725,  0.4626, -0.9924,  ...,  1.1670, -1.0820,  1.2211],\n",
      "        [-1.3247, -1.8796, -1.7083,  ...,  0.5978, -1.3119,  1.1039]])\n",
      "tensor([[ 0.0109, -0.5515, -0.1451,  ..., -0.8986,  0.0241, -0.7559],\n",
      "        [-0.6323,  0.2752, -0.6247,  ...,  0.5706, -0.6372,  0.6941],\n",
      "        [-0.0937, -0.5692, -0.2472,  ..., -1.4528, -0.0692, -1.3582],\n",
      "        ...,\n",
      "        [-0.5550, -0.4353, -0.6315,  ...,  0.4876, -0.5656,  0.7338],\n",
      "        [ 0.1660,  0.5654,  0.2624,  ...,  0.1290,  0.1676, -0.1125],\n",
      "        [ 1.1155,  2.6541,  2.1414,  ...,  0.8451,  1.0611,  0.3034]])\n",
      "tensor([[-1.3536, -2.3127, -2.0706,  ..., -0.2477, -1.3160,  0.5329],\n",
      "        [-0.6874,  0.3041, -0.6077,  ...,  0.2375, -0.6780,  0.2910],\n",
      "        [-0.0970, -0.5311, -0.1746,  ..., -0.1782, -0.0989,  0.0345],\n",
      "        ...,\n",
      "        [ 1.0591,  0.2038,  1.0540,  ..., -0.4803,  1.0622, -0.6976],\n",
      "        [-0.7811,  0.1883, -0.7849,  ...,  0.9757, -0.7939,  1.0631],\n",
      "        [ 0.5676,  0.6880,  0.7632,  ...,  0.1852,  0.5619, -0.2042]])\n",
      "tensor([[-2.7449,  1.0714, -1.6729,  ...,  2.5175, -2.7883,  2.5617],\n",
      "        [-0.7358,  0.6982, -0.5924,  ...,  0.8409, -0.7414,  0.7893],\n",
      "        [ 2.2284, -1.8601,  1.3913,  ..., -1.8968,  2.2570, -1.9007],\n",
      "        ...,\n",
      "        [-1.0721, -0.2398, -1.0838,  ...,  0.2576, -1.0570,  0.6189],\n",
      "        [-0.0409, -1.4045, -0.1648,  ..., -0.7006, -0.0356, -0.3591],\n",
      "        [-0.5866, -0.4511, -0.7580,  ..., -1.1064, -0.5595, -0.7678]])\n",
      "tensor([[-1.8517, -1.5220, -2.3642,  ...,  1.1435, -1.8639,  1.6400],\n",
      "        [-0.4773, -0.8146, -0.5913,  ...,  0.0347, -0.4807,  0.4003],\n",
      "        [-0.0383,  0.6963,  0.0240,  ...,  0.6592, -0.0541,  0.5716],\n",
      "        ...,\n",
      "        [ 0.8727,  0.8063,  1.0690,  ...,  0.0034,  0.8672, -0.3919],\n",
      "        [-1.2411, -0.3331, -1.3086,  ...,  0.6920, -1.2432,  1.0278],\n",
      "        [-0.1524, -1.9586, -0.3770,  ..., -0.9631, -0.1365, -0.5815]])\n",
      "tensor([[-1.9343,  0.0310, -1.9219,  ...,  0.8769, -1.9070,  1.3280],\n",
      "        [ 0.6895, -0.0666,  0.6209,  ..., -0.5262,  0.6915, -0.6318],\n",
      "        [ 0.3113, -0.0434,  0.3006,  ..., -0.2133,  0.3138, -0.2939],\n",
      "        ...,\n",
      "        [-0.2140, -0.5177, -0.2119,  ..., -0.7401, -0.1942, -0.8144],\n",
      "        [-0.3057, -0.6042, -0.3980,  ..., -0.2793, -0.3018, -0.0045],\n",
      "        [ 0.3184, -1.0200,  0.2079,  ..., -0.8826,  0.3288, -0.8324]])\n",
      "tensor([[-1.6011, -1.0743, -2.0459,  ...,  1.1845, -1.6279,  1.6971],\n",
      "        [ 0.7208, -0.3472,  0.5241,  ..., -0.9735,  0.7260, -0.7814],\n",
      "        [-0.2238, -0.7610, -0.2214,  ..., -0.8552, -0.2003, -0.9458],\n",
      "        ...,\n",
      "        [ 0.5886, -0.2630,  0.5064,  ..., -0.5731,  0.5918, -0.6273],\n",
      "        [-1.4981, -0.5277, -1.9166,  ..., -0.5201, -1.4292,  0.2520],\n",
      "        [-0.8545,  0.1763, -0.8291,  ...,  0.7497, -0.8625,  0.9123]])\n",
      "tensor([[-0.0228, -0.0502,  0.0348,  ..., -0.6179, -0.0030, -0.9238],\n",
      "        [ 0.9924,  0.3997,  1.0289,  ..., -0.3290,  0.9839, -0.5059],\n",
      "        [ 1.2853,  0.2660,  1.2340,  ..., -0.5157,  1.2885, -0.7205],\n",
      "        ...,\n",
      "        [-1.9209, -0.4898, -2.0058,  ...,  1.1784, -1.9006,  1.4399],\n",
      "        [-1.0356, -1.4830, -1.2831,  ...,  0.3070, -1.0342,  0.8982],\n",
      "        [ 1.1225,  1.1753,  1.5593,  ...,  0.3579,  1.0869, -0.0088]])\n",
      "tensor([[ 0.1340,  1.0373,  0.2574,  ...,  0.5575,  0.1213,  0.3411],\n",
      "        [-0.7614,  3.0974, -0.3176,  ...,  2.3485, -0.7968,  1.7527],\n",
      "        [ 2.5236,  0.2355,  1.9583,  ..., -1.5412,  2.5268, -1.7183],\n",
      "        ...,\n",
      "        [-0.7123, -0.3394, -0.7584,  ..., -0.0350, -0.7026,  0.2960],\n",
      "        [-0.7385, -0.2835, -0.7326,  ...,  0.1151, -0.7303,  0.3781],\n",
      "        [-0.8367,  1.5030, -0.5805,  ...,  1.4370, -0.8522,  1.1938]])\n",
      "tensor([[ 0.0234, -1.4986, -0.1748,  ..., -2.8211,  0.0491, -2.7541],\n",
      "        [-0.5151, -0.1739, -0.4993,  ...,  0.0301, -0.5029,  0.0813],\n",
      "        [ 0.2624, -0.4660,  0.1022,  ..., -1.9270,  0.2889, -1.8378],\n",
      "        ...,\n",
      "        [-0.1180,  0.6770, -0.0487,  ...,  0.7993, -0.1330,  0.6738],\n",
      "        [-0.7001,  0.0368, -0.7140,  ...,  0.7437, -0.7092,  0.8648],\n",
      "        [-0.7296,  1.3291, -0.5445,  ...,  1.5523, -0.7542,  1.3461]])\n",
      "tensor([[ 1.2966, -0.4327,  0.9659,  ..., -1.2194,  1.3122, -1.1380],\n",
      "        [-0.5392,  0.6357, -0.4519,  ...,  0.7883, -0.5476,  0.7229],\n",
      "        [-0.8394, -0.7186, -0.9089,  ...,  0.0401, -0.8276,  0.4103],\n",
      "        ...,\n",
      "        [ 1.2299,  0.0705,  1.1343,  ..., -0.5635,  1.2614, -0.6939],\n",
      "        [-1.3373, -0.5387, -1.3918,  ..., -0.3802, -1.2787,  0.1003],\n",
      "        [-0.4754,  0.7026, -0.3592,  ...,  0.7078, -0.4837,  0.6531]])\n",
      "tensor([[-0.4533,  0.7089, -0.3542,  ...,  1.0188, -0.4684,  0.8601],\n",
      "        [ 0.6210,  0.3359,  0.4800,  ..., -0.9799,  0.6345, -0.9340],\n",
      "        [-1.9078,  1.2272, -1.4182,  ...,  2.6316, -2.0394,  2.8650],\n",
      "        ...,\n",
      "        [ 0.0984, -0.1531,  0.0377,  ..., -0.3018,  0.1020, -0.2506],\n",
      "        [-0.9077, -0.7722, -1.0331,  ...,  0.3385, -0.9059,  0.7163],\n",
      "        [ 1.9929,  0.4469,  2.4168,  ..., -0.2497,  1.9340, -0.5447]])\n",
      "tensor([[-0.6588,  0.3586, -0.6072,  ...,  0.6019, -0.6587,  0.6200],\n",
      "        [-0.9232, -1.0259, -1.0210,  ..., -0.5158, -0.8933, -0.0904],\n",
      "        [ 0.4760,  1.9392,  0.8902,  ...,  1.0221,  0.4517,  0.4648],\n",
      "        ...,\n",
      "        [ 0.7508, -0.8698,  0.6291,  ..., -0.9854,  0.7667, -1.0532],\n",
      "        [ 0.8975,  0.2540,  0.8455,  ..., -0.2783,  0.8838, -0.3669],\n",
      "        [-1.3066,  0.1631, -1.3178,  ...,  1.0679, -1.3182,  1.3275]])\n",
      "tensor([[-1.1455,  2.5219, -0.7272,  ...,  2.2976, -1.1905,  2.0308],\n",
      "        [ 1.5139, -0.1603,  1.1722,  ..., -1.4231,  1.5599, -1.6342],\n",
      "        [-0.3655,  0.4244, -0.3028,  ...,  0.5995, -0.3748,  0.5775],\n",
      "        ...,\n",
      "        [-1.1985, -1.1113, -1.3541,  ...,  0.2917, -1.1777,  0.7361],\n",
      "        [ 0.7978,  0.5354,  0.8492,  ...,  0.1760,  0.7736,  0.0314],\n",
      "        [-0.0095,  1.7559,  0.2022,  ...,  1.0479, -0.0313,  0.7121]])\n",
      "tensor([[ 1.2398,  1.4567,  1.8545,  ...,  0.5062,  1.1894,  0.1060],\n",
      "        [-0.3397, -0.5375, -0.3296,  ..., -0.3499, -0.3271, -0.3199],\n",
      "        [ 0.3544, -1.4756,  0.1293,  ..., -1.1578,  0.3634, -0.9354],\n",
      "        ...,\n",
      "        [ 0.0645,  0.6035,  0.1616,  ...,  0.2600,  0.0579,  0.0604],\n",
      "        [-1.0365,  0.1375, -1.0373,  ...,  1.0754, -1.0503,  1.2267],\n",
      "        [ 1.9399, -0.2856,  1.3993,  ..., -1.2783,  1.9348, -1.2506]])\n",
      "tensor([[-0.3776,  1.8972, -0.1188,  ...,  1.4409, -0.3984,  1.0265],\n",
      "        [ 0.5235,  0.2052,  0.5647,  ..., -0.4502,  0.5271, -0.6387],\n",
      "        [ 2.2399, -1.4905,  1.4250,  ..., -1.7124,  2.2563, -1.6925],\n",
      "        ...,\n",
      "        [ 0.4465, -0.2122,  0.4591,  ..., -0.5625,  0.4559, -0.7951],\n",
      "        [ 1.3515, -0.3922,  1.0018,  ..., -1.0877,  1.3511, -0.9489],\n",
      "        [-1.9645,  0.5690, -1.6747,  ...,  1.7252, -2.0140,  1.9365]])\n",
      "tensor([[-1.2568,  0.9292, -1.0722,  ...,  1.8521, -1.2925,  1.8287],\n",
      "        [-0.0837, -1.3824, -0.1914,  ..., -0.8636, -0.0679, -0.7247],\n",
      "        [ 0.1163, -1.6361, -0.0875,  ..., -1.5605,  0.1400, -1.4112],\n",
      "        ...,\n",
      "        [ 0.7445,  0.9029,  0.8845,  ...,  0.1472,  0.7316, -0.0863],\n",
      "        [ 0.2592,  1.3346,  0.4509,  ...,  0.6333,  0.2426,  0.3510],\n",
      "        [ 0.9952,  1.1861,  1.3537,  ...,  0.5582,  0.9552,  0.1854]])\n",
      "tensor([[-1.1037,  2.3122, -0.6687,  ...,  2.1339, -1.1344,  1.7435],\n",
      "        [-1.0701,  0.1375, -1.0019,  ..., -0.1202, -1.0372,  0.1925],\n",
      "        [-0.1166, -0.5381, -0.2060,  ...,  0.0236, -0.1229,  0.3116],\n",
      "        ...,\n",
      "        [ 1.2650,  0.7816,  1.6290,  ...,  0.1509,  1.2365, -0.2484],\n",
      "        [-2.0744,  0.3092, -1.7118,  ...,  1.0170, -1.9608,  1.2683],\n",
      "        [-0.7960, -2.2102, -1.1113,  ..., -2.4022, -0.7546, -2.0563]])\n",
      "tensor([[ 0.9125, -1.0888,  0.6487,  ..., -2.6770,  0.9461, -2.6940],\n",
      "        [-0.4845, -0.6106, -0.5481,  ..., -0.4050, -0.4691, -0.2535],\n",
      "        [ 0.0830,  0.7796,  0.2321,  ...,  0.2735,  0.0791, -0.0334],\n",
      "        ...,\n",
      "        [ 0.3656,  1.3322,  0.5781,  ...,  0.5506,  0.3508,  0.1735],\n",
      "        [-0.2872, -1.4899, -0.3979,  ..., -0.9053, -0.2647, -0.7499],\n",
      "        [ 0.9368,  0.3363,  1.0423,  ..., -0.1402,  0.9327, -0.4787]])\n",
      "tensor([[ 0.5664, -0.1955,  0.5055,  ..., -0.6010,  0.5725, -0.7416],\n",
      "        [-0.0591, -1.1481, -0.1753,  ..., -0.3044, -0.0618,  0.0561],\n",
      "        [-0.3047, -0.1803, -0.3050,  ...,  0.0794, -0.3019,  0.0889],\n",
      "        ...,\n",
      "        [-0.5771, -0.5558, -0.7503,  ..., -0.8883, -0.5506, -0.5896],\n",
      "        [ 0.1995,  1.0592,  0.3328,  ...,  0.6990,  0.1807,  0.4536],\n",
      "        [-0.8628,  1.6318, -0.6090,  ...,  1.6820, -0.8879,  1.4327]])\n",
      "tensor([[ 0.8998,  0.2506,  0.8363,  ..., -0.5348,  0.8962, -0.5768],\n",
      "        [ 1.3773,  1.3054,  2.2117,  ...,  0.3177,  1.3346, -0.1334],\n",
      "        [-0.5534, -0.9646, -0.7432,  ..., -0.9317, -0.5337, -0.5247],\n",
      "        ...,\n",
      "        [-1.3392,  1.7097, -1.0125,  ...,  2.1613, -1.3771,  2.0542],\n",
      "        [ 0.6205, -0.0532,  0.5608,  ..., -0.2318,  0.6152, -0.2900],\n",
      "        [-2.8540, -1.3572, -3.2568,  ...,  1.2722, -2.8256,  1.8692]])\n",
      "tensor([[-0.8764,  0.4935, -0.7919,  ...,  1.2241, -0.8902,  1.1860],\n",
      "        [ 0.2573,  0.0419,  0.2198,  ..., -0.5134,  0.2641, -0.5961],\n",
      "        [-0.0150, -1.0052, -0.1912,  ..., -1.1593,  0.0020, -0.9339],\n",
      "        ...,\n",
      "        [ 0.0489, -0.8514, -0.1199,  ..., -0.9514,  0.0574, -0.6525],\n",
      "        [-0.2718,  0.5988, -0.1724,  ...,  0.5222, -0.2743,  0.3662],\n",
      "        [-1.2116,  1.4211, -0.9190,  ...,  1.9372, -1.2408,  1.7365]])\n",
      "tensor([[-1.3093, -0.4090, -1.4663,  ...,  1.4815, -1.3480,  1.7895],\n",
      "        [ 0.4268,  0.6519,  0.4957,  ...,  0.3520,  0.4104,  0.1859],\n",
      "        [ 0.2061, -0.9045,  0.0264,  ..., -1.0531,  0.2179, -0.8175],\n",
      "        ...,\n",
      "        [ 1.4597, -2.3226,  0.9530,  ..., -2.2896,  1.5098, -2.2860],\n",
      "        [-0.6347, -1.5841, -0.8085,  ...,  0.0487, -0.6353,  0.5653],\n",
      "        [ 1.2377, -0.3113,  1.3093,  ..., -0.6831,  1.2499, -1.0037]])\n",
      "tensor([[ 1.7941, -1.2752,  1.2149,  ..., -1.6552,  1.8181, -1.6271],\n",
      "        [ 0.8221, -0.1986,  0.7246,  ..., -0.6402,  0.8259, -0.6652],\n",
      "        [ 0.1412,  0.7628,  0.2843,  ...,  0.3068,  0.1378, -0.0271],\n",
      "        ...,\n",
      "        [ 0.3226, -1.9781,  0.0926,  ..., -1.3986,  0.3391, -1.2430],\n",
      "        [ 0.4296, -0.9098,  0.2255,  ..., -1.0690,  0.4376, -0.8466],\n",
      "        [ 0.5813, -0.1950,  0.5029,  ..., -0.5004,  0.5831, -0.5570]])\n",
      "tensor([[ 0.5487, -2.4819,  0.2845,  ..., -2.0599,  0.5756, -1.9891],\n",
      "        [ 1.6829,  0.6002,  2.0312,  ..., -0.4140,  1.6756, -0.8192],\n",
      "        [-0.5033,  2.4722, -0.1735,  ...,  1.4921, -0.5228,  1.0430],\n",
      "        ...,\n",
      "        [-0.6985,  1.0842, -0.5634,  ...,  1.3962, -0.7203,  1.2662],\n",
      "        [ 0.8270, -0.1216,  0.7350,  ..., -0.6816,  0.8357, -0.8037],\n",
      "        [-1.2039, -1.3831, -1.4681,  ...,  0.2342, -1.1931,  0.8187]])\n",
      "tensor([[ 0.5172,  0.4825,  0.5659,  ..., -0.1118,  0.5136, -0.3302],\n",
      "        [-1.4118,  0.4935, -1.2884,  ...,  1.2864, -1.4243,  1.4130],\n",
      "        [-1.7290,  0.6060, -1.5117,  ...,  1.2689, -1.7532,  1.5413],\n",
      "        ...,\n",
      "        [-1.0737, -0.2738, -1.1690,  ...,  1.1212, -1.0937,  1.3801],\n",
      "        [-1.4428, -1.8967, -2.1150,  ..., -0.8998, -1.3694, -0.2367],\n",
      "        [-2.7787,  0.1651, -2.2327,  ...,  1.9535, -2.7555,  2.1851]])\n",
      "tensor([[-1.3787, -1.4015, -1.7786,  ...,  0.5996, -1.3804,  1.1872],\n",
      "        [-1.6492,  1.5471, -1.1289,  ...,  1.8873, -1.6714,  1.7568],\n",
      "        [ 0.7320,  1.8953,  1.1017,  ...,  0.7631,  0.7024,  0.3117],\n",
      "        ...,\n",
      "        [-0.4444, -0.3008, -0.4911,  ...,  0.0877, -0.4443,  0.3666],\n",
      "        [ 2.0255, -0.0047,  1.8959,  ..., -0.7214,  2.0004, -0.9669],\n",
      "        [-0.9216, -1.7003, -1.1419,  ...,  0.2963, -0.9207,  0.8213]])\n",
      "tensor([[ 0.7164,  1.4127,  1.0518,  ...,  0.6468,  0.6891,  0.1912],\n",
      "        [-0.5452, -0.4068, -0.5827,  ...,  0.0358, -0.5423,  0.2622],\n",
      "        [-0.3901,  1.3668, -0.1542,  ...,  1.0264, -0.4009,  0.7055],\n",
      "        ...,\n",
      "        [-1.0855,  2.0898, -0.6992,  ...,  2.5755, -1.1208,  1.7760],\n",
      "        [ 1.7430, -0.0639,  1.6182,  ..., -0.7429,  1.7413, -0.9866],\n",
      "        [-0.1266, -2.0464, -0.3607,  ..., -0.8513, -0.1182, -0.4176]])\n",
      "tensor([[ 4.5677e-01, -6.9398e-01,  2.5792e-01,  8.0979e-01, -1.1577e+00,\n",
      "         -8.9502e-01,  4.6070e-01, -6.0003e-01],\n",
      "        [ 5.2010e-01,  3.5702e-02,  4.5809e-01,  5.3690e-01, -2.1315e-02,\n",
      "         -2.8098e-01,  5.1039e-01, -2.3048e-01],\n",
      "        [-3.1671e-01, -1.0489e+00, -4.2814e-01,  1.8315e-02, -4.2988e-01,\n",
      "         -3.1246e-01, -3.1237e-01, -4.0536e-02],\n",
      "        [-6.6989e-03,  2.7926e-01,  3.4704e-02, -3.5242e-01,  5.6999e-01,\n",
      "          1.4662e-01, -1.1299e-02,  9.3962e-02],\n",
      "        [ 3.0266e-01,  1.3209e+00,  5.2324e-01, -1.8917e-01,  1.6419e+00,\n",
      "          6.3988e-01,  2.8538e-01,  3.0161e-01],\n",
      "        [ 1.0967e+00,  1.3132e+00,  1.4393e+00,  2.3541e-01,  1.4193e+00,\n",
      "          3.3972e-01,  1.0606e+00, -8.6063e-03],\n",
      "        [ 1.4151e+00, -1.2904e+00,  1.0057e+00,  2.4269e+00, -6.1804e-01,\n",
      "         -2.2916e+00,  1.4670e+00, -2.3415e+00],\n",
      "        [-7.5863e-01,  7.4229e-01, -6.6182e-01, -1.0842e+00, -7.1677e-02,\n",
      "          1.2046e+00, -7.7546e-01,  1.1430e+00],\n",
      "        [ 1.0832e+00,  1.0059e+00,  1.3334e+00, -4.5899e-03,  1.3012e+00,\n",
      "          3.8832e-01,  1.0474e+00,  7.5263e-02],\n",
      "        [ 9.9803e-01,  1.1793e+00,  1.3653e+00,  3.9332e-01,  1.8998e+00,\n",
      "          3.3666e-01,  9.7631e-01, -1.3315e-01],\n",
      "        [ 4.7782e-01,  2.5527e-01,  4.7854e-01, -2.9001e-03,  4.5866e-01,\n",
      "          1.5188e-02,  4.6952e-01, -4.8617e-02],\n",
      "        [-9.4761e-01,  3.0227e-01, -9.0911e-01, -1.0402e+00, -3.8079e-01,\n",
      "          8.2134e-01, -9.5359e-01,  9.7767e-01],\n",
      "        [ 5.7313e-01,  1.3354e-01,  5.8162e-01,  3.4236e-01,  6.5250e-01,\n",
      "         -2.7462e-01,  5.6993e-01, -4.2213e-01],\n",
      "        [-4.6885e-01,  1.5412e+00, -2.5681e-01, -8.6594e-01,  8.3650e-01,\n",
      "          1.3328e+00, -4.8769e-01,  1.0134e+00],\n",
      "        [ 9.0237e-03,  1.4182e-01,  8.0167e-02,  9.7758e-02,  1.0044e+00,\n",
      "         -1.5446e-01,  1.2997e-02, -2.6410e-01],\n",
      "        [ 1.4736e+00,  1.7490e+00,  2.6832e+00,  5.3921e-01,  2.1248e+00,\n",
      "          4.4374e-01,  1.4281e+00, -1.0633e-01],\n",
      "        [ 2.0386e-01, -9.7458e-01,  1.5794e-02,  9.5013e-01, -1.2632e+00,\n",
      "         -1.0699e+00,  2.1469e-01, -8.1701e-01],\n",
      "        [-1.5466e+00, -1.5345e+00, -1.9479e+00, -7.5007e-01, -1.5480e+00,\n",
      "          8.7531e-02, -1.5034e+00,  7.2885e-01],\n",
      "        [ 1.6512e+00,  7.8727e-01,  2.0744e+00,  7.7689e-01,  1.1446e+00,\n",
      "         -1.2837e-01,  1.6150e+00, -4.5754e-01],\n",
      "        [-3.4816e-02,  1.1704e+00,  1.2115e-01, -5.5124e-01,  9.7791e-01,\n",
      "          1.0227e+00, -5.4877e-02,  7.3635e-01],\n",
      "        [ 1.3799e+00, -3.9568e-01,  1.2046e+00,  9.8535e-01,  2.7280e-01,\n",
      "         -7.4596e-01,  1.3749e+00, -8.0333e-01],\n",
      "        [ 8.7009e-02, -1.4986e-01,  1.2416e-01,  9.6755e-02,  8.7168e-01,\n",
      "         -4.2329e-01,  9.6297e-02, -5.2436e-01],\n",
      "        [-1.3656e+00, -2.0790e+00, -2.0365e+00, -3.2605e-01, -2.6518e+00,\n",
      "         -3.9647e-01, -1.3293e+00,  3.7490e-01],\n",
      "        [ 4.4367e-01,  4.5287e-01,  5.0395e-01,  1.7611e-01,  8.3896e-01,\n",
      "         -1.2117e-01,  4.4156e-01, -3.7620e-01],\n",
      "        [ 3.6375e-01,  1.1233e+00,  5.5642e-01, -1.4983e-01,  1.5507e+00,\n",
      "          5.1547e-01,  3.4861e-01,  1.6015e-01],\n",
      "        [ 4.5886e-02,  4.7462e-01,  7.9283e-02, -3.9450e-01,  3.4825e-01,\n",
      "          4.4693e-01,  3.3865e-02,  4.0023e-01],\n",
      "        [ 5.6200e-01,  1.0938e+00,  7.5191e-01,  2.6404e-02,  1.3637e+00,\n",
      "          3.5628e-01,  5.4634e-01,  5.7363e-02],\n",
      "        [-4.3040e-01, -9.1352e-01, -5.3999e-01, -2.5547e-01, -5.1382e-01,\n",
      "         -3.9780e-02, -4.3010e-01,  3.0501e-01],\n",
      "        [-3.4716e-02,  1.0594e+00,  1.2641e-01, -3.1754e-01,  1.1405e+00,\n",
      "          5.3803e-01, -4.0233e-02,  2.2585e-01],\n",
      "        [-4.5352e-01,  3.0182e-02, -4.5563e-01, -4.3337e-01, -4.7998e-02,\n",
      "          2.4896e-01, -4.5417e-01,  3.3881e-01],\n",
      "        [ 1.2962e-01,  1.3025e-02,  1.2445e-01,  1.1503e-01,  3.8744e-01,\n",
      "         -2.0211e-01,  1.3276e-01, -2.8748e-01],\n",
      "        [ 6.4783e-01, -1.0898e+00,  5.2524e-01,  1.2556e+00,  5.2306e-02,\n",
      "         -1.1319e+00,  6.6314e-01, -1.1461e+00],\n",
      "        [ 3.3937e-01, -1.4313e+00,  1.3332e-01,  2.1497e+00, -1.0301e+00,\n",
      "         -2.1562e+00,  3.6806e-01, -2.0911e+00],\n",
      "        [ 9.5448e-01,  2.7734e-02,  8.7355e-01,  7.2505e-01,  1.7125e-01,\n",
      "         -5.1438e-01,  9.5140e-01, -6.4574e-01],\n",
      "        [-1.7688e+00, -2.3093e+00, -2.8831e+00, -4.9999e-01, -3.1940e+00,\n",
      "         -3.6694e-01, -1.6693e+00,  4.8479e-01],\n",
      "        [-7.2875e-01,  9.4665e-01, -6.0031e-01, -9.3896e-01,  5.6507e-02,\n",
      "          1.1845e+00, -7.4491e-01,  1.0949e+00],\n",
      "        [-7.5016e-01,  1.3901e+00, -5.3725e-01, -1.2284e+00,  4.1797e-01,\n",
      "          1.5036e+00, -7.7043e-01,  1.2360e+00],\n",
      "        [ 7.4391e-01,  1.0543e+00,  9.1883e-01,  1.8293e-01,  1.1681e+00,\n",
      "          2.7877e-01,  7.2786e-01, -1.2398e-02],\n",
      "        [-6.5888e-01, -1.8022e+00, -9.2036e-01,  2.3903e-01, -1.9823e+00,\n",
      "         -8.4573e-01, -6.3654e-01, -3.1762e-01],\n",
      "        [-7.4801e-01,  2.8778e-01, -7.2587e-01, -8.2124e-01, -2.6759e-01,\n",
      "          7.5646e-01, -7.5512e-01,  8.4164e-01],\n",
      "        [-8.8858e-01,  1.4873e+00, -6.4510e-01, -1.2047e+00,  3.0641e-01,\n",
      "          1.4004e+00, -9.0459e-01,  1.2410e+00],\n",
      "        [ 1.2841e+00,  4.1371e-01,  1.3366e+00,  4.4886e-01,  7.9293e-01,\n",
      "         -1.9919e-01,  1.2625e+00, -3.5229e-01],\n",
      "        [ 8.3152e-01,  6.8821e-01,  9.1449e-01,  2.2631e-01,  8.0631e-01,\n",
      "          1.2888e-01,  8.1266e-01, -6.4555e-02],\n",
      "        [ 1.5376e+00, -5.1397e-01,  1.1215e+00,  1.3568e+00, -7.3975e-01,\n",
      "         -1.2872e+00,  1.5494e+00, -1.2314e+00],\n",
      "        [ 1.2687e-01, -1.3802e+00, -7.5602e-02,  1.0280e+00, -1.3418e+00,\n",
      "         -1.1710e+00,  1.4060e-01, -9.3355e-01],\n",
      "        [-1.3577e+00, -1.0402e+00, -1.5990e+00, -8.3988e-01, -1.3741e+00,\n",
      "          2.6816e-01, -1.3365e+00,  7.9551e-01],\n",
      "        [ 5.4419e-01,  1.6842e+00,  8.1125e-01, -2.3051e-01,  1.5367e+00,\n",
      "          8.3886e-01,  5.1722e-01,  4.5769e-01],\n",
      "        [ 1.6297e-01, -1.3015e+00, -2.5531e-02,  1.4221e+00, -1.1259e+00,\n",
      "         -1.5112e+00,  1.8627e-01, -1.3853e+00],\n",
      "        [ 2.5602e-01, -9.2690e-02,  2.2313e-01,  5.2400e-01,  2.2079e-01,\n",
      "         -5.3995e-01,  2.6530e-01, -6.6651e-01],\n",
      "        [-7.0450e-01, -1.3581e+00, -9.4654e-01,  3.8938e-02, -1.9499e+00,\n",
      "         -5.5023e-01, -6.9025e-01,  5.0073e-02],\n",
      "        [ 1.7671e+00, -1.0284e-01,  1.5741e+00,  9.6764e-01,  3.1075e-01,\n",
      "         -7.4658e-01,  1.7518e+00, -9.2995e-01],\n",
      "        [ 5.8782e-01,  1.4324e+00,  8.4226e-01,  1.3505e-01,  1.6130e+00,\n",
      "          4.7678e-01,  5.7006e-01,  2.8408e-02],\n",
      "        [ 1.0448e-01, -1.0563e+00,  9.6416e-03,  7.7252e-01, -1.3609e-01,\n",
      "         -8.3911e-01,  1.1935e-01, -8.5112e-01],\n",
      "        [ 8.2317e-02, -7.8980e-01, -9.6796e-02,  1.0596e+00, -1.2749e+00,\n",
      "         -1.2489e+00,  9.9516e-02, -1.0499e+00],\n",
      "        [-1.6599e+00, -1.9897e-01, -1.7877e+00, -2.1214e+00, -1.5078e+00,\n",
      "          1.7494e+00, -1.7209e+00,  2.0341e+00],\n",
      "        [-5.6749e-01,  3.3529e-01, -5.3448e-01, -6.1577e-01, -9.9810e-02,\n",
      "          2.6760e-01, -5.6703e-01,  4.6780e-01],\n",
      "        [ 8.3826e-01,  9.2891e-01,  9.8851e-01,  4.1843e-01,  1.0226e+00,\n",
      "          1.1857e-01,  8.2549e-01, -1.2651e-01],\n",
      "        [ 6.7524e-01,  2.0787e-01,  6.5759e-01,  5.3522e-01,  4.4543e-01,\n",
      "         -1.6354e-01,  6.6444e-01, -2.4737e-01],\n",
      "        [-4.5570e-01, -1.1508e-01, -4.4907e-01, -4.2626e-01,  1.3027e-01,\n",
      "          1.7876e-01, -4.5448e-01,  2.4068e-01],\n",
      "        [ 1.9508e+00,  1.7616e-01,  1.8389e+00,  5.9048e-01,  3.7272e-01,\n",
      "         -4.4024e-01,  1.8824e+00, -6.0486e-01],\n",
      "        [-9.8918e-01,  1.0097e-01, -9.0390e-01, -5.5705e-01, -1.5766e-02,\n",
      "          1.2081e-01, -9.6811e-01,  3.7636e-01],\n",
      "        [-1.0123e+00,  6.7503e-01, -8.9640e-01, -1.3071e+00, -2.7949e-01,\n",
      "          1.4050e+00, -1.0317e+00,  1.3762e+00],\n",
      "        [ 5.1369e-01,  4.5627e-01,  5.4014e-01, -1.7272e-01,  5.2489e-01,\n",
      "          1.9949e-01,  4.9398e-01,  1.2281e-01],\n",
      "        [ 5.5838e-01,  8.8979e-01,  6.9289e-01,  2.6377e-01,  1.0323e+00,\n",
      "          5.1335e-02,  5.5438e-01, -2.5293e-01],\n",
      "        [-3.9881e-01,  6.1481e-01, -3.0639e-01, -6.5402e-01,  5.3099e-01,\n",
      "          6.5265e-01, -4.0376e-01,  5.5602e-01],\n",
      "        [ 5.3711e-01, -2.7353e-02,  5.2605e-01,  2.1365e-01,  5.2247e-01,\n",
      "         -3.1318e-01,  5.3930e-01, -4.3523e-01],\n",
      "        [-1.7713e+00,  5.3683e-01, -1.4649e+00, -1.2228e+00, -5.7902e-01,\n",
      "          9.2380e-01, -1.7484e+00,  1.2016e+00],\n",
      "        [-9.3991e-01, -1.4762e+00, -1.2031e+00, -1.0642e-01, -1.7708e+00,\n",
      "         -4.9757e-01, -9.1510e-01,  1.1391e-01],\n",
      "        [ 4.2221e-01, -3.6004e-02,  3.5615e-01,  2.8996e-01, -6.4366e-02,\n",
      "         -2.7653e-01,  4.1825e-01, -2.6571e-01],\n",
      "        [-2.4106e+00,  4.6104e-01, -1.8178e+00, -2.4587e+00, -1.0296e+00,\n",
      "          2.1159e+00, -2.4158e+00,  2.0995e+00],\n",
      "        [-4.5351e-01,  8.9187e-01, -3.0153e-01, -7.2194e-01,  7.9383e-01,\n",
      "          8.6852e-01, -4.6339e-01,  6.5697e-01],\n",
      "        [-5.2617e-01,  6.2167e-01, -3.6833e-01, -5.8624e-01,  9.5182e-01,\n",
      "          7.4980e-01, -5.3145e-01,  5.9396e-01],\n",
      "        [ 7.6784e-02,  4.5483e-01,  2.1608e-01,  5.2734e-02,  1.5907e+00,\n",
      "          2.3378e-01,  7.5307e-02, -7.7614e-02],\n",
      "        [ 3.3749e-01, -1.4072e+00,  2.0305e-01,  6.5309e-01, -1.7859e-01,\n",
      "         -7.9493e-01,  3.4338e-01, -5.4529e-01],\n",
      "        [-1.1321e+00,  1.7304e+00, -8.2377e-01, -1.5102e+00, -4.3184e-02,\n",
      "          1.8124e+00, -1.1604e+00,  1.6442e+00],\n",
      "        [-1.1606e+00, -9.4793e-01, -1.2277e+00, -2.0467e-02, -4.5813e-01,\n",
      "         -6.5955e-01, -1.1112e+00, -2.7989e-01],\n",
      "        [-2.8388e-01, -1.4027e+00, -4.2539e-01,  2.0399e-01, -5.5275e-01,\n",
      "         -4.5141e-01, -2.8227e-01,  5.1930e-02],\n",
      "        [ 8.8379e-01,  5.8791e-01,  1.0091e+00,  3.5328e-02,  1.1793e+00,\n",
      "          8.3401e-02,  8.6755e-01, -2.1636e-01],\n",
      "        [-7.6156e-01, -9.3101e-01, -9.8013e-01,  7.2625e-02, -1.8493e+00,\n",
      "         -7.3181e-01, -7.3210e-01, -2.9452e-01],\n",
      "        [-1.2753e+00,  6.1762e-01, -1.1483e+00, -1.2656e+00, -5.3623e-01,\n",
      "          1.1098e+00, -1.2814e+00,  1.2696e+00],\n",
      "        [ 6.9584e-01,  7.1788e-01,  8.1495e-01,  1.3811e-01,  1.0728e+00,\n",
      "          9.2162e-02,  6.8293e-01, -1.8176e-01],\n",
      "        [ 2.6169e-01,  1.1203e+00,  4.1734e-01, -1.1203e-02,  1.1617e+00,\n",
      "          5.4426e-01,  2.4904e-01,  2.2890e-01],\n",
      "        [-4.2936e-01,  1.4172e+00, -2.2485e-01, -7.4033e-01,  9.1333e-01,\n",
      "          9.0125e-01, -4.3782e-01,  6.3915e-01],\n",
      "        [ 5.5262e-01, -1.3453e-01,  3.9073e-01,  1.5970e+00, -9.2208e-01,\n",
      "         -1.8679e+00,  5.8021e-01, -1.8088e+00],\n",
      "        [-1.3718e+00, -1.7243e-01, -1.3584e+00, -2.9469e-01, -5.7133e-01,\n",
      "         -1.8931e-01, -1.3290e+00,  2.8647e-01],\n",
      "        [ 1.4804e+00,  4.3416e-01,  1.4255e+00,  6.9158e-01,  3.5297e-01,\n",
      "         -4.2975e-01,  1.4589e+00, -5.8146e-01],\n",
      "        [-1.2631e+00, -1.2357e+00, -1.4964e+00, -1.1178e+00, -1.2649e+00,\n",
      "          4.5718e-01, -1.2492e+00,  9.4669e-01],\n",
      "        [-1.6068e+00,  2.0615e-01, -1.5764e+00, -1.6435e+00, -1.1510e+00,\n",
      "          1.3157e+00, -1.6151e+00,  1.5520e+00],\n",
      "        [-1.1346e-01, -2.6276e+00, -3.5117e-01,  1.4414e+00, -1.4607e+00,\n",
      "         -1.7775e+00, -9.0076e-02, -1.5463e+00],\n",
      "        [-3.8826e-02, -6.5915e-01, -5.4022e-02,  1.9191e-01,  5.0152e-01,\n",
      "         -3.8564e-01, -3.2775e-02, -3.5032e-01],\n",
      "        [-3.6053e-01, -2.9205e-01, -3.7221e-01, -1.3384e-01,  1.2523e-01,\n",
      "         -1.2984e-01, -3.4953e-01, -8.9009e-02],\n",
      "        [-5.2408e-01,  9.1943e-01, -4.1225e-01, -7.6789e-01,  2.1860e-01,\n",
      "          9.2797e-01, -5.3751e-01,  8.4185e-01],\n",
      "        [ 6.8502e-01, -4.4223e-01,  5.8763e-01,  9.5449e-01,  8.3896e-02,\n",
      "         -7.6743e-01,  6.9246e-01, -8.2903e-01],\n",
      "        [ 1.5913e+00, -1.5754e+00,  1.0800e+00,  2.3575e+00, -7.1979e-01,\n",
      "         -1.9514e+00,  1.6349e+00, -1.9590e+00],\n",
      "        [ 6.3946e-01,  5.6295e-01,  6.9273e-01,  1.2682e-01,  6.7558e-01,\n",
      "          1.4851e-01,  6.2364e-01,  1.5077e-02],\n",
      "        [-1.9274e+00,  2.0287e+00, -1.1576e+00, -2.6706e+00, -4.1009e-01,\n",
      "          2.8862e+00, -2.0276e+00,  2.6981e+00]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(y)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BleveNet(\n",
      "  (fc1): Linear(in_features=11, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc5): Linear(in_features=128, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (mish): Mish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Define the NN architecture\n",
    "## NN with 3 hidden layer, s=[26, 256, 256, 256, 8]\n",
    "\n",
    "class BleveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BleveNet, self).__init__()\n",
    "        # The first hidden layer has 256 neurons\n",
    "        self.fc1 = nn.Linear(X_train_torch.shape[1], 256)\n",
    "        # The second hidden layer has 256 neurons\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        # The third hidden layer has 256 neurons\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        # The final layer has 8 output neuron\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 8)\n",
    "\n",
    "\n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Mish activation\n",
    "        self.mish = nn.Mish()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add third fully connected layer\n",
    "        x = self.fc3(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add fourth fully connected layer\n",
    "        x = self.fc4(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add final fully connected layers\n",
    "        output = self.fc5(x)\n",
    "       \n",
    "        return output\n",
    "\n",
    "# initialize the NN\n",
    "model = BleveNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.HuberLoss()        # This is the best loss function for my model\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)     # This is the best optimizer for my model \n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200 \tTraining Loss: 0.078495\n",
      "Epoch: 2/200 \tTraining Loss: 0.023879\n",
      "Epoch: 3/200 \tTraining Loss: 0.020733\n",
      "Epoch: 4/200 \tTraining Loss: 0.018966\n",
      "Epoch: 5/200 \tTraining Loss: 0.016620\n",
      "Epoch: 6/200 \tTraining Loss: 0.015690\n",
      "Epoch: 7/200 \tTraining Loss: 0.015347\n",
      "Epoch: 8/200 \tTraining Loss: 0.015341\n",
      "Epoch: 9/200 \tTraining Loss: 0.014642\n",
      "Epoch: 10/200 \tTraining Loss: 0.013157\n",
      "Epoch: 11/200 \tTraining Loss: 0.012930\n",
      "Epoch: 12/200 \tTraining Loss: 0.012844\n",
      "Epoch: 13/200 \tTraining Loss: 0.012289\n",
      "Epoch: 14/200 \tTraining Loss: 0.012912\n",
      "Epoch: 15/200 \tTraining Loss: 0.011364\n",
      "Epoch: 16/200 \tTraining Loss: 0.011578\n",
      "Epoch: 17/200 \tTraining Loss: 0.011783\n",
      "Epoch: 18/200 \tTraining Loss: 0.011517\n",
      "Epoch: 19/200 \tTraining Loss: 0.011187\n",
      "Epoch: 20/200 \tTraining Loss: 0.010974\n",
      "Epoch: 21/200 \tTraining Loss: 0.010349\n",
      "Epoch: 22/200 \tTraining Loss: 0.011515\n",
      "Epoch: 23/200 \tTraining Loss: 0.011119\n",
      "Epoch: 24/200 \tTraining Loss: 0.011643\n",
      "Epoch: 25/200 \tTraining Loss: 0.011250\n",
      "Epoch: 26/200 \tTraining Loss: 0.010567\n",
      "Epoch: 27/200 \tTraining Loss: 0.010377\n",
      "Epoch: 28/200 \tTraining Loss: 0.010489\n",
      "Epoch: 29/200 \tTraining Loss: 0.009958\n",
      "Epoch: 30/200 \tTraining Loss: 0.010506\n",
      "Epoch: 31/200 \tTraining Loss: 0.010015\n",
      "Epoch: 32/200 \tTraining Loss: 0.009929\n",
      "Epoch: 33/200 \tTraining Loss: 0.010685\n",
      "Epoch: 34/200 \tTraining Loss: 0.009942\n",
      "Epoch: 35/200 \tTraining Loss: 0.009816\n",
      "Epoch: 36/200 \tTraining Loss: 0.009640\n",
      "Epoch: 37/200 \tTraining Loss: 0.010020\n",
      "Epoch: 38/200 \tTraining Loss: 0.010135\n",
      "Epoch: 39/200 \tTraining Loss: 0.009715\n",
      "Epoch: 40/200 \tTraining Loss: 0.010201\n",
      "Epoch: 41/200 \tTraining Loss: 0.010232\n",
      "Epoch: 42/200 \tTraining Loss: 0.010091\n",
      "Epoch: 43/200 \tTraining Loss: 0.010258\n",
      "Epoch: 44/200 \tTraining Loss: 0.010409\n",
      "Epoch: 45/200 \tTraining Loss: 0.009762\n",
      "Epoch: 46/200 \tTraining Loss: 0.009935\n",
      "Epoch: 47/200 \tTraining Loss: 0.009567\n",
      "Epoch: 48/200 \tTraining Loss: 0.010412\n",
      "Epoch: 49/200 \tTraining Loss: 0.009807\n",
      "Epoch: 50/200 \tTraining Loss: 0.009362\n",
      "Epoch: 51/200 \tTraining Loss: 0.009644\n",
      "Epoch: 52/200 \tTraining Loss: 0.010229\n",
      "Epoch: 53/200 \tTraining Loss: 0.010487\n",
      "Epoch: 54/200 \tTraining Loss: 0.009801\n",
      "Epoch: 55/200 \tTraining Loss: 0.009206\n",
      "Epoch: 56/200 \tTraining Loss: 0.009751\n",
      "Epoch: 57/200 \tTraining Loss: 0.009520\n",
      "Epoch: 58/200 \tTraining Loss: 0.009631\n",
      "Epoch: 59/200 \tTraining Loss: 0.009457\n",
      "Epoch: 60/200 \tTraining Loss: 0.009879\n",
      "Epoch: 61/200 \tTraining Loss: 0.009609\n",
      "Epoch: 62/200 \tTraining Loss: 0.010127\n",
      "Epoch: 63/200 \tTraining Loss: 0.009808\n",
      "Epoch: 64/200 \tTraining Loss: 0.009428\n",
      "Epoch: 65/200 \tTraining Loss: 0.009375\n",
      "Epoch: 66/200 \tTraining Loss: 0.009389\n",
      "Epoch: 67/200 \tTraining Loss: 0.009297\n",
      "Epoch: 68/200 \tTraining Loss: 0.009461\n",
      "Epoch: 69/200 \tTraining Loss: 0.009137\n",
      "Epoch: 70/200 \tTraining Loss: 0.009749\n",
      "Epoch: 71/200 \tTraining Loss: 0.009770\n",
      "Epoch: 72/200 \tTraining Loss: 0.009013\n",
      "Epoch: 73/200 \tTraining Loss: 0.009298\n",
      "Epoch: 74/200 \tTraining Loss: 0.009002\n",
      "Epoch: 75/200 \tTraining Loss: 0.009410\n",
      "Epoch: 76/200 \tTraining Loss: 0.010077\n",
      "Epoch: 77/200 \tTraining Loss: 0.009318\n",
      "Epoch: 78/200 \tTraining Loss: 0.008816\n",
      "Epoch: 79/200 \tTraining Loss: 0.008821\n",
      "Epoch: 80/200 \tTraining Loss: 0.009177\n",
      "Epoch: 81/200 \tTraining Loss: 0.008702\n",
      "Epoch: 82/200 \tTraining Loss: 0.009162\n",
      "Epoch: 83/200 \tTraining Loss: 0.009570\n",
      "Epoch: 84/200 \tTraining Loss: 0.009544\n",
      "Epoch: 85/200 \tTraining Loss: 0.009215\n",
      "Epoch: 86/200 \tTraining Loss: 0.008887\n",
      "Epoch: 87/200 \tTraining Loss: 0.008953\n",
      "Epoch: 88/200 \tTraining Loss: 0.009326\n",
      "Epoch: 89/200 \tTraining Loss: 0.009601\n",
      "Epoch: 90/200 \tTraining Loss: 0.009550\n",
      "Epoch: 91/200 \tTraining Loss: 0.008846\n",
      "Epoch: 92/200 \tTraining Loss: 0.008724\n",
      "Epoch: 93/200 \tTraining Loss: 0.008933\n",
      "Epoch: 94/200 \tTraining Loss: 0.009205\n",
      "Epoch: 95/200 \tTraining Loss: 0.009770\n",
      "Epoch: 96/200 \tTraining Loss: 0.008614\n",
      "Epoch: 97/200 \tTraining Loss: 0.009210\n",
      "Epoch: 98/200 \tTraining Loss: 0.008632\n",
      "Epoch: 99/200 \tTraining Loss: 0.009076\n",
      "Epoch: 100/200 \tTraining Loss: 0.009541\n",
      "Epoch: 101/200 \tTraining Loss: 0.008906\n",
      "Epoch: 102/200 \tTraining Loss: 0.008942\n",
      "Epoch: 103/200 \tTraining Loss: 0.009019\n",
      "Epoch: 104/200 \tTraining Loss: 0.008571\n",
      "Epoch: 105/200 \tTraining Loss: 0.009349\n",
      "Epoch: 106/200 \tTraining Loss: 0.009158\n",
      "Epoch: 107/200 \tTraining Loss: 0.008728\n",
      "Epoch: 108/200 \tTraining Loss: 0.009149\n",
      "Epoch: 109/200 \tTraining Loss: 0.009822\n",
      "Epoch: 110/200 \tTraining Loss: 0.009423\n",
      "Epoch: 111/200 \tTraining Loss: 0.009120\n",
      "Epoch: 112/200 \tTraining Loss: 0.008997\n",
      "Epoch: 113/200 \tTraining Loss: 0.009142\n",
      "Epoch: 114/200 \tTraining Loss: 0.008542\n",
      "Epoch: 115/200 \tTraining Loss: 0.009561\n",
      "Epoch: 116/200 \tTraining Loss: 0.009173\n",
      "Epoch: 117/200 \tTraining Loss: 0.009820\n",
      "Epoch: 118/200 \tTraining Loss: 0.009143\n",
      "Epoch: 119/200 \tTraining Loss: 0.008678\n",
      "Epoch: 120/200 \tTraining Loss: 0.008841\n",
      "Epoch: 121/200 \tTraining Loss: 0.008706\n",
      "Epoch: 122/200 \tTraining Loss: 0.008497\n",
      "Epoch: 123/200 \tTraining Loss: 0.009305\n",
      "Epoch: 124/200 \tTraining Loss: 0.008792\n",
      "Epoch: 125/200 \tTraining Loss: 0.008580\n",
      "Epoch: 126/200 \tTraining Loss: 0.008453\n",
      "Epoch: 127/200 \tTraining Loss: 0.009217\n",
      "Epoch: 128/200 \tTraining Loss: 0.009271\n",
      "Epoch: 129/200 \tTraining Loss: 0.009082\n",
      "Epoch: 130/200 \tTraining Loss: 0.009236\n",
      "Epoch: 131/200 \tTraining Loss: 0.009380\n",
      "Epoch: 132/200 \tTraining Loss: 0.008828\n",
      "Epoch: 133/200 \tTraining Loss: 0.008551\n",
      "Epoch: 134/200 \tTraining Loss: 0.008756\n",
      "Epoch: 135/200 \tTraining Loss: 0.008839\n",
      "Epoch: 136/200 \tTraining Loss: 0.009081\n",
      "Epoch: 137/200 \tTraining Loss: 0.008865\n",
      "Epoch: 138/200 \tTraining Loss: 0.008941\n",
      "Epoch: 139/200 \tTraining Loss: 0.009383\n",
      "Epoch: 140/200 \tTraining Loss: 0.008564\n",
      "Epoch: 141/200 \tTraining Loss: 0.008740\n",
      "Epoch: 142/200 \tTraining Loss: 0.008707\n",
      "Epoch: 143/200 \tTraining Loss: 0.008846\n",
      "Epoch: 144/200 \tTraining Loss: 0.008840\n",
      "Epoch: 145/200 \tTraining Loss: 0.008893\n",
      "Epoch: 146/200 \tTraining Loss: 0.008806\n",
      "Epoch: 147/200 \tTraining Loss: 0.008913\n",
      "Epoch: 148/200 \tTraining Loss: 0.008566\n",
      "Epoch: 149/200 \tTraining Loss: 0.009143\n",
      "Epoch: 150/200 \tTraining Loss: 0.009005\n",
      "Epoch: 151/200 \tTraining Loss: 0.008642\n",
      "Epoch: 152/200 \tTraining Loss: 0.008566\n",
      "Epoch: 153/200 \tTraining Loss: 0.008725\n",
      "Epoch: 154/200 \tTraining Loss: 0.008851\n",
      "Epoch: 155/200 \tTraining Loss: 0.008785\n",
      "Epoch: 156/200 \tTraining Loss: 0.008958\n",
      "Epoch: 157/200 \tTraining Loss: 0.008946\n",
      "Epoch: 158/200 \tTraining Loss: 0.008727\n",
      "Epoch: 159/200 \tTraining Loss: 0.008928\n",
      "Epoch: 160/200 \tTraining Loss: 0.008448\n",
      "Epoch: 161/200 \tTraining Loss: 0.009008\n",
      "Epoch: 162/200 \tTraining Loss: 0.008382\n",
      "Epoch: 163/200 \tTraining Loss: 0.008421\n",
      "Epoch: 164/200 \tTraining Loss: 0.009095\n",
      "Epoch: 165/200 \tTraining Loss: 0.009050\n",
      "Epoch: 166/200 \tTraining Loss: 0.008413\n",
      "Epoch: 167/200 \tTraining Loss: 0.009635\n",
      "Epoch: 168/200 \tTraining Loss: 0.009244\n",
      "Epoch: 169/200 \tTraining Loss: 0.008433\n",
      "Epoch: 170/200 \tTraining Loss: 0.008692\n",
      "Epoch: 171/200 \tTraining Loss: 0.009279\n",
      "Epoch: 172/200 \tTraining Loss: 0.008913\n",
      "Epoch: 173/200 \tTraining Loss: 0.008903\n",
      "Epoch: 174/200 \tTraining Loss: 0.008761\n",
      "Epoch: 175/200 \tTraining Loss: 0.008903\n",
      "Epoch: 176/200 \tTraining Loss: 0.009027\n",
      "Epoch: 177/200 \tTraining Loss: 0.008763\n",
      "Epoch: 178/200 \tTraining Loss: 0.009075\n",
      "Epoch: 179/200 \tTraining Loss: 0.009013\n",
      "Epoch: 180/200 \tTraining Loss: 0.008661\n",
      "Epoch: 181/200 \tTraining Loss: 0.008802\n",
      "Epoch: 182/200 \tTraining Loss: 0.009573\n",
      "Epoch: 183/200 \tTraining Loss: 0.009285\n",
      "Epoch: 184/200 \tTraining Loss: 0.008670\n",
      "Epoch: 185/200 \tTraining Loss: 0.008829\n",
      "Epoch: 186/200 \tTraining Loss: 0.008473\n",
      "Epoch: 187/200 \tTraining Loss: 0.009012\n",
      "Epoch: 188/200 \tTraining Loss: 0.008565\n",
      "Epoch: 189/200 \tTraining Loss: 0.008852\n",
      "Epoch: 190/200 \tTraining Loss: 0.008504\n",
      "Epoch: 191/200 \tTraining Loss: 0.008353\n",
      "Epoch: 192/200 \tTraining Loss: 0.009378\n",
      "Epoch: 193/200 \tTraining Loss: 0.008913\n",
      "Epoch: 194/200 \tTraining Loss: 0.009020\n",
      "Epoch: 195/200 \tTraining Loss: 0.008499\n",
      "Epoch: 196/200 \tTraining Loss: 0.008835\n",
      "Epoch: 197/200 \tTraining Loss: 0.008878\n",
      "Epoch: 198/200 \tTraining Loss: 0.009181\n",
      "Epoch: 199/200 \tTraining Loss: 0.009137\n",
      "Epoch: 200/200 \tTraining Loss: 0.008691\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200 \n",
    "\n",
    "model.to(device)    # bring the model to gpu\n",
    "model.train()       # prep model for training\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #bring data and target to gpu\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print('Epoch: {}/{} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1,\n",
    "        n_epochs, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287185fa850>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "\n",
    "# Save the model  -- I already saved this and submitted\n",
    "torch.save(model.state_dict(), 'PyTorch_Model/NN_mish_Drop_L2_Huber_Extra128_200Epoch_Quantile.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the saved state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2772653   0.47560936  1.4385734  ... -0.20668665  1.2563114\n",
      "  -0.48045057]\n",
      " [-0.99022037 -0.32078427 -1.0326473  ...  0.6787401  -0.9912824\n",
      "   0.9388323 ]\n",
      " [-0.17263769  0.87897694 -0.02790673 ...  0.6185683  -0.17573412\n",
      "   0.39813843]\n",
      " ...\n",
      " [ 0.59163654 -0.01064622  0.5184686  ... -0.37825137  0.58817\n",
      "  -0.3988412 ]\n",
      " [-1.2942623   1.4113775  -0.9939901  ...  1.8934125  -1.3299655\n",
      "   1.7983557 ]\n",
      " [-0.2644971  -1.9108483  -0.5045444  ... -1.2538246  -0.2387816\n",
      "  -0.9137027 ]]\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('PyTorch_Model/NN_mish_Drop_L2_Huber_200Epoch_Quantile.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval()           # prep model for *evaluation*\n",
    "model.to(device)\n",
    "with torch.no_grad():  # turn off gradient to save memory\n",
    "    y_predNN_torch = model(X_test_torch.to(device))\n",
    "\n",
    "y_predNN_normal = y_predNN_torch.cpu().numpy()     # convert to numpy array\n",
    "y_test_normal = y_test_torch.cpu().numpy()\n",
    "print(y_predNN_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network scores in normal distribution: r2 = 0.9876143214406887, mape = 0.416534960269928\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test_normal, y_predNN_normal)\n",
    "r2 = r2_score(y_test_normal, y_predNN_normal)\n",
    "print(f\"Neural Network scores in normal distribution: r2 = {r2}, mape = {mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network scores in actual distribution: r2 = 0.9843538716088607, mape = 0.04412047054243462\n"
     ]
    }
   ],
   "source": [
    "y_predNN = quantile.inverse_transform(y_predNN_normal)\n",
    "mape = mean_absolute_percentage_error(y_test, y_predNN.astype('float64'))\n",
    "r2 = r2_score(y_test, y_predNN)\n",
    "\n",
    "print(f\"Neural Network scores in actual distribution: r2 = {r2}, mape = {mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40293893, 0.18692414, 0.06679379, 1.5731983 , 1.1409516 ,\n",
       "       0.07116825, 0.08229017, 0.11094648, 0.0684045 , 0.01790491,\n",
       "       0.076277  , 0.28509498, 0.13568424, 0.17459093, 1.2293346 ,\n",
       "       0.14248492, 0.21850143, 0.06556914, 0.22037481, 0.10233872,\n",
       "       0.11252213, 0.19777906, 0.69064593, 0.15893647, 0.09778114,\n",
       "       0.06329427, 0.52257925, 0.03382068, 0.0137039 , 0.08567823,\n",
       "       0.06398399, 0.49113005, 0.31454965, 0.22651668, 0.17856087,\n",
       "       1.3262647 , 0.9491288 , 0.08730866, 0.17905883, 1.7284456 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39918807, 0.18489788, 0.07076792, 1.603528  , 1.0806105 ,\n",
       "       0.06908134, 0.08818348, 0.10897039, 0.06826332, 0.01860524,\n",
       "       0.08134046, 0.28987974, 0.12975076, 0.17156978, 1.2115381 ,\n",
       "       0.15436813, 0.22705919, 0.06763056, 0.22765867, 0.10868868,\n",
       "       0.11713055, 0.19952142, 0.66621888, 0.15975925, 0.09596858,\n",
       "       0.06414993, 0.59720933, 0.03660972, 0.01633277, 0.08981635,\n",
       "       0.06839496, 0.49123496, 0.30692583, 0.2290165 , 0.18374079,\n",
       "       1.2546521 , 0.83790588, 0.08270955, 0.18826026, 1.7111793 ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.36676340e-02, 1.85481800e-02, 1.16362342e-01, ...,\n",
       "        3.87540700e+01, 9.85093640e-02, 8.02679810e-02],\n",
       "       [1.88341180e-02, 1.49853250e-02, 3.32267860e-02, ...,\n",
       "        1.10768800e+02, 2.12428740e-02, 3.99188070e-01],\n",
       "       [4.82065450e-02, 2.26087420e-02, 7.29268908e-02, ...,\n",
       "        9.14076770e+01, 5.16740420e-02, 1.84897880e-01],\n",
       "       ...,\n",
       "       [7.48656170e-02, 1.68266440e-02, 9.27517236e-02, ...,\n",
       "        3.51032030e+01, 7.93257060e-02, 9.26706940e-02],\n",
       "       [1.48923780e-02, 2.82288120e-02, 3.50396958e-02, ...,\n",
       "        3.61880250e+02, 1.65773410e-02, 1.17031230e+00],\n",
       "       [4.29282640e-02, 7.86490400e-03, 5.24556696e-02, ...,\n",
       "        1.25165350e+01, 4.73894250e-02, 4.77122370e-02]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3816304 ,  0.28268605,  1.4829322 , ..., -0.30745506,\n",
       "         1.3684012 , -0.5699484 ],\n",
       "       [-1.0927829 , -0.31069657, -1.1450505 , ...,  0.7362669 ,\n",
       "        -1.0969453 ,  1.0197092 ],\n",
       "       [-0.11125448,  0.76144725,  0.03355394, ...,  0.54064226,\n",
       "        -0.11799674,  0.33428347],\n",
       "       ...,\n",
       "       [ 0.60861874,  0.03356267,  0.5383628 , ..., -0.40858847,\n",
       "         0.60639787, -0.4104572 ],\n",
       "       [-1.3439791 ,  1.4611413 , -1.0646684 , ...,  1.977942  ,\n",
       "        -1.3777595 ,  1.9264768 ],\n",
       "       [-0.24901262, -2.1335402 , -0.47832558, ..., -1.3961294 ,\n",
       "        -0.22524492, -1.1426171 ]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3745447 ,  0.39098334,  1.541328  , ..., -0.3063252 ,\n",
       "         1.3605843 , -0.5498472 ],\n",
       "       [-1.0866694 , -0.32501316, -1.165355  , ...,  0.7668543 ,\n",
       "        -1.1000178 ,  1.0265232 ],\n",
       "       [-0.08239491,  0.81565875,  0.05113338, ...,  0.5583257 ,\n",
       "        -0.08981794,  0.34370404],\n",
       "       ...,\n",
       "       [ 0.6009814 , -0.14309058,  0.5339893 , ..., -0.49559617,\n",
       "         0.6055057 , -0.4972145 ],\n",
       "       [-1.2923795 ,  1.4716097 , -1.0610684 , ...,  1.9973941 ,\n",
       "        -1.3589212 ,  1.9229813 ],\n",
       "       [-0.2747004 , -1.994422  , -0.48124322, ..., -1.3523613 ,\n",
       "        -0.23567753, -1.0565274 ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Pressure\n",
      "[-0.05803021 -0.18981701 -0.11518781 ... -0.05726141 -0.302009\n",
      " -0.04012128]\n",
      "\n",
      "Positive Impulse\n",
      "[ 38.80099  113.936646  92.900665 ...  32.103645 366.63266   13.11972 ]\n",
      "\n",
      "Positive Pressure\n",
      "[0.08168865 0.40293893 0.18692414 ... 0.08577602 1.1673032  0.0519053 ]\n"
     ]
    }
   ],
   "source": [
    "# Negative Pressure\n",
    "print(\"Negative Pressure\")\n",
    "print(y_predNN[:,3])\n",
    "print()\n",
    "\n",
    "\n",
    "# Positive Impulse\n",
    "print(\"Positive Impulse\")\n",
    "print(y_predNN[:,5])\n",
    "print()\n",
    "\n",
    "# Positive Pressure\n",
    "print(\"Positive Pressure\")\n",
    "print(y_predNN[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
