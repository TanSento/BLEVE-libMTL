{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import timeit\n",
    "#import shap\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"positive_peak_time\")\n",
    "df2 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"negative_peak_time\")\n",
    "df3 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"arrival_time\")\n",
    "df4 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"positive_duration\")\n",
    "df5 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"negative_duration\")\n",
    "df6 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"positive_pressure\")\n",
    "df7 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"negative_pressure\")\n",
    "df8 = pd.read_excel(\"data_new/train.xlsx\", sheet_name=\"positive_impulse\")\n",
    "\n",
    "\n",
    "\n",
    "dt1 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"positive_peak_time\")\n",
    "dt2 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"negative_peak_time\")\n",
    "dt3 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"arrival_time\")\n",
    "dt4 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"positive_duration\")\n",
    "dt5 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"negative_duration\")\n",
    "dt6 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"positive_pressure\")\n",
    "dt7 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"negative_pressure\")\n",
    "dt8 = pd.read_excel(\"data_new/test.xlsx\", sheet_name=\"positive_impulse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>7</td>\n",
       "      <td>0.017034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>8</td>\n",
       "      <td>0.019576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>9</td>\n",
       "      <td>0.022172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>36</td>\n",
       "      <td>0.093782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>37</td>\n",
       "      <td>0.096635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>38</td>\n",
       "      <td>0.099487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>39</td>\n",
       "      <td>0.102341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>Subcooled</td>\n",
       "      <td>40</td>\n",
       "      <td>0.105201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21600 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0      B291                         13.6          0.665119             1.0   \n",
       "1      B291                         13.6          0.665119             1.0   \n",
       "2      B291                         13.6          0.665119             1.0   \n",
       "3      B291                         13.6          0.665119             1.0   \n",
       "4      B291                         13.6          0.665119             1.0   \n",
       "...     ...                          ...               ...             ...   \n",
       "21595  B103                         30.7          0.181290             0.6   \n",
       "21596  B103                         30.7          0.181290             0.6   \n",
       "21597  B103                         30.7          0.181290             0.6   \n",
       "21598  B103                         30.7          0.181290             0.6   \n",
       "21599  B103                         30.7          0.181290             0.6   \n",
       "\n",
       "       Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                  4.0              0.8                  1.8   \n",
       "1                  4.0              0.8                  1.8   \n",
       "2                  4.0              0.8                  1.8   \n",
       "3                  4.0              0.8                  1.8   \n",
       "4                  4.0              0.8                  1.8   \n",
       "...                ...              ...                  ...   \n",
       "21595              2.0              2.8                  1.2   \n",
       "21596              2.0              2.8                  1.2   \n",
       "21597              2.0              2.8                  1.2   \n",
       "21598              2.0              2.8                  1.2   \n",
       "21599              2.0              2.8                  1.2   \n",
       "\n",
       "       Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                           0.4                   435.0   \n",
       "1                           0.4                   435.0   \n",
       "2                           0.4                   435.0   \n",
       "3                           0.4                   435.0   \n",
       "4                           0.4                   435.0   \n",
       "...                         ...                     ...   \n",
       "21595                       2.2                   334.7   \n",
       "21596                       2.2                   334.7   \n",
       "21597                       2.2                   334.7   \n",
       "21598                       2.2                   334.7   \n",
       "21599                       2.2                   334.7   \n",
       "\n",
       "        Liquid Temerature (K)       Status  Stand-off Distance    Target  \n",
       "0                       372.5  Superheated                   5  0.012166  \n",
       "1                       372.5  Superheated                   6  0.014556  \n",
       "2                       372.5  Superheated                   7  0.017034  \n",
       "3                       372.5  Superheated                   8  0.019576  \n",
       "4                       372.5  Superheated                   9  0.022172  \n",
       "...                       ...          ...                 ...       ...  \n",
       "21595                   404.9    Subcooled                  36  0.093782  \n",
       "21596                   404.9    Subcooled                  37  0.096635  \n",
       "21597                   404.9    Subcooled                  38  0.099487  \n",
       "21598                   404.9    Subcooled                  39  0.102341  \n",
       "21599                   404.9    Subcooled                  40  0.105201  \n",
       "\n",
       "[21600 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>7</td>\n",
       "      <td>0.017533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>8</td>\n",
       "      <td>0.020293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>9</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>P55</td>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>36</td>\n",
       "      <td>0.091819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>P55</td>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>37</td>\n",
       "      <td>0.094618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>P55</td>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>38</td>\n",
       "      <td>0.097421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>P55</td>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>39</td>\n",
       "      <td>0.100227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>P55</td>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>Superheated</td>\n",
       "      <td>40</td>\n",
       "      <td>0.103035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0     P197                    11.559040          0.602823             3.0   \n",
       "1     P197                    11.559040          0.602823             3.0   \n",
       "2     P197                    11.559040          0.602823             3.0   \n",
       "3     P197                    11.559040          0.602823             3.0   \n",
       "4     P197                    11.559040          0.602823             3.0   \n",
       "...    ...                          ...               ...             ...   \n",
       "7195   P55                     5.970915          0.284706             0.6   \n",
       "7196   P55                     5.970915          0.284706             0.6   \n",
       "7197   P55                     5.970915          0.284706             0.6   \n",
       "7198   P55                     5.970915          0.284706             0.6   \n",
       "7199   P55                     5.970915          0.284706             0.6   \n",
       "\n",
       "      Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                 0.8              2.2                  0.2   \n",
       "1                 0.8              2.2                  0.2   \n",
       "2                 0.8              2.2                  0.2   \n",
       "3                 0.8              2.2                  0.2   \n",
       "4                 0.8              2.2                  0.2   \n",
       "...               ...              ...                  ...   \n",
       "7195              9.8              2.8                  1.0   \n",
       "7196              9.8              2.8                  1.0   \n",
       "7197              9.8              2.8                  1.0   \n",
       "7198              9.8              2.8                  1.0   \n",
       "7199              9.8              2.8                  1.0   \n",
       "\n",
       "      Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                          1.0                   296.7   \n",
       "1                          1.0                   296.7   \n",
       "2                          1.0                   296.7   \n",
       "3                          1.0                   296.7   \n",
       "4                          1.0                   296.7   \n",
       "...                        ...                     ...   \n",
       "7195                       2.2                   439.3   \n",
       "7196                       2.2                   439.3   \n",
       "7197                       2.2                   439.3   \n",
       "7198                       2.2                   439.3   \n",
       "7199                       2.2                   439.3   \n",
       "\n",
       "       Liquid Temerature (K)       Status  Stand-off Distance    Target  \n",
       "0                      328.5  Superheated                   5  0.012114  \n",
       "1                      328.5  Superheated                   6  0.014798  \n",
       "2                      328.5  Superheated                   7  0.017533  \n",
       "3                      328.5  Superheated                   8  0.020293  \n",
       "4                      328.5  Superheated                   9  0.023077  \n",
       "...                      ...          ...                 ...       ...  \n",
       "7195                   349.9  Superheated                  36  0.091819  \n",
       "7196                   349.9  Superheated                  37  0.094618  \n",
       "7197                   349.9  Superheated                  38  0.097421  \n",
       "7198                   349.9  Superheated                  39  0.100227  \n",
       "7199                   349.9  Superheated                  40  0.103035  \n",
       "\n",
       "[7200 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.009970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.010039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B291</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.010011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.017944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.017724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.017498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.017280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>B103</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.017078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21600 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0      B291                         13.6          0.665119             1.0   \n",
       "1      B291                         13.6          0.665119             1.0   \n",
       "2      B291                         13.6          0.665119             1.0   \n",
       "3      B291                         13.6          0.665119             1.0   \n",
       "4      B291                         13.6          0.665119             1.0   \n",
       "...     ...                          ...               ...             ...   \n",
       "21595  B103                         30.7          0.181290             0.6   \n",
       "21596  B103                         30.7          0.181290             0.6   \n",
       "21597  B103                         30.7          0.181290             0.6   \n",
       "21598  B103                         30.7          0.181290             0.6   \n",
       "21599  B103                         30.7          0.181290             0.6   \n",
       "\n",
       "       Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                  4.0              0.8                  1.8   \n",
       "1                  4.0              0.8                  1.8   \n",
       "2                  4.0              0.8                  1.8   \n",
       "3                  4.0              0.8                  1.8   \n",
       "4                  4.0              0.8                  1.8   \n",
       "...                ...              ...                  ...   \n",
       "21595              2.0              2.8                  1.2   \n",
       "21596              2.0              2.8                  1.2   \n",
       "21597              2.0              2.8                  1.2   \n",
       "21598              2.0              2.8                  1.2   \n",
       "21599              2.0              2.8                  1.2   \n",
       "\n",
       "       Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                           0.4                   435.0   \n",
       "1                           0.4                   435.0   \n",
       "2                           0.4                   435.0   \n",
       "3                           0.4                   435.0   \n",
       "4                           0.4                   435.0   \n",
       "...                         ...                     ...   \n",
       "21595                       2.2                   334.7   \n",
       "21596                       2.2                   334.7   \n",
       "21597                       2.2                   334.7   \n",
       "21598                       2.2                   334.7   \n",
       "21599                       2.2                   334.7   \n",
       "\n",
       "        Liquid Temerature (K)  Status  Stand-off Distance    Target  \n",
       "0                       372.5       1                   5  0.009827  \n",
       "1                       372.5       1                   6  0.009906  \n",
       "2                       372.5       1                   7  0.009970  \n",
       "3                       372.5       1                   8  0.010039  \n",
       "4                       372.5       1                   9  0.010011  \n",
       "...                       ...     ...                 ...       ...  \n",
       "21595                   404.9       0                  36  0.017944  \n",
       "21596                   404.9       0                  37  0.017724  \n",
       "21597                   404.9       0                  38  0.017498  \n",
       "21598                   404.9       0                  39  0.017280  \n",
       "21599                   404.9       0                  40  0.017078  \n",
       "\n",
       "[21600 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding 'Status' feature into 0 and 1 \n",
    "# 0 for Subcooled and 1 for Superheated\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "df5['Status'] = LE.fit_transform(df5['Status'])\n",
    "dt5['Status'] = LE.fit_transform(dt5['Status'])\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.55904</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.015426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.55904</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.015341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.55904</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.015277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.55904</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.015224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.55904</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.015191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P197</td>\n",
       "      <td>11.55904</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.015170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.009452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.009528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.009658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.009688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.009598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.009631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.012086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.012530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>P168</td>\n",
       "      <td>12.72223</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>389.7</td>\n",
       "      <td>296.4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.012757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "30  P197                     11.55904          0.602823             3.0   \n",
       "31  P197                     11.55904          0.602823             3.0   \n",
       "32  P197                     11.55904          0.602823             3.0   \n",
       "33  P197                     11.55904          0.602823             3.0   \n",
       "34  P197                     11.55904          0.602823             3.0   \n",
       "35  P197                     11.55904          0.602823             3.0   \n",
       "36  P168                     12.72223          0.648320             1.8   \n",
       "37  P168                     12.72223          0.648320             1.8   \n",
       "38  P168                     12.72223          0.648320             1.8   \n",
       "39  P168                     12.72223          0.648320             1.8   \n",
       "40  P168                     12.72223          0.648320             1.8   \n",
       "41  P168                     12.72223          0.648320             1.8   \n",
       "42  P168                     12.72223          0.648320             1.8   \n",
       "43  P168                     12.72223          0.648320             1.8   \n",
       "44  P168                     12.72223          0.648320             1.8   \n",
       "45  P168                     12.72223          0.648320             1.8   \n",
       "46  P168                     12.72223          0.648320             1.8   \n",
       "47  P168                     12.72223          0.648320             1.8   \n",
       "48  P168                     12.72223          0.648320             1.8   \n",
       "49  P168                     12.72223          0.648320             1.8   \n",
       "\n",
       "    Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "30              0.8              2.2                  0.2   \n",
       "31              0.8              2.2                  0.2   \n",
       "32              0.8              2.2                  0.2   \n",
       "33              0.8              2.2                  0.2   \n",
       "34              0.8              2.2                  0.2   \n",
       "35              0.8              2.2                  0.2   \n",
       "36              8.2              0.6                  1.8   \n",
       "37              8.2              0.6                  1.8   \n",
       "38              8.2              0.6                  1.8   \n",
       "39              8.2              0.6                  1.8   \n",
       "40              8.2              0.6                  1.8   \n",
       "41              8.2              0.6                  1.8   \n",
       "42              8.2              0.6                  1.8   \n",
       "43              8.2              0.6                  1.8   \n",
       "44              8.2              0.6                  1.8   \n",
       "45              8.2              0.6                  1.8   \n",
       "46              8.2              0.6                  1.8   \n",
       "47              8.2              0.6                  1.8   \n",
       "48              8.2              0.6                  1.8   \n",
       "49              8.2              0.6                  1.8   \n",
       "\n",
       "    Tank Height with Gas (m)   Vapour Temerature (K)   Liquid Temerature (K)  \\\n",
       "30                       1.0                   296.7                   328.5   \n",
       "31                       1.0                   296.7                   328.5   \n",
       "32                       1.0                   296.7                   328.5   \n",
       "33                       1.0                   296.7                   328.5   \n",
       "34                       1.0                   296.7                   328.5   \n",
       "35                       1.0                   296.7                   328.5   \n",
       "36                       0.2                   389.7                   296.4   \n",
       "37                       0.2                   389.7                   296.4   \n",
       "38                       0.2                   389.7                   296.4   \n",
       "39                       0.2                   389.7                   296.4   \n",
       "40                       0.2                   389.7                   296.4   \n",
       "41                       0.2                   389.7                   296.4   \n",
       "42                       0.2                   389.7                   296.4   \n",
       "43                       0.2                   389.7                   296.4   \n",
       "44                       0.2                   389.7                   296.4   \n",
       "45                       0.2                   389.7                   296.4   \n",
       "46                       0.2                   389.7                   296.4   \n",
       "47                       0.2                   389.7                   296.4   \n",
       "48                       0.2                   389.7                   296.4   \n",
       "49                       0.2                   389.7                   296.4   \n",
       "\n",
       "    Status  Stand-off Distance    Target  \n",
       "30       1                  35  0.015426  \n",
       "31       1                  36  0.015341  \n",
       "32       1                  37  0.015277  \n",
       "33       1                  38  0.015224  \n",
       "34       1                  39  0.015191  \n",
       "35       1                  40  0.015170  \n",
       "36       0                   5  0.009043  \n",
       "37       0                   6  0.009390  \n",
       "38       0                   7  0.009452  \n",
       "39       0                   8  0.009528  \n",
       "40       0                   9  0.009658  \n",
       "41       0                  10  0.009688  \n",
       "42       0                  11  0.009588  \n",
       "43       0                  12  0.009598  \n",
       "44       0                  13  0.009700  \n",
       "45       0                  14  0.009631  \n",
       "46       0                  15  0.009524  \n",
       "47       0                  16  0.012086  \n",
       "48       0                  17  0.012530  \n",
       "49       0                  18  0.012757  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt5.iloc[30:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0.665119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>435.0</td>\n",
       "      <td>372.5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>30.7</td>\n",
       "      <td>0.181290</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>334.7</td>\n",
       "      <td>404.9</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21600 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0                             13.6          0.665119             1.0   \n",
       "1                             13.6          0.665119             1.0   \n",
       "2                             13.6          0.665119             1.0   \n",
       "3                             13.6          0.665119             1.0   \n",
       "4                             13.6          0.665119             1.0   \n",
       "...                            ...               ...             ...   \n",
       "21595                         30.7          0.181290             0.6   \n",
       "21596                         30.7          0.181290             0.6   \n",
       "21597                         30.7          0.181290             0.6   \n",
       "21598                         30.7          0.181290             0.6   \n",
       "21599                         30.7          0.181290             0.6   \n",
       "\n",
       "       Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                  4.0              0.8                  1.8   \n",
       "1                  4.0              0.8                  1.8   \n",
       "2                  4.0              0.8                  1.8   \n",
       "3                  4.0              0.8                  1.8   \n",
       "4                  4.0              0.8                  1.8   \n",
       "...                ...              ...                  ...   \n",
       "21595              2.0              2.8                  1.2   \n",
       "21596              2.0              2.8                  1.2   \n",
       "21597              2.0              2.8                  1.2   \n",
       "21598              2.0              2.8                  1.2   \n",
       "21599              2.0              2.8                  1.2   \n",
       "\n",
       "       Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                           0.4                   435.0   \n",
       "1                           0.4                   435.0   \n",
       "2                           0.4                   435.0   \n",
       "3                           0.4                   435.0   \n",
       "4                           0.4                   435.0   \n",
       "...                         ...                     ...   \n",
       "21595                       2.2                   334.7   \n",
       "21596                       2.2                   334.7   \n",
       "21597                       2.2                   334.7   \n",
       "21598                       2.2                   334.7   \n",
       "21599                       2.2                   334.7   \n",
       "\n",
       "        Liquid Temerature (K)  Status  Stand-off Distance  \n",
       "0                       372.5       1                   5  \n",
       "1                       372.5       1                   6  \n",
       "2                       372.5       1                   7  \n",
       "3                       372.5       1                   8  \n",
       "4                       372.5       1                   9  \n",
       "...                       ...     ...                 ...  \n",
       "21595                   404.9       0                  36  \n",
       "21596                   404.9       0                  37  \n",
       "21597                   404.9       0                  38  \n",
       "21598                   404.9       0                  39  \n",
       "21599                   404.9       0                  40  \n",
       "\n",
       "[21600 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traindf = df5.drop(['ID','Target'], axis=1)\n",
    "X_testdf = dt5.drop(['ID','Target'], axis=1)\n",
    "\n",
    "X_traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tank Failure Pressure (bar)</th>\n",
       "      <th>Liquid Ratio (%)</th>\n",
       "      <th>Tank Width (m)</th>\n",
       "      <th>Tank Length (m)</th>\n",
       "      <th>Tank Height (m)</th>\n",
       "      <th>Height of BLEVE (m)</th>\n",
       "      <th>Tank Height with Gas (m)</th>\n",
       "      <th>Vapour Temerature (K)</th>\n",
       "      <th>Liquid Temerature (K)</th>\n",
       "      <th>Status</th>\n",
       "      <th>Stand-off Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.559040</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>328.5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>5.970915</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>439.3</td>\n",
       "      <td>349.9</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tank Failure Pressure (bar)  Liquid Ratio (%)  Tank Width (m)  \\\n",
       "0                       11.559040          0.602823             3.0   \n",
       "1                       11.559040          0.602823             3.0   \n",
       "2                       11.559040          0.602823             3.0   \n",
       "3                       11.559040          0.602823             3.0   \n",
       "4                       11.559040          0.602823             3.0   \n",
       "...                           ...               ...             ...   \n",
       "7195                     5.970915          0.284706             0.6   \n",
       "7196                     5.970915          0.284706             0.6   \n",
       "7197                     5.970915          0.284706             0.6   \n",
       "7198                     5.970915          0.284706             0.6   \n",
       "7199                     5.970915          0.284706             0.6   \n",
       "\n",
       "      Tank Length (m)  Tank Height (m)  Height of BLEVE (m)  \\\n",
       "0                 0.8              2.2                  0.2   \n",
       "1                 0.8              2.2                  0.2   \n",
       "2                 0.8              2.2                  0.2   \n",
       "3                 0.8              2.2                  0.2   \n",
       "4                 0.8              2.2                  0.2   \n",
       "...               ...              ...                  ...   \n",
       "7195              9.8              2.8                  1.0   \n",
       "7196              9.8              2.8                  1.0   \n",
       "7197              9.8              2.8                  1.0   \n",
       "7198              9.8              2.8                  1.0   \n",
       "7199              9.8              2.8                  1.0   \n",
       "\n",
       "      Tank Height with Gas (m)   Vapour Temerature (K)  \\\n",
       "0                          1.0                   296.7   \n",
       "1                          1.0                   296.7   \n",
       "2                          1.0                   296.7   \n",
       "3                          1.0                   296.7   \n",
       "4                          1.0                   296.7   \n",
       "...                        ...                     ...   \n",
       "7195                       2.2                   439.3   \n",
       "7196                       2.2                   439.3   \n",
       "7197                       2.2                   439.3   \n",
       "7198                       2.2                   439.3   \n",
       "7199                       2.2                   439.3   \n",
       "\n",
       "       Liquid Temerature (K)  Status  Stand-off Distance  \n",
       "0                      328.5       1                   5  \n",
       "1                      328.5       1                   6  \n",
       "2                      328.5       1                   7  \n",
       "3                      328.5       1                   8  \n",
       "4                      328.5       1                   9  \n",
       "...                      ...     ...                 ...  \n",
       "7195                   349.9       1                  36  \n",
       "7196                   349.9       1                  37  \n",
       "7197                   349.9       1                  38  \n",
       "7198                   349.9       1                  39  \n",
       "7199                   349.9       1                  40  \n",
       "\n",
       "[7200 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.009827\n",
       "1        0.009906\n",
       "2        0.009970\n",
       "3        0.010039\n",
       "4        0.010011\n",
       "           ...   \n",
       "21595    0.017944\n",
       "21596    0.017724\n",
       "21597    0.017498\n",
       "21598    0.017280\n",
       "21599    0.017078\n",
       "Name: Target, Length: 21600, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y5_train = df5['Target']\n",
    "y5_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = df1['Target']\n",
    "y2_train = df2['Target']\n",
    "y3_train = df3['Target']\n",
    "y4_train = df4['Target']\n",
    "y6_train = df6['Target']\n",
    "y7_train = df7['Target']\n",
    "y8_train = df8['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.012114\n",
       "1       0.014798\n",
       "2       0.017533\n",
       "3       0.020293\n",
       "4       0.023077\n",
       "          ...   \n",
       "7195    0.091819\n",
       "7196    0.094618\n",
       "7197    0.097421\n",
       "7198    0.100227\n",
       "7199    0.103035\n",
       "Name: Target, Length: 7200, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_test = dt1['Target']\n",
    "y2_test = dt2['Target']\n",
    "y3_test = dt3['Target']\n",
    "y4_test = dt4['Target']\n",
    "y5_test = dt5['Target']\n",
    "y6_test = dt6['Target']\n",
    "y7_test = dt7['Target']\n",
    "y8_test = dt8['Target']\n",
    "\n",
    "y1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y1_train.values.reshape(-1,1), y2_train.values.reshape(-1,1), y3_train.values.reshape(-1,1), \n",
    "                          y4_train.values.reshape(-1,1), y5_train.values.reshape(-1,1), y6_train.values.reshape(-1,1),\n",
    "                          y7_train.values.reshape(-1,1), y8_train.values.reshape(-1,1)), axis=1)\n",
    "\n",
    "y_test = np.concatenate((y1_test.values.reshape(-1,1), y2_test.values.reshape(-1,1), y3_test.values.reshape(-1,1), \n",
    "                          y4_test.values.reshape(-1,1), y5_test.values.reshape(-1,1), y6_test.values.reshape(-1,1),\n",
    "                          y7_test.values.reshape(-1,1), y8_test.values.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 8)\n",
      "(7200, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.21663990e-02,  1.92270974e-02,  1.02530480e-02, ...,\n",
       "         6.13340850e-01, -2.35990550e-01,  1.05453270e+02],\n",
       "       [ 1.45556140e-02,  2.19475630e-02,  1.24416710e-02, ...,\n",
       "         4.85479950e-01, -2.01730860e-01,  8.91907810e+01],\n",
       "       [ 1.70337890e-02,  2.47348970e-02,  1.47326780e-02, ...,\n",
       "         3.97631170e-01, -1.78507950e-01,  7.72377550e+01],\n",
       "       ...,\n",
       "       [ 9.94869250e-02,  1.13699184e-01,  9.45632310e-02, ...,\n",
       "         6.88239110e-02, -4.64044960e-02,  2.74606420e+01],\n",
       "       [ 1.02341190e-01,  1.16520062e-01,  9.73516780e-02, ...,\n",
       "         6.64670090e-02, -4.60044180e-02,  2.67297230e+01],\n",
       "       [ 1.05201100e-01,  1.19343956e-01,  1.00149770e-01, ...,\n",
       "         6.42466250e-02, -4.48966060e-02,  2.60354210e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.21143940e-02,  2.36260840e-02,  9.64583550e-03, ...,\n",
       "         2.50615600e-01, -1.13256240e-01,  5.26190380e+01],\n",
       "       [ 1.47982630e-02,  2.66367886e-02,  1.20925640e-02, ...,\n",
       "         2.00786950e-01, -1.03320270e-01,  4.60554850e+01],\n",
       "       [ 1.75325390e-02,  2.95875370e-02,  1.46107920e-02, ...,\n",
       "         1.66701170e-01, -9.43374630e-02,  4.11314200e+01],\n",
       "       ...,\n",
       "       [ 9.74210350e-02,  1.11182812e-01,  9.28768070e-02, ...,\n",
       "         9.06703620e-02, -5.40905860e-02,  3.56521530e+01],\n",
       "       [ 1.00227500e-01,  1.14051970e-01,  9.56180690e-02, ...,\n",
       "         8.74992310e-02, -5.23571000e-02,  3.46799510e+01],\n",
       "       [ 1.03034510e-01,  1.16930324e-01,  9.83653590e-02, ...,\n",
       "         8.45144470e-02, -5.04742410e-02,  3.37590220e+01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and Power Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing both X_train and X_test using standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_traindf)\n",
    "X_test = scaler.transform(X_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if it succeeded\n",
    "# df_stdscal = pd.DataFrame(X_train)\n",
    "# df_stdscal.hist(figsize = (20,20), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "y_train_normal = quantile.fit_transform(y_train)\n",
    "y_test_normal = quantile.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13282937, -0.24046414, -0.33752546, -0.42328697, -0.50113971,\n",
       "       -0.56880009, -0.6374526 , -0.6996398 , -0.75546111, -0.80519565,\n",
       "       -0.85363159, -0.89909811, -0.94159534, -0.97887334, -1.01505231,\n",
       "       -1.0521215 , -1.08724264, -1.12069735, -1.15449619, -1.18573499,\n",
       "       -1.21596976, -1.2436481 , -1.27113591, -1.29845258, -1.32647432,\n",
       "       -1.35388867, -1.37806628, -1.40604031, -1.43284272, -1.45727479,\n",
       "       -1.48291819, -1.50498221, -1.53121516, -1.55699008, -1.57938197,\n",
       "        0.45279688,  0.32077739,  0.19759081,  0.08977174, -0.00920681])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_normal[1:41, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.055485, 41.13142 , 37.34763 , 34.215847, 31.660479, 29.51226 ,\n",
       "       27.62623 , 25.996059, 24.593987, 23.341728, 22.203737, 21.178555,\n",
       "       20.26375 , 19.439846, 18.682037, 17.977852, 17.324688, 16.722097,\n",
       "       16.167007, 15.652895, 15.172283, 14.719731, 14.292322, 13.888784,\n",
       "       13.508397, 13.149973, 12.811902, 12.492044, 12.188312, 11.898917,\n",
       "       11.622511, 11.358176, 11.105268, 10.863276, 10.631696, 83.744408,\n",
       "       73.62957 , 65.149193, 58.173275, 52.403481])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_check = quantile.inverse_transform(y_test_normal)\n",
    "y_test_check[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.055485, 41.13142 , 37.34763 , 34.215847, 31.660479, 29.51226 ,\n",
       "       27.62623 , 25.996059, 24.593987, 23.341728, 22.203737, 21.178555,\n",
       "       20.26375 , 19.439846, 18.682037, 17.977852, 17.324688, 16.722097,\n",
       "       16.167007, 15.652895, 15.172283, 14.719731, 14.292322, 13.888784,\n",
       "       13.508397, 13.149973, 12.811902, 12.492044, 12.188312, 11.898917,\n",
       "       11.622511, 11.358176, 11.105268, 10.863276, 10.631696, 83.744408,\n",
       "       73.62957 , 65.149193, 58.173275, 52.403481])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if it succeeded\n",
    "# df_stdscal = pd.DataFrame(y_train)\n",
    "# df_stdscal.hist(figsize = (20,20), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.backends.cudnn.version() , torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8024,  0.7595, -0.9898,  ...,  0.6962,  1.3190, -1.6846],\n",
      "        [-0.8024,  0.7595, -0.9898,  ...,  0.6962,  1.3190, -1.5883],\n",
      "        [-0.8024,  0.7595, -0.9898,  ...,  0.6962,  1.3190, -1.4921],\n",
      "        ...,\n",
      "        [ 0.9096, -1.3719, -1.5129,  ...,  1.5587, -0.7582,  1.4921],\n",
      "        [ 0.9096, -1.3719, -1.5129,  ...,  1.5587, -0.7582,  1.5883],\n",
      "        [ 0.9096, -1.3719, -1.5129,  ...,  1.5587, -0.7582,  1.6846]])\n"
     ]
    }
   ],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "X_train_torch = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_torch = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "\n",
    "\n",
    "y_train_torch = torch.from_numpy(y_train_normal.astype(np.float32))\n",
    "y_test_torch = torch.from_numpy(y_test_normal.astype(np.float32))\n",
    "\n",
    "\n",
    "print(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8878, -2.6412, -1.8978,  ...,  1.3802, -1.4426,  0.6927],\n",
       "        [-1.5732, -2.1187, -1.5748,  ...,  1.1909, -1.2257,  0.5174],\n",
       "        [-1.3570, -1.7601, -1.3660,  ...,  1.0275, -1.0601,  0.3689],\n",
       "        ...,\n",
       "        [ 1.4216,  1.3089,  1.4319,  ..., -0.7408,  0.7991, -0.6441],\n",
       "        [ 1.6162,  1.4910,  1.6337,  ..., -0.7787,  0.8107, -0.6733],\n",
       "        [ 1.8511,  1.7361,  1.8826,  ..., -0.8198,  0.8473, -0.6979]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8947, -1.8800, -2.0452,  ...,  0.6301, -0.4754, -0.0063],\n",
       "        [-1.5462, -1.5752, -1.6165,  ...,  0.4224, -0.3520, -0.1328],\n",
       "        [-1.3203, -1.3580, -1.3736,  ...,  0.2338, -0.2298, -0.2405],\n",
       "        ...,\n",
       "        [ 1.3003,  1.1768,  1.3228,  ..., -0.4314,  0.5893, -0.3827],\n",
       "        [ 1.4655,  1.3283,  1.4963,  ..., -0.4692,  0.6343, -0.4098],\n",
       "        [ 1.6633,  1.5193,  1.7074,  ..., -0.5085,  0.6895, -0.4363]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(X_train_torch)):\n",
    "   train_data.append([X_train_torch[i],\n",
    "                      y_train_torch[i] \n",
    "                     ])\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(X_test_torch)):\n",
    "   test_data.append([X_test_torch[i], \n",
    "                     y_test_torch[i]\n",
    "                     ])\n",
    "\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=512,               # batch_size could be smaller\n",
    "    num_workers=0)                                                                   # Increasing num_workers slow down the training because it does not use GPU at all\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=512,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8878, -2.6412, -1.8978,  ...,  1.3802, -1.4426,  0.6927],\n",
      "        [-1.5732, -2.1187, -1.5748,  ...,  1.1909, -1.2257,  0.5174],\n",
      "        [-1.3570, -1.7601, -1.3660,  ...,  1.0275, -1.0601,  0.3689],\n",
      "        ...,\n",
      "        [-0.9979, -1.0126, -1.0149,  ...,  0.4693, -0.6818,  0.2249],\n",
      "        [-0.8830, -0.8911, -0.8996,  ...,  0.3513, -0.6417,  0.1510],\n",
      "        [-0.7784, -0.7775, -0.7954,  ...,  0.2407, -0.5527,  0.0837]])\n",
      "tensor([[-0.6820, -0.6862, -0.6977,  ...,  0.1379, -0.4179,  0.0224],\n",
      "        [-0.5917, -0.6010, -0.6080,  ...,  0.0406, -0.3576, -0.0370],\n",
      "        [-0.5070, -0.5145, -0.5230,  ..., -0.0512, -0.3485, -0.0875],\n",
      "        ...,\n",
      "        [-0.1655, -0.3644, -0.1926,  ..., -1.4773,  1.3318, -1.6337],\n",
      "        [-0.0918, -0.2905, -0.1186,  ..., -1.5434,  1.3688, -1.6855],\n",
      "        [-0.0192, -0.2167, -0.0458,  ..., -1.6069,  1.4008, -1.7329]])\n",
      "tensor([[ 5.3093e-02, -1.4326e-01,  2.6921e-02,  ..., -1.6665e+00,\n",
      "          1.4558e+00, -1.7748e+00],\n",
      "        [ 1.2589e-01, -7.2220e-02,  1.0023e-01,  ..., -1.7245e+00,\n",
      "          1.5266e+00, -1.8162e+00],\n",
      "        [ 2.0062e-01,  6.9243e-04,  1.7394e-01,  ..., -1.7775e+00,\n",
      "          1.6315e+00, -1.8532e+00],\n",
      "        ...,\n",
      "        [ 4.2210e-01,  3.1512e-01,  3.9370e-01,  ..., -1.7573e+00,\n",
      "          1.6684e+00, -1.5192e+00],\n",
      "        [ 5.0212e-01,  3.9127e-01,  4.7318e-01,  ..., -1.8004e+00,\n",
      "          1.7534e+00, -1.5560e+00],\n",
      "        [ 5.8515e-01,  4.6955e-01,  5.5513e-01,  ..., -1.8436e+00,\n",
      "          1.8219e+00, -1.5905e+00]])\n",
      "tensor([[ 0.6727,  0.5494,  0.6410,  ..., -1.8831,  1.8901, -1.6252],\n",
      "        [ 0.7658,  0.6336,  0.7315,  ..., -1.9232,  1.9521, -1.6614],\n",
      "        [ 0.8661,  0.7222,  0.8288,  ..., -1.9614,  1.9980, -1.6936],\n",
      "        ...,\n",
      "        [ 0.9507,  0.7988,  0.9566,  ..., -0.6335,  0.8700, -0.8025],\n",
      "        [ 1.0669,  0.8988,  1.0747,  ..., -0.6769,  0.9302, -0.8357],\n",
      "        [ 1.1989,  1.0095,  1.2073,  ..., -0.7215,  0.9835, -0.8659]])\n",
      "tensor([[ 1.3512,  1.1354,  1.3640,  ..., -0.7639,  1.0289, -0.8961],\n",
      "        [ 1.5298,  1.2807,  1.5500,  ..., -0.8073,  1.0708, -0.9250],\n",
      "        [ 1.7416,  1.4607,  1.7761,  ..., -0.8484,  1.1095, -0.9509],\n",
      "        ...,\n",
      "        [-1.7413, -2.2388, -1.7130,  ...,  1.5533, -1.5553,  0.9864],\n",
      "        [-1.4858, -1.8588, -1.4726,  ...,  1.3733, -1.3491,  0.8323],\n",
      "        [-1.3022, -1.5830, -1.2932,  ...,  1.2153, -1.1551,  0.6956]])\n",
      "tensor([[-1.1522, -1.3750, -1.1491,  ...,  1.0808, -1.0228,  0.5715],\n",
      "        [-1.0270, -1.2129, -1.0222,  ...,  0.9554, -0.8598,  0.4582],\n",
      "        [-0.9140, -1.0778, -0.9111,  ...,  0.8406, -0.7654,  0.3565],\n",
      "        ...,\n",
      "        [-0.7437, -0.5074, -0.7250,  ...,  1.1672, -1.1741,  1.4080],\n",
      "        [-0.6590, -0.4267, -0.6408,  ...,  1.0842, -1.0672,  1.3411],\n",
      "        [-0.5783, -0.3507, -0.5618,  ...,  1.0095, -0.9707,  1.2833]])\n",
      "tensor([[-0.5007, -0.2789, -0.4855,  ...,  0.9388, -0.9258,  1.2272],\n",
      "        [-0.4245, -0.2087, -0.4119,  ...,  0.8736, -0.8698,  1.1742],\n",
      "        [-0.3526, -0.1389, -0.3398,  ...,  0.8111, -0.8054,  1.1197],\n",
      "        ...,\n",
      "        [ 0.0956,  0.0019,  0.0766,  ..., -1.1939,  0.9122, -1.1193],\n",
      "        [ 0.1676,  0.0742,  0.1487,  ..., -1.2502,  1.0336, -1.1587],\n",
      "        [ 0.2412,  0.1446,  0.2219,  ..., -1.3038,  1.1614, -1.1935]])\n",
      "tensor([[ 0.3163,  0.2158,  0.2961,  ..., -1.3540,  1.2656, -1.2271],\n",
      "        [ 0.3929,  0.2864,  0.3716,  ..., -1.4019,  1.1996, -1.2595],\n",
      "        [ 0.4716,  0.3601,  0.4490,  ..., -1.4503,  1.2005, -1.2926],\n",
      "        ...,\n",
      "        [ 0.4469,  0.6342,  0.4579,  ...,  0.0714, -0.0862,  0.4223],\n",
      "        [ 0.5231,  0.7182,  0.5359,  ...,  0.0301, -0.0211,  0.3903],\n",
      "        [ 0.6032,  0.8076,  0.6167,  ..., -0.0115,  0.0414,  0.3575]])\n",
      "tensor([[ 0.6880,  0.9044,  0.7022,  ..., -0.0516,  0.1054,  0.3257],\n",
      "        [ 0.7770,  1.0124,  0.7934,  ..., -0.0942,  0.1660,  0.2922],\n",
      "        [ 0.8720,  1.1380,  0.8920,  ..., -0.1296,  0.2010,  0.2635],\n",
      "        ...,\n",
      "        [ 1.8208,  1.2646,  1.7997,  ..., -1.4407,  1.5186, -1.4497],\n",
      "        [ 2.1009,  1.4392,  2.0987,  ..., -1.4748,  1.5613, -1.4727],\n",
      "        [ 2.4609,  1.6718,  2.5021,  ..., -1.5091,  1.6110, -1.4963]])\n",
      "tensor([[-1.8449, -1.9079, -1.8757,  ...,  1.3827, -1.8663,  1.2055],\n",
      "        [-1.5397, -1.6306, -1.5546,  ...,  1.2771, -1.6331,  1.0929],\n",
      "        [-1.3364, -1.4210, -1.3487,  ...,  1.1828, -1.3924,  0.9759],\n",
      "        ...,\n",
      "        [-1.1629, -0.8605, -1.1523,  ...,  1.2938, -1.3247,  1.4098],\n",
      "        [-1.0382, -0.7528, -1.0283,  ...,  1.1851, -1.2320,  1.3233],\n",
      "        [-0.9287, -0.6681, -0.9189,  ...,  1.0858, -1.1594,  1.2504]])\n",
      "tensor([[-0.8297, -0.5866, -0.8192,  ...,  0.9927, -1.0603,  1.1808],\n",
      "        [-0.7377, -0.4915, -0.7275,  ...,  0.9086, -0.9525,  1.1138],\n",
      "        [-0.6511, -0.4140, -0.6414,  ...,  0.8261, -0.8359,  1.0585],\n",
      "        ...,\n",
      "        [-0.2914, -0.2008, -0.2874,  ...,  0.2940, -0.3564,  0.3044],\n",
      "        [-0.2192, -0.1322, -0.2147,  ...,  0.2228, -0.3010,  0.2578],\n",
      "        [-0.1479, -0.0611, -0.1440,  ...,  0.1604, -0.2385,  0.2123]])\n",
      "tensor([[-0.0772,  0.0127, -0.0733,  ...,  0.0947, -0.1674,  0.1687],\n",
      "        [-0.0068,  0.0868, -0.0033,  ...,  0.0339, -0.0935,  0.1297],\n",
      "        [ 0.0638,  0.1580,  0.0666,  ..., -0.0237, -0.0204,  0.0930],\n",
      "        ...,\n",
      "        [ 0.2052,  0.1411,  0.2103,  ..., -0.1111,  0.1564, -0.1918],\n",
      "        [ 0.2756,  0.2151,  0.2814,  ..., -0.1679,  0.2396, -0.2293],\n",
      "        [ 0.3483,  0.2896,  0.3536,  ..., -0.2198,  0.3343, -0.2659]])\n",
      "tensor([[ 0.4230,  0.3632,  0.4274,  ..., -0.2739,  0.4346, -0.3031],\n",
      "        [ 0.4994,  0.4374,  0.5046,  ..., -0.3245,  0.5394, -0.3393],\n",
      "        [ 0.5793,  0.5133,  0.5848,  ..., -0.3729,  0.4695, -0.3711],\n",
      "        ...,\n",
      "        [ 0.7112,  0.8089,  0.7262,  ..., -0.0698,  0.3282,  0.0969],\n",
      "        [ 0.8030,  0.9104,  0.8193,  ..., -0.1125,  0.3546,  0.0668],\n",
      "        [ 0.9026,  1.0216,  0.9203,  ..., -0.1514,  0.3779,  0.0403]])\n",
      "tensor([[ 1.0124,  1.1462,  1.0320,  ..., -0.1931,  0.4076,  0.0114],\n",
      "        [ 1.1352,  1.2946,  1.1588,  ..., -0.2329,  0.4400, -0.0142],\n",
      "        [ 1.2758,  1.4837,  1.3048,  ..., -0.2699,  0.4804, -0.0422],\n",
      "        ...,\n",
      "        [-2.1975, -2.1065, -2.1549,  ...,  2.0626, -2.2453,  1.8443],\n",
      "        [-1.7767, -1.7925, -1.7368,  ...,  1.8984, -1.9928,  1.7163],\n",
      "        [-1.5279, -1.5497, -1.4974,  ...,  1.7553, -1.7915,  1.5983]])\n",
      "tensor([[-1.3470, -1.3578, -1.3211,  ...,  1.6282, -1.5887,  1.4846],\n",
      "        [-1.2003, -1.2065, -1.1804,  ...,  1.5118, -1.4592,  1.3798],\n",
      "        [-1.0761, -1.0753, -1.0576,  ...,  1.3971, -1.3114,  1.2852],\n",
      "        ...,\n",
      "        [-0.4953, -0.6084, -0.5079,  ...,  0.0899, -0.2641, -0.2649],\n",
      "        [-0.4156, -0.5219, -0.4274,  ...,  0.0134, -0.0262, -0.3266],\n",
      "        [-0.3388, -0.4429, -0.3500,  ..., -0.0640, -0.0879, -0.3855]])\n",
      "tensor([[-0.2651, -0.3669, -0.2748,  ..., -0.1346, -0.0973, -0.4386],\n",
      "        [-0.1922, -0.2930, -0.2014,  ..., -0.2071, -0.0175, -0.4907],\n",
      "        [-0.1203, -0.2196, -0.1287,  ..., -0.2763,  0.1001, -0.5388],\n",
      "        ...,\n",
      "        [-0.0454, -0.0956, -0.0384,  ...,  0.2298, -0.0940,  0.0943],\n",
      "        [ 0.0234, -0.0276,  0.0303,  ...,  0.1692, -0.0770,  0.0516],\n",
      "        [ 0.0924,  0.0414,  0.0986,  ...,  0.1097, -0.0220,  0.0077]])\n",
      "tensor([[ 0.1621,  0.1124,  0.1676,  ...,  0.0531,  0.0579, -0.0327],\n",
      "        [ 0.2324,  0.1839,  0.2377,  ..., -0.0047,  0.1452, -0.0714],\n",
      "        [ 0.3041,  0.2543,  0.3092,  ..., -0.0589,  0.2379, -0.1070],\n",
      "        ...,\n",
      "        [ 0.4481,  0.6090,  0.4593,  ...,  0.0697, -0.0654,  0.3741],\n",
      "        [ 0.5246,  0.6927,  0.5372,  ...,  0.0263, -0.0242,  0.3428],\n",
      "        [ 0.6045,  0.7807,  0.6181,  ..., -0.0161, -0.0358,  0.3124]])\n",
      "tensor([[ 0.6895,  0.8745,  0.7036,  ..., -0.0574, -0.0138,  0.2820],\n",
      "        [ 0.7788,  0.9773,  0.7948,  ..., -0.1004,  0.0209,  0.2545],\n",
      "        [ 0.8737,  1.0966,  0.8937,  ..., -0.1357,  0.0699,  0.2266],\n",
      "        ...,\n",
      "        [ 1.6551,  1.2237,  1.6418,  ..., -1.3116,  1.6219, -1.3284],\n",
      "        [ 1.8975,  1.3878,  1.8952,  ..., -1.3464,  1.6831, -1.3530],\n",
      "        [ 2.2144,  1.6009,  2.2276,  ..., -1.3826,  1.7297, -1.3749]])\n",
      "tensor([[-1.7953, -2.1977, -1.7898,  ...,  1.5736, -1.8280,  1.1694],\n",
      "        [-1.5209, -1.8428, -1.5173,  ...,  1.4330, -1.6008,  1.0197],\n",
      "        [-1.3293, -1.5774, -1.3241,  ...,  1.3042, -1.4363,  0.8836],\n",
      "        ...,\n",
      "        [-0.8956, -1.2582, -0.9075,  ...,  0.4119, -0.3410, -0.2938],\n",
      "        [-0.7925, -1.1158, -0.8026,  ...,  0.2914, -0.1914, -0.3838],\n",
      "        [-0.6968, -0.9936, -0.7069,  ...,  0.1736, -0.0441, -0.4659]])\n",
      "tensor([[-0.6070, -0.8852, -0.6166,  ...,  0.0621,  0.1053, -0.5414],\n",
      "        [-0.5211, -0.7856, -0.5326,  ..., -0.0446,  0.2415, -0.6148],\n",
      "        [-0.4403, -0.6940, -0.4512,  ..., -0.1455,  0.3699, -0.6793],\n",
      "        ...,\n",
      "        [-0.3215, -0.2343, -0.3091,  ...,  0.6339, -0.7146,  0.6998],\n",
      "        [-0.2505, -0.1654, -0.2385,  ...,  0.5730, -0.6661,  0.6496],\n",
      "        [-0.1807, -0.0951, -0.1689,  ...,  0.5130, -0.6105,  0.6015]])\n",
      "tensor([[-0.1111, -0.0242, -0.1000,  ...,  0.4565, -0.5485,  0.5554],\n",
      "        [-0.0420,  0.0470, -0.0310,  ...,  0.3976, -0.4725,  0.5085],\n",
      "        [ 0.0274,  0.1179,  0.0380,  ...,  0.3449, -0.3862,  0.4673],\n",
      "        ...,\n",
      "        [ 0.2685,  0.2072,  0.2717,  ..., -0.1673,  0.1384, -0.1985],\n",
      "        [ 0.3405,  0.2792,  0.3441,  ..., -0.2162,  0.2579, -0.2335],\n",
      "        [ 0.4148,  0.3523,  0.4189,  ..., -0.2659,  0.2874, -0.2677]])\n",
      "tensor([[ 0.4921,  0.4266,  0.4955,  ..., -0.3143,  0.2874, -0.3014],\n",
      "        [ 0.5710,  0.5017,  0.5757,  ..., -0.3594,  0.2874, -0.3338],\n",
      "        [ 0.6544,  0.5799,  0.6594,  ..., -0.4046,  0.3015, -0.3644],\n",
      "        ...,\n",
      "        [ 0.9089,  0.8589,  0.9191,  ..., -0.3714,  0.5042, -0.2727],\n",
      "        [ 1.0183,  0.9615,  1.0303,  ..., -0.4110,  0.5845, -0.3015],\n",
      "        [ 1.1410,  1.0754,  1.1561,  ..., -0.4510,  0.5866, -0.3291]])\n",
      "tensor([[ 1.2818,  1.2065,  1.3015,  ..., -0.4893,  0.5866, -0.3572],\n",
      "        [ 1.4458,  1.3613,  1.4710,  ..., -0.5275,  0.5866, -0.3825],\n",
      "        [ 1.6417,  1.5597,  1.6809,  ..., -0.5617,  0.5866, -0.4079],\n",
      "        ...,\n",
      "        [-1.6808, -1.5431, -1.7178,  ...,  1.0082, -1.0954,  0.6253],\n",
      "        [-1.4254, -1.3374, -1.4517,  ...,  0.8322, -0.9048,  0.4889],\n",
      "        [-1.2431, -1.1594, -1.2630,  ...,  0.6819, -0.8215,  0.3742]])\n",
      "tensor([[-1.0960, -1.0188, -1.1137,  ...,  0.5442, -0.7435,  0.2769],\n",
      "        [-0.9704, -0.8829, -0.9870,  ...,  0.4142, -0.6209,  0.1920],\n",
      "        [-0.8589, -0.7884, -0.8730,  ...,  0.2947, -0.4642,  0.1220],\n",
      "        ...,\n",
      "        [-0.5615, -0.7084, -0.5682,  ...,  0.1756, -0.1907, -0.2650],\n",
      "        [-0.4806, -0.6211, -0.4868,  ...,  0.0843, -0.0928, -0.3314],\n",
      "        [-0.4030, -0.5364, -0.4080,  ..., -0.0041,  0.0564, -0.3954]])\n",
      "tensor([[-0.3275, -0.4553, -0.3326,  ..., -0.0897,  0.2135, -0.4528],\n",
      "        [-0.2538, -0.3782, -0.2588,  ..., -0.1672,  0.3594, -0.5090],\n",
      "        [-0.1810, -0.3041, -0.1867,  ..., -0.2422,  0.3764, -0.5621],\n",
      "        ...,\n",
      "        [-0.1373,  0.0400, -0.1270,  ...,  0.5145, -0.5309,  0.7792],\n",
      "        [-0.0700,  0.1092, -0.0587,  ...,  0.4613, -0.5047,  0.7379],\n",
      "        [-0.0025,  0.1785,  0.0097,  ...,  0.4061, -0.4745,  0.6980]])\n",
      "tensor([[ 0.0650,  0.2490,  0.0784,  ...,  0.3574, -0.4252,  0.6578],\n",
      "        [ 0.1333,  0.3234,  0.1475,  ...,  0.3067, -0.3704,  0.6187],\n",
      "        [ 0.2019,  0.4029,  0.2165,  ...,  0.2582, -0.3009,  0.5853],\n",
      "        ...,\n",
      "        [ 0.3376,  0.5235,  0.3638,  ...,  0.4268, -0.3602,  0.7237],\n",
      "        [ 0.4099,  0.6029,  0.4364,  ...,  0.3851, -0.3335,  0.6916],\n",
      "        [ 0.4848,  0.6873,  0.5111,  ...,  0.3444, -0.2954,  0.6578]])\n",
      "tensor([[ 0.5628,  0.7761,  0.5881,  ...,  0.3028, -0.2557,  0.6249],\n",
      "        [ 0.6441,  0.8728,  0.6705,  ...,  0.2653, -0.2104,  0.5940],\n",
      "        [ 0.7301,  0.9779,  0.7564,  ...,  0.2263, -0.1626,  0.5635],\n",
      "        ...,\n",
      "        [ 1.8557,  1.4277,  1.8134,  ..., -1.6637,  1.6949, -1.4950],\n",
      "        [ 2.1518,  1.6533,  2.1189,  ..., -1.6954,  1.7872, -1.5215],\n",
      "        [ 2.5309,  1.9607,  2.5321,  ..., -1.7309,  1.8663, -1.5494]])\n",
      "tensor([[-1.6568, -2.6021, -1.7643,  ...,  0.3089, -0.5079, -0.4905],\n",
      "        [-1.4008, -2.0877, -1.4726,  ...,  0.0874, -0.2687, -0.6403],\n",
      "        [-1.2168, -1.7387, -1.2712,  ..., -0.1120, -0.0917, -0.7665],\n",
      "        ...,\n",
      "        [-1.0022, -1.1201, -0.9955,  ...,  1.0084, -0.8115,  0.5883],\n",
      "        [-0.8937, -0.9989, -0.8886,  ...,  0.8983, -0.7061,  0.4872],\n",
      "        [-0.7947, -0.8952, -0.7895,  ...,  0.7938, -0.5997,  0.3974]])\n",
      "tensor([[-0.7025, -0.7958, -0.6979,  ...,  0.6951, -0.4706,  0.3155],\n",
      "        [-0.6159, -0.7006, -0.6116,  ...,  0.6033, -0.4165,  0.2396],\n",
      "        [-0.5332, -0.6140, -0.5297,  ...,  0.5155, -0.3360,  0.1713],\n",
      "        ...,\n",
      "        [-0.3513, -0.2351, -0.3415,  ...,  0.6835, -0.7470,  0.7748],\n",
      "        [-0.2796, -0.1635, -0.2700,  ...,  0.6232, -0.6633,  0.7231],\n",
      "        [-0.2110, -0.0906, -0.2005,  ...,  0.5645, -0.5850,  0.6794]])\n",
      "tensor([[-0.1432, -0.0208, -0.1317,  ...,  0.5089, -0.5092,  0.6336],\n",
      "        [-0.0760,  0.0440, -0.0628,  ...,  0.4552, -0.4676,  0.5918],\n",
      "        [-0.0082,  0.1119,  0.0064,  ...,  0.3990, -0.4217,  0.5487],\n",
      "        ...,\n",
      "        [ 0.3790,  0.3131,  0.3655,  ..., -0.9894,  0.8480, -0.8221],\n",
      "        [ 0.4568,  0.3869,  0.4428,  ..., -1.0389,  0.8480, -0.8511],\n",
      "        [ 0.5368,  0.4628,  0.5223,  ..., -1.0860,  0.8517, -0.8818]])\n",
      "tensor([[ 0.6214,  0.5415,  0.6057,  ..., -1.1316,  0.8900, -0.9100],\n",
      "        [ 0.7101,  0.6234,  0.6935,  ..., -1.1740,  0.9416, -0.9360],\n",
      "        [ 0.8044,  0.7112,  0.7865,  ..., -1.2155,  1.0038, -0.9626],\n",
      "        ...,\n",
      "        [ 0.5646,  1.0724,  0.6227,  ...,  0.4235, -0.2268,  0.9503],\n",
      "        [ 0.6740,  1.1901,  0.7063,  ...,  0.3859, -0.1711,  0.9204],\n",
      "        [ 0.7604,  1.3341,  0.7954,  ...,  0.3490, -0.1112,  0.8893]])\n",
      "tensor([[ 0.8519,  1.5136,  0.8920,  ...,  0.3125, -0.0409,  0.8589],\n",
      "        [ 0.9521,  1.7608,  0.9978,  ...,  0.2783,  0.0279,  0.8281],\n",
      "        [ 1.0632,  2.0835,  1.1150,  ...,  0.2443,  0.1067,  0.7945],\n",
      "        ...,\n",
      "        [-2.0134, -1.6847, -1.9400,  ...,  2.3210, -2.3930,  2.1787],\n",
      "        [-1.6949, -1.4793, -1.6365,  ...,  2.1447, -2.1577,  2.0231],\n",
      "        [-1.4828, -1.3107, -1.4391,  ...,  1.9654, -1.9220,  1.8850]])\n",
      "tensor([[-1.3195, -1.1685, -1.2852,  ...,  1.8107, -1.7347,  1.7721],\n",
      "        [-1.1841, -1.0442, -1.1543,  ...,  1.6678, -1.5992,  1.6708],\n",
      "        [-1.0682, -0.9340, -1.0401,  ...,  1.5408, -1.4679,  1.5778],\n",
      "        ...,\n",
      "        [-0.5832, -0.6235, -0.5885,  ...,  0.3616, -0.5214,  0.2091],\n",
      "        [-0.5011, -0.5430, -0.5065,  ...,  0.2806, -0.4902,  0.1501],\n",
      "        [-0.4215, -0.4632, -0.4275,  ...,  0.2050, -0.4169,  0.0951]])\n",
      "tensor([[-0.3452, -0.3853, -0.3514,  ...,  0.1327, -0.3208,  0.0435],\n",
      "        [-0.2713, -0.3121, -0.2779,  ...,  0.0623, -0.2042, -0.0073],\n",
      "        [-0.1999, -0.2421, -0.2051,  ..., -0.0062, -0.0921, -0.0553],\n",
      "        ...,\n",
      "        [-0.2178, -0.0345, -0.1964,  ...,  0.8479, -0.7547,  1.1505],\n",
      "        [-0.1509,  0.0333, -0.1298,  ...,  0.7979, -0.7054,  1.1053],\n",
      "        [-0.0854,  0.1031, -0.0627,  ...,  0.7468, -0.6502,  1.0614]])\n",
      "tensor([[-0.0184,  0.1727,  0.0049,  ...,  0.6994, -0.5895,  1.0214],\n",
      "        [ 0.0480,  0.2427,  0.0707,  ...,  0.6511, -0.5269,  0.9774],\n",
      "        [ 0.1145,  0.3141,  0.1375,  ...,  0.6080, -0.4542,  0.9412],\n",
      "        ...,\n",
      "        [ 0.4554,  0.5651,  0.4706,  ...,  0.1675, -0.1872,  0.3682],\n",
      "        [ 0.5326,  0.6492,  0.5479,  ...,  0.1239, -0.1329,  0.3342],\n",
      "        [ 0.6126,  0.7379,  0.6292,  ...,  0.0804, -0.0774,  0.3018]])\n",
      "tensor([[ 0.6966,  0.8310,  0.7151,  ...,  0.0391, -0.0163,  0.2708],\n",
      "        [ 0.7861,  0.9327,  0.8061,  ..., -0.0027,  0.0448,  0.2413],\n",
      "        [ 0.8825,  1.0445,  0.9050,  ..., -0.0414,  0.1114,  0.2137],\n",
      "        ...,\n",
      "        [ 1.1702,  1.8187,  1.1928,  ..., -0.1924,  0.4104,  0.3221],\n",
      "        [ 1.3153,  2.1489,  1.3425,  ..., -0.2251,  0.4608,  0.2941],\n",
      "        [ 1.4832,  2.5756,  1.5184,  ..., -0.2585,  0.5172,  0.2680]])\n",
      "tensor([[-2.8071, -3.3720, -2.8458,  ...,  1.8670, -1.8139,  1.2767],\n",
      "        [-2.0827, -2.5913, -2.0787,  ...,  1.6044, -1.5400,  1.0847],\n",
      "        [-1.6803, -2.0956, -1.6775,  ...,  1.3919, -1.3143,  0.9132],\n",
      "        ...,\n",
      "        [-1.1433, -1.2420, -1.1307,  ...,  1.2792, -1.2370,  1.0089],\n",
      "        [-1.0224, -1.1032, -1.0109,  ...,  1.1647, -1.1251,  0.9040],\n",
      "        [-0.9136, -0.9868, -0.9040,  ...,  1.0552, -0.9860,  0.8122]])\n",
      "tensor([[-0.8167, -0.8831, -0.8061,  ...,  0.9576, -0.9186,  0.7253],\n",
      "        [-0.7250, -0.7850, -0.7148,  ...,  0.8673, -0.8510,  0.6459],\n",
      "        [-0.6392, -0.6928, -0.6303,  ...,  0.7829, -0.7523,  0.5687],\n",
      "        ...,\n",
      "        [-0.2111, -0.4515, -0.2318,  ..., -0.9693,  1.1916, -1.2497],\n",
      "        [-0.1373, -0.3753, -0.1585,  ..., -1.0492,  1.2728, -1.2981],\n",
      "        [-0.0653, -0.3011, -0.0857,  ..., -1.1238,  1.3447, -1.3455]])\n",
      "tensor([[ 0.0061, -0.2289, -0.0143,  ..., -1.1951,  1.4244, -1.3947],\n",
      "        [ 0.0774, -0.1576,  0.0574,  ..., -1.2595,  1.4986, -1.4389],\n",
      "        [ 0.1490, -0.0863,  0.1289,  ..., -1.3194,  1.5871, -1.4848],\n",
      "        ...,\n",
      "        [ 0.3470,  0.2469,  0.3322,  ..., -0.9385,  0.9070, -0.8406],\n",
      "        [ 0.4229,  0.3202,  0.4070,  ..., -0.9880,  1.0052, -0.8741],\n",
      "        [ 0.5012,  0.3953,  0.4851,  ..., -1.0353,  1.1000, -0.9044]])\n",
      "tensor([[ 0.5827,  0.4720,  0.5662,  ..., -1.0818,  1.1282, -0.9329],\n",
      "        [ 0.6675,  0.5516,  0.6512,  ..., -1.1258,  1.1282, -0.9627],\n",
      "        [ 0.7588,  0.6339,  0.7410,  ..., -1.1670,  1.1282, -0.9900],\n",
      "        ...,\n",
      "        [ 1.0853,  0.9172,  1.0512,  ..., -1.5215,  1.5259, -1.2816],\n",
      "        [ 1.2209,  1.0288,  1.1815,  ..., -1.5586,  1.6268, -1.3074],\n",
      "        [ 1.3775,  1.1544,  1.3337,  ..., -1.5937,  1.6336, -1.3342]])\n",
      "tensor([[ 1.5628,  1.2987,  1.5126,  ..., -1.6236,  1.6090, -1.3613],\n",
      "        [ 1.7827,  1.4805,  1.7346,  ..., -1.6576,  1.6147, -1.3888],\n",
      "        [ 2.0578,  1.7243,  2.0104,  ..., -1.6904,  1.6386, -1.4140],\n",
      "        ...,\n",
      "        [-1.6156, -1.8187, -1.5987,  ...,  1.5488, -1.5603,  1.1512],\n",
      "        [-1.4045, -1.5547, -1.3905,  ...,  1.3752, -1.3931,  1.0010],\n",
      "        [-1.2406, -1.3553, -1.2291,  ...,  1.2203, -1.2472,  0.8726]])\n",
      "tensor([[-1.1032, -1.1982, -1.0948,  ...,  1.0904, -1.1131,  0.7589],\n",
      "        [-0.9846, -1.0619, -0.9772,  ...,  0.9654, -1.0266,  0.6577],\n",
      "        [-0.8770, -0.9448, -0.8719,  ...,  0.8546, -0.8872,  0.5649],\n",
      "        ...,\n",
      "        [-0.4048, -0.6515, -0.4352,  ..., -2.2482,  1.2799, -2.3914],\n",
      "        [-0.3262, -0.5611, -0.3542,  ..., -2.3272,  1.5640, -2.5451],\n",
      "        [-0.2485, -0.4801, -0.2764,  ..., -2.4084,  1.7728, -2.5788]])\n",
      "tensor([[-1.7314e-01, -4.0246e-01, -2.0025e-01, -1.4414e+00, -1.5589e+00,\n",
      "         -2.4850e+00,  1.5868e+00, -2.6232e+00],\n",
      "        [-9.9057e-02, -3.2662e-01, -1.2514e-01, -1.3857e+00, -1.5876e+00,\n",
      "         -2.5499e+00,  1.9723e+00, -2.6602e+00],\n",
      "        [-2.5705e-02, -2.5187e-01, -5.1552e-02, -1.3381e+00, -1.5844e+00,\n",
      "         -2.6089e+00,  2.0509e+00, -2.7008e+00],\n",
      "        [ 4.6871e-02, -1.7855e-01,  2.1183e-02, -1.2918e+00, -1.5349e+00,\n",
      "         -2.6626e+00,  2.1517e+00, -2.7419e+00],\n",
      "        [ 1.1971e-01, -1.0508e-01,  9.4226e-02, -1.2470e+00, -1.4691e+00,\n",
      "         -2.7016e+00,  2.2617e+00, -2.7732e+00],\n",
      "        [ 1.9241e-01, -3.3226e-02,  1.6816e-01, -1.2032e+00, -1.4513e+00,\n",
      "         -2.7405e+00,  2.3456e+00, -2.8027e+00],\n",
      "        [ 2.6638e-01,  3.8057e-02,  2.4342e-01, -1.1643e+00, -1.4560e+00,\n",
      "         -2.7796e+00,  2.3376e+00, -2.8322e+00],\n",
      "        [ 3.4361e-01,  1.0937e-01,  3.1927e-01, -1.1249e+00, -1.4671e+00,\n",
      "         -2.8192e+00,  2.5968e+00, -2.8617e+00],\n",
      "        [ 4.2160e-01,  1.8046e-01,  3.9725e-01, -1.0880e+00, -1.4792e+00,\n",
      "         -2.8596e+00,  2.5218e+00, -2.8892e+00],\n",
      "        [ 5.0181e-01,  2.5267e-01,  4.7706e-01, -1.0547e+00, -1.4821e+00,\n",
      "         -2.8950e+00,  2.6476e+00, -2.9143e+00],\n",
      "        [ 5.8499e-01,  3.2711e-01,  5.5956e-01, -1.0241e+00, -1.4743e+00,\n",
      "         -2.9260e+00,  2.8136e+00, -2.9394e+00],\n",
      "        [ 6.7248e-01,  4.0353e-01,  6.4596e-01, -9.9067e-01, -1.4552e+00,\n",
      "         -2.9572e+00,  2.7450e+00, -2.9646e+00],\n",
      "        [ 7.6572e-01,  4.8348e-01,  7.3912e-01, -9.6083e-01, -1.4335e+00,\n",
      "         -2.9888e+00,  2.7559e+00, -2.9899e+00],\n",
      "        [ 8.6615e-01,  5.6552e-01,  8.3668e-01, -9.2829e-01, -1.4187e+00,\n",
      "         -3.0209e+00,  2.9796e+00, -3.0156e+00],\n",
      "        [ 9.7423e-01,  6.5094e-01,  9.4372e-01, -8.9729e-01, -1.4149e+00,\n",
      "         -3.0537e+00,  3.1378e+00, -3.0416e+00],\n",
      "        [ 1.0958e+00,  7.4050e-01,  1.0644e+00, -8.6766e-01, -1.4250e+00,\n",
      "         -3.0875e+00,  3.1750e+00, -3.0681e+00],\n",
      "        [ 1.2350e+00,  8.3716e-01,  1.2014e+00, -8.3775e-01, -1.4407e+00,\n",
      "         -3.1187e+00,  3.1003e+00, -3.0948e+00],\n",
      "        [ 1.3969e+00,  9.4093e-01,  1.3619e+00, -8.1121e-01, -1.4639e+00,\n",
      "         -3.1505e+00,  3.0854e+00, -3.1202e+00],\n",
      "        [ 1.5908e+00,  1.0575e+00,  1.5544e+00, -7.8893e-01, -1.5002e+00,\n",
      "         -3.1834e+00,  3.1367e+00, -3.1463e+00],\n",
      "        [ 1.8273e+00,  1.1875e+00,  1.7872e+00, -7.6315e-01, -1.5334e+00,\n",
      "         -3.2177e+00,  3.1721e+00, -3.1731e+00],\n",
      "        [ 2.1195e+00,  1.3429e+00,  2.0932e+00, -7.3646e-01, -1.5638e+00,\n",
      "         -3.2538e+00,  3.0871e+00, -3.2008e+00],\n",
      "        [ 2.4912e+00,  1.5431e+00,  2.5089e+00, -7.1196e-01, -1.5862e+00,\n",
      "         -3.2921e+00,  2.9835e+00, -3.2297e+00],\n",
      "        [ 3.0531e+00,  1.8230e+00,  3.0999e+00, -6.8954e-01, -1.5995e+00,\n",
      "         -3.3331e+00,  2.9173e+00, -3.2598e+00],\n",
      "        [ 5.1993e+00,  2.1973e+00,  5.1993e+00, -6.6985e-01, -1.6045e+00,\n",
      "         -3.3778e+00,  2.9391e+00, -3.2916e+00],\n",
      "        [-2.5050e+00, -1.7990e+00, -2.6113e+00, -9.1966e-01,  5.9848e-01,\n",
      "          1.6387e+00, -1.7201e+00,  1.4534e+00],\n",
      "        [-1.8986e+00, -1.5381e+00, -1.9194e+00, -6.0574e-01,  5.7407e-01,\n",
      "          1.4316e+00, -1.4752e+00,  1.2990e+00],\n",
      "        [-1.5777e+00, -1.3319e+00, -1.5842e+00, -4.4354e-01,  5.8913e-01,\n",
      "          1.2633e+00, -1.3484e+00,  1.1651e+00],\n",
      "        [-1.3611e+00, -1.1721e+00, -1.3708e+00, -3.2590e-01,  5.7837e-01,\n",
      "          1.1160e+00, -1.1997e+00,  1.0467e+00],\n",
      "        [-1.1983e+00, -1.0435e+00, -1.2064e+00, -2.1825e-01,  5.4425e-01,\n",
      "          9.8990e-01, -1.0487e+00,  9.4377e-01],\n",
      "        [-1.0618e+00, -9.3054e-01, -1.0670e+00, -1.2374e-01,  5.2753e-01,\n",
      "          8.7734e-01, -9.7067e-01,  8.5137e-01],\n",
      "        [-9.4285e-01, -8.2383e-01, -9.4783e-01, -3.9401e-02,  5.5498e-01,\n",
      "          7.7208e-01, -8.6681e-01,  7.6740e-01],\n",
      "        [-8.3735e-01, -7.2628e-01, -8.4092e-01,  6.5392e-02,  5.6432e-01,\n",
      "          6.7463e-01, -7.4042e-01,  6.9273e-01],\n",
      "        [-7.3981e-01, -6.4083e-01, -7.4311e-01,  1.2086e-01,  5.6295e-01,\n",
      "          5.8647e-01, -6.8229e-01,  6.2023e-01],\n",
      "        [-6.4929e-01, -5.5972e-01, -6.5183e-01,  1.9062e-01,  5.3997e-01,\n",
      "          4.9964e-01, -6.2108e-01,  5.5365e-01],\n",
      "        [-5.6430e-01, -4.7972e-01, -5.6596e-01,  3.0442e-01,  5.1733e-01,\n",
      "          4.2102e-01, -5.4547e-01,  4.8873e-01],\n",
      "        [-4.8337e-01, -4.0210e-01, -4.8504e-01,  3.6141e-01,  5.3578e-01,\n",
      "          3.4472e-01, -4.5166e-01,  4.3232e-01],\n",
      "        [-4.0532e-01, -3.2577e-01, -4.0649e-01,  3.8776e-01,  5.9010e-01,\n",
      "          2.7117e-01, -3.7504e-01,  3.7568e-01],\n",
      "        [-3.2973e-01, -2.5225e-01, -3.3071e-01,  4.2627e-01,  6.1138e-01,\n",
      "          2.0125e-01, -3.3803e-01,  3.2244e-01],\n",
      "        [-2.5672e-01, -1.8111e-01, -2.5750e-01,  4.9118e-01,  5.9337e-01,\n",
      "          1.3446e-01, -2.8575e-01,  2.7196e-01],\n",
      "        [-1.8419e-01, -1.1192e-01, -1.8559e-01,  5.5179e-01,  5.6733e-01,\n",
      "          6.9657e-02, -2.3003e-01,  2.2718e-01],\n",
      "        [-1.1218e-01, -4.3132e-02, -1.1430e-01,  5.7695e-01,  5.5790e-01,\n",
      "          8.7816e-03, -1.6524e-01,  1.8281e-01],\n",
      "        [-4.1427e-02,  2.5563e-02, -4.3775e-02,  5.8947e-01,  5.6562e-01,\n",
      "         -4.9515e-02, -8.2002e-02,  1.4480e-01],\n",
      "        [ 2.9271e-02,  9.5296e-02,  2.6375e-02,  6.0506e-01,  5.9248e-01,\n",
      "         -1.0750e-01,  2.9633e-03,  1.0271e-01],\n",
      "        [ 9.9981e-02,  1.6809e-01,  9.7145e-02,  6.3029e-01,  6.2968e-01,\n",
      "         -1.5994e-01,  3.1315e-02,  6.3618e-02],\n",
      "        [ 1.7138e-01,  2.4190e-01,  1.6768e-01,  6.7388e-01,  6.5435e-01,\n",
      "         -2.1126e-01,  7.3606e-02,  2.6903e-02],\n",
      "        [ 2.4328e-01,  3.1519e-01,  2.3926e-01,  7.1966e-01,  6.4882e-01,\n",
      "         -2.6033e-01,  1.1441e-01, -6.4607e-03],\n",
      "        [ 3.1665e-01,  3.8904e-01,  3.1272e-01,  7.4968e-01,  6.3411e-01,\n",
      "         -3.0974e-01,  1.6082e-01, -4.0892e-02],\n",
      "        [ 3.9165e-01,  4.6410e-01,  3.8753e-01,  7.6592e-01,  6.2109e-01,\n",
      "         -3.5402e-01,  2.1506e-01, -7.3246e-02],\n",
      "        [ 4.6883e-01,  5.4152e-01,  4.6455e-01,  7.7890e-01,  6.1509e-01,\n",
      "         -3.9885e-01,  2.7836e-01, -1.0316e-01],\n",
      "        [ 5.4855e-01,  6.2250e-01,  5.4426e-01,  7.9622e-01,  6.0992e-01,\n",
      "         -4.4131e-01,  3.5536e-01, -1.3431e-01],\n",
      "        [ 6.3180e-01,  7.0882e-01,  6.2781e-01,  8.1875e-01,  6.0768e-01,\n",
      "         -4.8236e-01,  4.3899e-01, -1.6576e-01],\n",
      "        [ 7.2050e-01,  8.0192e-01,  7.1603e-01,  8.5089e-01,  6.0844e-01,\n",
      "         -5.2189e-01,  4.6140e-01, -1.9335e-01],\n",
      "        [ 8.1499e-01,  9.0387e-01,  8.0932e-01,  8.8932e-01,  6.1796e-01,\n",
      "         -5.5969e-01,  4.8494e-01, -2.2301e-01],\n",
      "        [ 9.1691e-01,  1.0206e+00,  9.1085e-01,  9.3183e-01,  6.4082e-01,\n",
      "         -5.9993e-01,  5.1298e-01, -2.4936e-01],\n",
      "        [ 1.0292e+00,  1.1527e+00,  1.0231e+00,  9.7478e-01,  6.5735e-01,\n",
      "         -6.3859e-01,  5.4100e-01, -2.7540e-01],\n",
      "        [ 1.1552e+00,  1.3010e+00,  1.1509e+00,  1.0051e+00,  6.6412e-01,\n",
      "         -6.7368e-01,  5.7852e-01, -3.0203e-01],\n",
      "        [ 1.3003e+00,  1.4836e+00,  1.2981e+00,  1.0349e+00,  6.5921e-01,\n",
      "         -7.0872e-01,  6.2253e-01, -3.2795e-01],\n",
      "        [ 1.4687e+00,  1.7264e+00,  1.4701e+00,  1.0608e+00,  6.5165e-01,\n",
      "         -7.4320e-01,  6.7309e-01, -3.5482e-01],\n",
      "        [ 1.6721e+00,  2.0542e+00,  1.6839e+00,  1.0858e+00,  6.4245e-01,\n",
      "         -7.7606e-01,  7.3363e-01, -3.7841e-01],\n",
      "        [ 1.9181e+00,  2.4906e+00,  1.9462e+00,  1.1135e+00,  6.3126e-01,\n",
      "         -8.1160e-01,  7.9409e-01, -4.0457e-01],\n",
      "        [-2.2713e+00, -2.4110e+00, -2.2459e+00, -2.0518e+00, -4.5508e-01,\n",
      "          1.9501e+00, -1.8869e+00,  1.4555e+00],\n",
      "        [-1.8198e+00, -2.0238e+00, -1.7761e+00, -1.8246e+00, -4.2803e-01,\n",
      "          1.7272e+00, -1.5849e+00,  1.2835e+00],\n",
      "        [-1.5443e+00, -1.7263e+00, -1.5215e+00, -1.5959e+00, -4.1191e-01,\n",
      "          1.5323e+00, -1.4179e+00,  1.1295e+00],\n",
      "        [-1.3498e+00, -1.4830e+00, -1.3363e+00, -1.4016e+00, -3.0429e-01,\n",
      "          1.3739e+00, -1.2187e+00,  9.9036e-01],\n",
      "        [-1.1961e+00, -1.3041e+00, -1.1846e+00, -1.2318e+00, -2.8298e-01,\n",
      "          1.2284e+00, -1.1290e+00,  8.6532e-01],\n",
      "        [-1.0645e+00, -1.1596e+00, -1.0573e+00, -1.0784e+00, -2.7228e-01,\n",
      "          1.1048e+00, -9.8911e-01,  7.5394e-01],\n",
      "        [-9.5114e-01, -1.0318e+00, -9.4257e-01, -9.5022e-01, -2.1191e-01,\n",
      "          9.8864e-01, -8.4587e-01,  6.5042e-01],\n",
      "        [-8.4651e-01, -9.1887e-01, -8.3901e-01, -8.2028e-01, -1.7988e-01,\n",
      "          8.8518e-01, -7.8426e-01,  5.5595e-01],\n",
      "        [-7.5035e-01, -8.1647e-01, -7.4444e-01, -7.0030e-01, -1.2736e-01,\n",
      "          7.8592e-01, -6.7209e-01,  4.6734e-01],\n",
      "        [-6.6071e-01, -7.2490e-01, -6.5554e-01, -6.1165e-01, -1.3133e-01,\n",
      "          6.9202e-01, -5.3986e-01,  3.8556e-01],\n",
      "        [-5.7611e-01, -6.3784e-01, -5.7186e-01, -5.4397e-01, -1.1697e-01,\n",
      "          6.0534e-01, -4.1117e-01,  3.1105e-01],\n",
      "        [-4.9508e-01, -5.5481e-01, -4.9221e-01, -4.9041e-01, -1.1048e-01,\n",
      "          5.2048e-01, -3.8152e-01,  2.4258e-01],\n",
      "        [-4.1732e-01, -4.7353e-01, -4.1478e-01, -4.4512e-01, -5.5424e-02,\n",
      "          4.4115e-01, -3.0652e-01,  1.8021e-01],\n",
      "        [-3.4215e-01, -3.9436e-01, -3.3987e-01, -4.1032e-01,  3.7989e-02,\n",
      "          3.6376e-01, -2.0610e-01,  1.2198e-01],\n",
      "        [-2.6864e-01, -3.2147e-01, -2.6647e-01, -3.7604e-01,  2.4441e-02,\n",
      "          2.8685e-01, -7.7828e-02,  6.6497e-02],\n",
      "        [-1.9644e-01, -2.5103e-01, -1.9432e-01, -3.4207e-01, -5.9188e-03,\n",
      "          2.1274e-01,  6.5379e-02,  1.4130e-02],\n",
      "        [-1.2561e-01, -1.8152e-01, -1.2373e-01, -3.0756e-01, -3.2859e-02,\n",
      "          1.4375e-01,  4.9975e-02, -3.5367e-02],\n",
      "        [-5.5595e-02, -1.1194e-01, -5.3842e-02, -2.7136e-01, -2.8552e-02,\n",
      "          7.5635e-02,  8.4868e-02, -8.1474e-02],\n",
      "        [ 1.4525e-02, -3.8829e-02,  1.6307e-02, -2.3817e-01,  2.7268e-02,\n",
      "          1.0741e-02,  1.4497e-01, -1.2492e-01],\n",
      "        [ 8.4378e-02,  3.4014e-02,  8.6193e-02, -2.0934e-01,  1.1413e-01,\n",
      "         -5.1985e-02,  2.3018e-01, -1.6902e-01],\n",
      "        [ 1.5468e-01,  1.0644e-01,  1.5715e-01, -1.7784e-01,  1.5075e-01,\n",
      "         -1.1389e-01,  3.2652e-01, -2.0860e-01],\n",
      "        [ 2.2572e-01,  1.7610e-01,  2.2842e-01, -1.4633e-01,  1.4096e-01,\n",
      "         -1.7305e-01,  4.3258e-01, -2.4875e-01],\n",
      "        [ 2.9761e-01,  2.4605e-01,  3.0043e-01, -1.1404e-01,  1.1348e-01,\n",
      "         -2.2847e-01,  5.2911e-01, -2.8901e-01],\n",
      "        [ 3.7249e-01,  3.1714e-01,  3.7444e-01, -7.8814e-02,  8.3013e-02,\n",
      "         -2.8363e-01,  4.7216e-01, -3.2448e-01],\n",
      "        [ 4.4816e-01,  3.8922e-01,  4.5064e-01, -4.4863e-02,  5.3162e-02,\n",
      "         -3.3521e-01,  4.7232e-01, -3.6127e-01],\n",
      "        [ 5.2735e-01,  4.6478e-01,  5.3001e-01, -1.2778e-02,  2.2139e-02,\n",
      "         -3.8539e-01,  5.0640e-01, -3.9809e-01],\n",
      "        [ 6.0953e-01,  5.4376e-01,  6.1207e-01,  1.9586e-02,  1.6594e-02,\n",
      "         -4.3383e-01,  5.5523e-01, -4.3067e-01],\n",
      "        [ 6.9576e-01,  6.3297e-01,  6.9906e-01,  5.2856e-02,  1.1675e-01,\n",
      "         -4.8124e-01,  6.1811e-01, -4.6381e-01],\n",
      "        [ 7.8849e-01,  7.3272e-01,  7.9074e-01,  8.4834e-02,  2.4641e-01,\n",
      "         -5.2740e-01,  6.8956e-01, -4.9636e-01],\n",
      "        [ 8.8777e-01,  8.2787e-01,  8.9063e-01,  1.1652e-01,  2.4381e-01,\n",
      "         -5.7167e-01,  7.6057e-01, -5.2645e-01],\n",
      "        [ 9.9715e-01,  9.2837e-01,  1.0007e+00,  1.5196e-01,  2.2296e-01,\n",
      "         -6.1535e-01,  8.3872e-01, -5.5632e-01],\n",
      "        [ 1.1195e+00,  1.0398e+00,  1.1235e+00,  1.8802e-01,  1.9792e-01,\n",
      "         -6.5745e-01,  9.1115e-01, -5.8677e-01],\n",
      "        [ 1.2596e+00,  1.1637e+00,  1.2648e+00,  2.2505e-01,  1.7052e-01,\n",
      "         -6.9904e-01,  8.2240e-01, -6.1703e-01],\n",
      "        [ 1.4216e+00,  1.3089e+00,  1.4319e+00,  2.6181e-01,  1.4152e-01,\n",
      "         -7.4081e-01,  7.9908e-01, -6.4409e-01],\n",
      "        [ 1.6162e+00,  1.4910e+00,  1.6337e+00,  3.0043e-01,  1.0572e-01,\n",
      "         -7.7872e-01,  8.1072e-01, -6.7331e-01],\n",
      "        [ 1.8511e+00,  1.7361e+00,  1.8826e+00,  3.3264e-01,  7.6235e-02,\n",
      "         -8.1978e-01,  8.4734e-01, -6.9787e-01]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(y)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BleveNet(\n",
      "  (fc1): Linear(in_features=11, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc5): Linear(in_features=128, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (mish): Mish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Define the NN architecture\n",
    "## NN with 3 hidden layer, s=[26, 256, 256, 256, 128, 8]\n",
    "\n",
    "class BleveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BleveNet, self).__init__()\n",
    "        # The first hidden layer has 256 neurons\n",
    "        self.fc1 = nn.Linear(X_train_torch.shape[1], 256)\n",
    "        # The second hidden layer has 256 neurons\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        # The third hidden layer has 256 neurons\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        # The fourth layer has 128 output neurons\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        # The final layer has 8 output neurons\n",
    "        self.fc5 = nn.Linear(128, 8)\n",
    "\n",
    "\n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Mish activation\n",
    "        self.mish = nn.Mish()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add third fully connected layer\n",
    "        x = self.fc3(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "        # add fourth fully connected layers\n",
    "        x = self.fc4(x)\n",
    "        x = self.mish(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # add final output layers:\n",
    "        output = self.fc5(x)\n",
    "       \n",
    "        return output\n",
    "\n",
    "# initialize the NN\n",
    "model = BleveNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.HuberLoss()        # This is the best loss function for my model\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)     # This is the best optimizer for my model \n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/500 \tTraining Loss: 0.116054\n",
      "Epoch: 2/500 \tTraining Loss: 0.050513\n",
      "Epoch: 3/500 \tTraining Loss: 0.038355\n",
      "Epoch: 4/500 \tTraining Loss: 0.033127\n",
      "Epoch: 5/500 \tTraining Loss: 0.029307\n",
      "Epoch: 6/500 \tTraining Loss: 0.027199\n",
      "Epoch: 7/500 \tTraining Loss: 0.024626\n",
      "Epoch: 8/500 \tTraining Loss: 0.027118\n",
      "Epoch: 9/500 \tTraining Loss: 0.024726\n",
      "Epoch: 10/500 \tTraining Loss: 0.027207\n",
      "Epoch: 11/500 \tTraining Loss: 0.022710\n",
      "Epoch: 12/500 \tTraining Loss: 0.021458\n",
      "Epoch: 13/500 \tTraining Loss: 0.021113\n",
      "Epoch: 14/500 \tTraining Loss: 0.023813\n",
      "Epoch: 15/500 \tTraining Loss: 0.021378\n",
      "Epoch: 16/500 \tTraining Loss: 0.026396\n",
      "Epoch: 17/500 \tTraining Loss: 0.031130\n",
      "Epoch: 18/500 \tTraining Loss: 0.029562\n",
      "Epoch: 19/500 \tTraining Loss: 0.022414\n",
      "Epoch: 20/500 \tTraining Loss: 0.021940\n",
      "Epoch: 21/500 \tTraining Loss: 0.022012\n",
      "Epoch: 22/500 \tTraining Loss: 0.026254\n",
      "Epoch: 23/500 \tTraining Loss: 0.026147\n",
      "Epoch: 24/500 \tTraining Loss: 0.020243\n",
      "Epoch: 25/500 \tTraining Loss: 0.016966\n",
      "Epoch: 26/500 \tTraining Loss: 0.017315\n",
      "Epoch: 27/500 \tTraining Loss: 0.020212\n",
      "Epoch: 28/500 \tTraining Loss: 0.020355\n",
      "Epoch: 29/500 \tTraining Loss: 0.019342\n",
      "Epoch: 30/500 \tTraining Loss: 0.019714\n",
      "Epoch: 31/500 \tTraining Loss: 0.020568\n",
      "Epoch: 32/500 \tTraining Loss: 0.024868\n",
      "Epoch: 33/500 \tTraining Loss: 0.020083\n",
      "Epoch: 34/500 \tTraining Loss: 0.019294\n",
      "Epoch: 35/500 \tTraining Loss: 0.018377\n",
      "Epoch: 36/500 \tTraining Loss: 0.018233\n",
      "Epoch: 37/500 \tTraining Loss: 0.018083\n",
      "Epoch: 38/500 \tTraining Loss: 0.017744\n",
      "Epoch: 39/500 \tTraining Loss: 0.019183\n",
      "Epoch: 40/500 \tTraining Loss: 0.017959\n",
      "Epoch: 41/500 \tTraining Loss: 0.019043\n",
      "Epoch: 42/500 \tTraining Loss: 0.019366\n",
      "Epoch: 43/500 \tTraining Loss: 0.017642\n",
      "Epoch: 44/500 \tTraining Loss: 0.019655\n",
      "Epoch: 45/500 \tTraining Loss: 0.019272\n",
      "Epoch: 46/500 \tTraining Loss: 0.018713\n",
      "Epoch: 47/500 \tTraining Loss: 0.018200\n",
      "Epoch: 48/500 \tTraining Loss: 0.021570\n",
      "Epoch: 49/500 \tTraining Loss: 0.022227\n",
      "Epoch: 50/500 \tTraining Loss: 0.020702\n",
      "Epoch: 51/500 \tTraining Loss: 0.022045\n",
      "Epoch: 52/500 \tTraining Loss: 0.019030\n",
      "Epoch: 53/500 \tTraining Loss: 0.017958\n",
      "Epoch: 54/500 \tTraining Loss: 0.032472\n",
      "Epoch: 55/500 \tTraining Loss: 0.024980\n",
      "Epoch: 56/500 \tTraining Loss: 0.037474\n",
      "Epoch: 57/500 \tTraining Loss: 0.032878\n",
      "Epoch: 58/500 \tTraining Loss: 0.022176\n",
      "Epoch: 59/500 \tTraining Loss: 0.024401\n",
      "Epoch: 60/500 \tTraining Loss: 0.021266\n",
      "Epoch: 61/500 \tTraining Loss: 0.024426\n",
      "Epoch: 62/500 \tTraining Loss: 0.025052\n",
      "Epoch: 63/500 \tTraining Loss: 0.021998\n",
      "Epoch: 64/500 \tTraining Loss: 0.022161\n",
      "Epoch: 65/500 \tTraining Loss: 0.018620\n",
      "Epoch: 66/500 \tTraining Loss: 0.020811\n",
      "Epoch: 67/500 \tTraining Loss: 0.019072\n",
      "Epoch: 68/500 \tTraining Loss: 0.020584\n",
      "Epoch: 69/500 \tTraining Loss: 0.019048\n",
      "Epoch: 70/500 \tTraining Loss: 0.017897\n",
      "Epoch: 71/500 \tTraining Loss: 0.020080\n",
      "Epoch: 72/500 \tTraining Loss: 0.022555\n",
      "Epoch: 73/500 \tTraining Loss: 0.016312\n",
      "Epoch: 74/500 \tTraining Loss: 0.018079\n",
      "Epoch: 75/500 \tTraining Loss: 0.027176\n",
      "Epoch: 76/500 \tTraining Loss: 0.020871\n",
      "Epoch: 77/500 \tTraining Loss: 0.022350\n",
      "Epoch: 78/500 \tTraining Loss: 0.019843\n",
      "Epoch: 79/500 \tTraining Loss: 0.018944\n",
      "Epoch: 80/500 \tTraining Loss: 0.016899\n",
      "Epoch: 81/500 \tTraining Loss: 0.016397\n",
      "Epoch: 82/500 \tTraining Loss: 0.016811\n",
      "Epoch: 83/500 \tTraining Loss: 0.017706\n",
      "Epoch: 84/500 \tTraining Loss: 0.016686\n",
      "Epoch: 85/500 \tTraining Loss: 0.015653\n",
      "Epoch: 86/500 \tTraining Loss: 0.015771\n",
      "Epoch: 87/500 \tTraining Loss: 0.016469\n",
      "Epoch: 88/500 \tTraining Loss: 0.018433\n",
      "Epoch: 89/500 \tTraining Loss: 0.020572\n",
      "Epoch: 90/500 \tTraining Loss: 0.026302\n",
      "Epoch: 91/500 \tTraining Loss: 0.032771\n",
      "Epoch: 92/500 \tTraining Loss: 0.025760\n",
      "Epoch: 93/500 \tTraining Loss: 0.028290\n",
      "Epoch: 94/500 \tTraining Loss: 0.023962\n",
      "Epoch: 95/500 \tTraining Loss: 0.020205\n",
      "Epoch: 96/500 \tTraining Loss: 0.022151\n",
      "Epoch: 97/500 \tTraining Loss: 0.022495\n",
      "Epoch: 98/500 \tTraining Loss: 0.018975\n",
      "Epoch: 99/500 \tTraining Loss: 0.017935\n",
      "Epoch: 100/500 \tTraining Loss: 0.016036\n",
      "Epoch: 101/500 \tTraining Loss: 0.016468\n",
      "Epoch: 102/500 \tTraining Loss: 0.017023\n",
      "Epoch: 103/500 \tTraining Loss: 0.018035\n",
      "Epoch: 104/500 \tTraining Loss: 0.016664\n",
      "Epoch: 105/500 \tTraining Loss: 0.017151\n",
      "Epoch: 106/500 \tTraining Loss: 0.019458\n",
      "Epoch: 107/500 \tTraining Loss: 0.019606\n",
      "Epoch: 108/500 \tTraining Loss: 0.019777\n",
      "Epoch: 109/500 \tTraining Loss: 0.020707\n",
      "Epoch: 110/500 \tTraining Loss: 0.019859\n",
      "Epoch: 111/500 \tTraining Loss: 0.017487\n",
      "Epoch: 112/500 \tTraining Loss: 0.018575\n",
      "Epoch: 113/500 \tTraining Loss: 0.019311\n",
      "Epoch: 114/500 \tTraining Loss: 0.017380\n",
      "Epoch: 115/500 \tTraining Loss: 0.016459\n",
      "Epoch: 116/500 \tTraining Loss: 0.015896\n",
      "Epoch: 117/500 \tTraining Loss: 0.017070\n",
      "Epoch: 118/500 \tTraining Loss: 0.018719\n",
      "Epoch: 119/500 \tTraining Loss: 0.018543\n",
      "Epoch: 120/500 \tTraining Loss: 0.019648\n",
      "Epoch: 121/500 \tTraining Loss: 0.016826\n",
      "Epoch: 122/500 \tTraining Loss: 0.016119\n",
      "Epoch: 123/500 \tTraining Loss: 0.015720\n",
      "Epoch: 124/500 \tTraining Loss: 0.016963\n",
      "Epoch: 125/500 \tTraining Loss: 0.017557\n",
      "Epoch: 126/500 \tTraining Loss: 0.017176\n",
      "Epoch: 127/500 \tTraining Loss: 0.016299\n",
      "Epoch: 128/500 \tTraining Loss: 0.015709\n",
      "Epoch: 129/500 \tTraining Loss: 0.016994\n",
      "Epoch: 130/500 \tTraining Loss: 0.016092\n",
      "Epoch: 131/500 \tTraining Loss: 0.015463\n",
      "Epoch: 132/500 \tTraining Loss: 0.018206\n",
      "Epoch: 133/500 \tTraining Loss: 0.016386\n",
      "Epoch: 134/500 \tTraining Loss: 0.016873\n",
      "Epoch: 135/500 \tTraining Loss: 0.019522\n",
      "Epoch: 136/500 \tTraining Loss: 0.017866\n",
      "Epoch: 137/500 \tTraining Loss: 0.017872\n",
      "Epoch: 138/500 \tTraining Loss: 0.019014\n",
      "Epoch: 139/500 \tTraining Loss: 0.024586\n",
      "Epoch: 140/500 \tTraining Loss: 0.028643\n",
      "Epoch: 141/500 \tTraining Loss: 0.020933\n",
      "Epoch: 142/500 \tTraining Loss: 0.017746\n",
      "Epoch: 143/500 \tTraining Loss: 0.017801\n",
      "Epoch: 144/500 \tTraining Loss: 0.016947\n",
      "Epoch: 145/500 \tTraining Loss: 0.015827\n",
      "Epoch: 146/500 \tTraining Loss: 0.017181\n",
      "Epoch: 147/500 \tTraining Loss: 0.016626\n",
      "Epoch: 148/500 \tTraining Loss: 0.016441\n",
      "Epoch: 149/500 \tTraining Loss: 0.021592\n",
      "Epoch: 150/500 \tTraining Loss: 0.019824\n",
      "Epoch: 151/500 \tTraining Loss: 0.022962\n",
      "Epoch: 152/500 \tTraining Loss: 0.017488\n",
      "Epoch: 153/500 \tTraining Loss: 0.016391\n",
      "Epoch: 154/500 \tTraining Loss: 0.015313\n",
      "Epoch: 155/500 \tTraining Loss: 0.016888\n",
      "Epoch: 156/500 \tTraining Loss: 0.018388\n",
      "Epoch: 157/500 \tTraining Loss: 0.017115\n",
      "Epoch: 158/500 \tTraining Loss: 0.016430\n",
      "Epoch: 159/500 \tTraining Loss: 0.016150\n",
      "Epoch: 160/500 \tTraining Loss: 0.018664\n",
      "Epoch: 161/500 \tTraining Loss: 0.019183\n",
      "Epoch: 162/500 \tTraining Loss: 0.016668\n",
      "Epoch: 163/500 \tTraining Loss: 0.016626\n",
      "Epoch: 164/500 \tTraining Loss: 0.017043\n",
      "Epoch: 165/500 \tTraining Loss: 0.018221\n",
      "Epoch: 166/500 \tTraining Loss: 0.016335\n",
      "Epoch: 167/500 \tTraining Loss: 0.016747\n",
      "Epoch: 168/500 \tTraining Loss: 0.016404\n",
      "Epoch: 169/500 \tTraining Loss: 0.017170\n",
      "Epoch: 170/500 \tTraining Loss: 0.016233\n",
      "Epoch: 171/500 \tTraining Loss: 0.015105\n",
      "Epoch: 172/500 \tTraining Loss: 0.017626\n",
      "Epoch: 173/500 \tTraining Loss: 0.016851\n",
      "Epoch: 174/500 \tTraining Loss: 0.017805\n",
      "Epoch: 175/500 \tTraining Loss: 0.017496\n",
      "Epoch: 176/500 \tTraining Loss: 0.016666\n",
      "Epoch: 177/500 \tTraining Loss: 0.015024\n",
      "Epoch: 178/500 \tTraining Loss: 0.014641\n",
      "Epoch: 179/500 \tTraining Loss: 0.015633\n",
      "Epoch: 180/500 \tTraining Loss: 0.016871\n",
      "Epoch: 181/500 \tTraining Loss: 0.017378\n",
      "Epoch: 182/500 \tTraining Loss: 0.024754\n",
      "Epoch: 183/500 \tTraining Loss: 0.022659\n",
      "Epoch: 184/500 \tTraining Loss: 0.019087\n",
      "Epoch: 185/500 \tTraining Loss: 0.017709\n",
      "Epoch: 186/500 \tTraining Loss: 0.017820\n",
      "Epoch: 187/500 \tTraining Loss: 0.018374\n",
      "Epoch: 188/500 \tTraining Loss: 0.019780\n",
      "Epoch: 189/500 \tTraining Loss: 0.018509\n",
      "Epoch: 190/500 \tTraining Loss: 0.017969\n",
      "Epoch: 191/500 \tTraining Loss: 0.018843\n",
      "Epoch: 192/500 \tTraining Loss: 0.016654\n",
      "Epoch: 193/500 \tTraining Loss: 0.016663\n",
      "Epoch: 194/500 \tTraining Loss: 0.017429\n",
      "Epoch: 195/500 \tTraining Loss: 0.015383\n",
      "Epoch: 196/500 \tTraining Loss: 0.014519\n",
      "Epoch: 197/500 \tTraining Loss: 0.014462\n",
      "Epoch: 198/500 \tTraining Loss: 0.015474\n",
      "Epoch: 199/500 \tTraining Loss: 0.019416\n",
      "Epoch: 200/500 \tTraining Loss: 0.018546\n",
      "Epoch: 201/500 \tTraining Loss: 0.015364\n",
      "Epoch: 202/500 \tTraining Loss: 0.014649\n",
      "Epoch: 203/500 \tTraining Loss: 0.014408\n",
      "Epoch: 204/500 \tTraining Loss: 0.013921\n",
      "Epoch: 205/500 \tTraining Loss: 0.013101\n",
      "Epoch: 206/500 \tTraining Loss: 0.013931\n",
      "Epoch: 207/500 \tTraining Loss: 0.018379\n",
      "Epoch: 208/500 \tTraining Loss: 0.021949\n",
      "Epoch: 209/500 \tTraining Loss: 0.024164\n",
      "Epoch: 210/500 \tTraining Loss: 0.024365\n",
      "Epoch: 211/500 \tTraining Loss: 0.027827\n",
      "Epoch: 212/500 \tTraining Loss: 0.020122\n",
      "Epoch: 213/500 \tTraining Loss: 0.020463\n",
      "Epoch: 214/500 \tTraining Loss: 0.018788\n",
      "Epoch: 215/500 \tTraining Loss: 0.018394\n",
      "Epoch: 216/500 \tTraining Loss: 0.019236\n",
      "Epoch: 217/500 \tTraining Loss: 0.019400\n",
      "Epoch: 218/500 \tTraining Loss: 0.017744\n",
      "Epoch: 219/500 \tTraining Loss: 0.017794\n",
      "Epoch: 220/500 \tTraining Loss: 0.016185\n",
      "Epoch: 221/500 \tTraining Loss: 0.015116\n",
      "Epoch: 222/500 \tTraining Loss: 0.015150\n",
      "Epoch: 223/500 \tTraining Loss: 0.015567\n",
      "Epoch: 224/500 \tTraining Loss: 0.016656\n",
      "Epoch: 225/500 \tTraining Loss: 0.017749\n",
      "Epoch: 226/500 \tTraining Loss: 0.017913\n",
      "Epoch: 227/500 \tTraining Loss: 0.016186\n",
      "Epoch: 228/500 \tTraining Loss: 0.015722\n",
      "Epoch: 229/500 \tTraining Loss: 0.015097\n",
      "Epoch: 230/500 \tTraining Loss: 0.016882\n",
      "Epoch: 231/500 \tTraining Loss: 0.014926\n",
      "Epoch: 232/500 \tTraining Loss: 0.014718\n",
      "Epoch: 233/500 \tTraining Loss: 0.013743\n",
      "Epoch: 234/500 \tTraining Loss: 0.015024\n",
      "Epoch: 235/500 \tTraining Loss: 0.014851\n",
      "Epoch: 236/500 \tTraining Loss: 0.013751\n",
      "Epoch: 237/500 \tTraining Loss: 0.016752\n",
      "Epoch: 238/500 \tTraining Loss: 0.014978\n",
      "Epoch: 239/500 \tTraining Loss: 0.014632\n",
      "Epoch: 240/500 \tTraining Loss: 0.015429\n",
      "Epoch: 241/500 \tTraining Loss: 0.013958\n",
      "Epoch: 242/500 \tTraining Loss: 0.014693\n",
      "Epoch: 243/500 \tTraining Loss: 0.016141\n",
      "Epoch: 244/500 \tTraining Loss: 0.016912\n",
      "Epoch: 245/500 \tTraining Loss: 0.016622\n",
      "Epoch: 246/500 \tTraining Loss: 0.016939\n",
      "Epoch: 247/500 \tTraining Loss: 0.013858\n",
      "Epoch: 248/500 \tTraining Loss: 0.014405\n",
      "Epoch: 249/500 \tTraining Loss: 0.015796\n",
      "Epoch: 250/500 \tTraining Loss: 0.015891\n",
      "Epoch: 251/500 \tTraining Loss: 0.014752\n",
      "Epoch: 252/500 \tTraining Loss: 0.018715\n",
      "Epoch: 253/500 \tTraining Loss: 0.020090\n",
      "Epoch: 254/500 \tTraining Loss: 0.018301\n",
      "Epoch: 255/500 \tTraining Loss: 0.016147\n",
      "Epoch: 256/500 \tTraining Loss: 0.016691\n",
      "Epoch: 257/500 \tTraining Loss: 0.014880\n",
      "Epoch: 258/500 \tTraining Loss: 0.016700\n",
      "Epoch: 259/500 \tTraining Loss: 0.015303\n",
      "Epoch: 260/500 \tTraining Loss: 0.017110\n",
      "Epoch: 261/500 \tTraining Loss: 0.016373\n",
      "Epoch: 262/500 \tTraining Loss: 0.014555\n",
      "Epoch: 263/500 \tTraining Loss: 0.014759\n",
      "Epoch: 264/500 \tTraining Loss: 0.017341\n",
      "Epoch: 265/500 \tTraining Loss: 0.015330\n",
      "Epoch: 266/500 \tTraining Loss: 0.013818\n",
      "Epoch: 267/500 \tTraining Loss: 0.014673\n",
      "Epoch: 268/500 \tTraining Loss: 0.014077\n",
      "Epoch: 269/500 \tTraining Loss: 0.013254\n",
      "Epoch: 270/500 \tTraining Loss: 0.013926\n",
      "Epoch: 271/500 \tTraining Loss: 0.013533\n",
      "Epoch: 272/500 \tTraining Loss: 0.016809\n",
      "Epoch: 273/500 \tTraining Loss: 0.017318\n",
      "Epoch: 274/500 \tTraining Loss: 0.018707\n",
      "Epoch: 275/500 \tTraining Loss: 0.017048\n",
      "Epoch: 276/500 \tTraining Loss: 0.022715\n",
      "Epoch: 277/500 \tTraining Loss: 0.017436\n",
      "Epoch: 278/500 \tTraining Loss: 0.020616\n",
      "Epoch: 279/500 \tTraining Loss: 0.019597\n",
      "Epoch: 280/500 \tTraining Loss: 0.018574\n",
      "Epoch: 281/500 \tTraining Loss: 0.015195\n",
      "Epoch: 282/500 \tTraining Loss: 0.015073\n",
      "Epoch: 283/500 \tTraining Loss: 0.013348\n",
      "Epoch: 284/500 \tTraining Loss: 0.013418\n",
      "Epoch: 285/500 \tTraining Loss: 0.014474\n",
      "Epoch: 286/500 \tTraining Loss: 0.014188\n",
      "Epoch: 287/500 \tTraining Loss: 0.016192\n",
      "Epoch: 288/500 \tTraining Loss: 0.013940\n",
      "Epoch: 289/500 \tTraining Loss: 0.014779\n",
      "Epoch: 290/500 \tTraining Loss: 0.015786\n",
      "Epoch: 291/500 \tTraining Loss: 0.015235\n",
      "Epoch: 292/500 \tTraining Loss: 0.016569\n",
      "Epoch: 293/500 \tTraining Loss: 0.021104\n",
      "Epoch: 294/500 \tTraining Loss: 0.017674\n",
      "Epoch: 295/500 \tTraining Loss: 0.014760\n",
      "Epoch: 296/500 \tTraining Loss: 0.015266\n",
      "Epoch: 297/500 \tTraining Loss: 0.016603\n",
      "Epoch: 298/500 \tTraining Loss: 0.014050\n",
      "Epoch: 299/500 \tTraining Loss: 0.012875\n",
      "Epoch: 300/500 \tTraining Loss: 0.013948\n",
      "Epoch: 301/500 \tTraining Loss: 0.014531\n",
      "Epoch: 302/500 \tTraining Loss: 0.015736\n",
      "Epoch: 303/500 \tTraining Loss: 0.014640\n",
      "Epoch: 304/500 \tTraining Loss: 0.017121\n",
      "Epoch: 305/500 \tTraining Loss: 0.016940\n",
      "Epoch: 306/500 \tTraining Loss: 0.013572\n",
      "Epoch: 307/500 \tTraining Loss: 0.014238\n",
      "Epoch: 308/500 \tTraining Loss: 0.014025\n",
      "Epoch: 309/500 \tTraining Loss: 0.012950\n",
      "Epoch: 310/500 \tTraining Loss: 0.013768\n",
      "Epoch: 311/500 \tTraining Loss: 0.013939\n",
      "Epoch: 312/500 \tTraining Loss: 0.014029\n",
      "Epoch: 313/500 \tTraining Loss: 0.013454\n",
      "Epoch: 314/500 \tTraining Loss: 0.012540\n",
      "Epoch: 315/500 \tTraining Loss: 0.015537\n",
      "Epoch: 316/500 \tTraining Loss: 0.015653\n",
      "Epoch: 317/500 \tTraining Loss: 0.015024\n",
      "Epoch: 318/500 \tTraining Loss: 0.015090\n",
      "Epoch: 319/500 \tTraining Loss: 0.015706\n",
      "Epoch: 320/500 \tTraining Loss: 0.014493\n",
      "Epoch: 321/500 \tTraining Loss: 0.013663\n",
      "Epoch: 322/500 \tTraining Loss: 0.017161\n",
      "Epoch: 323/500 \tTraining Loss: 0.019058\n",
      "Epoch: 324/500 \tTraining Loss: 0.016404\n",
      "Epoch: 325/500 \tTraining Loss: 0.016743\n",
      "Epoch: 326/500 \tTraining Loss: 0.015329\n",
      "Epoch: 327/500 \tTraining Loss: 0.014262\n",
      "Epoch: 328/500 \tTraining Loss: 0.013544\n",
      "Epoch: 329/500 \tTraining Loss: 0.014152\n",
      "Epoch: 330/500 \tTraining Loss: 0.015416\n",
      "Epoch: 331/500 \tTraining Loss: 0.015724\n",
      "Epoch: 332/500 \tTraining Loss: 0.017532\n",
      "Epoch: 333/500 \tTraining Loss: 0.017026\n",
      "Epoch: 334/500 \tTraining Loss: 0.016590\n",
      "Epoch: 335/500 \tTraining Loss: 0.013430\n",
      "Epoch: 336/500 \tTraining Loss: 0.014230\n",
      "Epoch: 337/500 \tTraining Loss: 0.014067\n",
      "Epoch: 338/500 \tTraining Loss: 0.014952\n",
      "Epoch: 339/500 \tTraining Loss: 0.015461\n",
      "Epoch: 340/500 \tTraining Loss: 0.014652\n",
      "Epoch: 341/500 \tTraining Loss: 0.014492\n",
      "Epoch: 342/500 \tTraining Loss: 0.017260\n",
      "Epoch: 343/500 \tTraining Loss: 0.017062\n",
      "Epoch: 344/500 \tTraining Loss: 0.015974\n",
      "Epoch: 345/500 \tTraining Loss: 0.019766\n",
      "Epoch: 346/500 \tTraining Loss: 0.018458\n",
      "Epoch: 347/500 \tTraining Loss: 0.018260\n",
      "Epoch: 348/500 \tTraining Loss: 0.017886\n",
      "Epoch: 349/500 \tTraining Loss: 0.017479\n",
      "Epoch: 350/500 \tTraining Loss: 0.017698\n",
      "Epoch: 351/500 \tTraining Loss: 0.019191\n",
      "Epoch: 352/500 \tTraining Loss: 0.018498\n",
      "Epoch: 353/500 \tTraining Loss: 0.016669\n",
      "Epoch: 354/500 \tTraining Loss: 0.014178\n",
      "Epoch: 355/500 \tTraining Loss: 0.015052\n",
      "Epoch: 356/500 \tTraining Loss: 0.015536\n",
      "Epoch: 357/500 \tTraining Loss: 0.015556\n",
      "Epoch: 358/500 \tTraining Loss: 0.016129\n",
      "Epoch: 359/500 \tTraining Loss: 0.014631\n",
      "Epoch: 360/500 \tTraining Loss: 0.014195\n",
      "Epoch: 361/500 \tTraining Loss: 0.014532\n",
      "Epoch: 362/500 \tTraining Loss: 0.015929\n",
      "Epoch: 363/500 \tTraining Loss: 0.013896\n",
      "Epoch: 364/500 \tTraining Loss: 0.013407\n",
      "Epoch: 365/500 \tTraining Loss: 0.013162\n",
      "Epoch: 366/500 \tTraining Loss: 0.015481\n",
      "Epoch: 367/500 \tTraining Loss: 0.015238\n",
      "Epoch: 368/500 \tTraining Loss: 0.014995\n",
      "Epoch: 369/500 \tTraining Loss: 0.014655\n",
      "Epoch: 370/500 \tTraining Loss: 0.012658\n",
      "Epoch: 371/500 \tTraining Loss: 0.014008\n",
      "Epoch: 372/500 \tTraining Loss: 0.015406\n",
      "Epoch: 373/500 \tTraining Loss: 0.014638\n",
      "Epoch: 374/500 \tTraining Loss: 0.017530\n",
      "Epoch: 375/500 \tTraining Loss: 0.019764\n",
      "Epoch: 376/500 \tTraining Loss: 0.016911\n",
      "Epoch: 377/500 \tTraining Loss: 0.018576\n",
      "Epoch: 378/500 \tTraining Loss: 0.017649\n",
      "Epoch: 379/500 \tTraining Loss: 0.015309\n",
      "Epoch: 380/500 \tTraining Loss: 0.014802\n",
      "Epoch: 381/500 \tTraining Loss: 0.014245\n",
      "Epoch: 382/500 \tTraining Loss: 0.013993\n",
      "Epoch: 383/500 \tTraining Loss: 0.015103\n",
      "Epoch: 384/500 \tTraining Loss: 0.015726\n",
      "Epoch: 385/500 \tTraining Loss: 0.015101\n",
      "Epoch: 386/500 \tTraining Loss: 0.015609\n",
      "Epoch: 387/500 \tTraining Loss: 0.014867\n",
      "Epoch: 388/500 \tTraining Loss: 0.012978\n",
      "Epoch: 389/500 \tTraining Loss: 0.015676\n",
      "Epoch: 390/500 \tTraining Loss: 0.015861\n",
      "Epoch: 391/500 \tTraining Loss: 0.015395\n",
      "Epoch: 392/500 \tTraining Loss: 0.014106\n",
      "Epoch: 393/500 \tTraining Loss: 0.013166\n",
      "Epoch: 394/500 \tTraining Loss: 0.012497\n",
      "Epoch: 395/500 \tTraining Loss: 0.013042\n",
      "Epoch: 396/500 \tTraining Loss: 0.012463\n",
      "Epoch: 397/500 \tTraining Loss: 0.012873\n",
      "Epoch: 398/500 \tTraining Loss: 0.014666\n",
      "Epoch: 399/500 \tTraining Loss: 0.015521\n",
      "Epoch: 400/500 \tTraining Loss: 0.015332\n",
      "Epoch: 401/500 \tTraining Loss: 0.015524\n",
      "Epoch: 402/500 \tTraining Loss: 0.014685\n",
      "Epoch: 403/500 \tTraining Loss: 0.015918\n",
      "Epoch: 404/500 \tTraining Loss: 0.016214\n",
      "Epoch: 405/500 \tTraining Loss: 0.017758\n",
      "Epoch: 406/500 \tTraining Loss: 0.015256\n",
      "Epoch: 407/500 \tTraining Loss: 0.016234\n",
      "Epoch: 408/500 \tTraining Loss: 0.017203\n",
      "Epoch: 409/500 \tTraining Loss: 0.017860\n",
      "Epoch: 410/500 \tTraining Loss: 0.015170\n",
      "Epoch: 411/500 \tTraining Loss: 0.014790\n",
      "Epoch: 412/500 \tTraining Loss: 0.013123\n",
      "Epoch: 413/500 \tTraining Loss: 0.015086\n",
      "Epoch: 414/500 \tTraining Loss: 0.016079\n",
      "Epoch: 415/500 \tTraining Loss: 0.014548\n",
      "Epoch: 416/500 \tTraining Loss: 0.016433\n",
      "Epoch: 417/500 \tTraining Loss: 0.014540\n",
      "Epoch: 418/500 \tTraining Loss: 0.013237\n",
      "Epoch: 419/500 \tTraining Loss: 0.011728\n",
      "Epoch: 420/500 \tTraining Loss: 0.012329\n",
      "Epoch: 421/500 \tTraining Loss: 0.012564\n",
      "Epoch: 422/500 \tTraining Loss: 0.013152\n",
      "Epoch: 423/500 \tTraining Loss: 0.013853\n",
      "Epoch: 424/500 \tTraining Loss: 0.014324\n",
      "Epoch: 425/500 \tTraining Loss: 0.014777\n",
      "Epoch: 426/500 \tTraining Loss: 0.015159\n",
      "Epoch: 427/500 \tTraining Loss: 0.015931\n",
      "Epoch: 428/500 \tTraining Loss: 0.016114\n",
      "Epoch: 429/500 \tTraining Loss: 0.019057\n",
      "Epoch: 430/500 \tTraining Loss: 0.018432\n",
      "Epoch: 431/500 \tTraining Loss: 0.017133\n",
      "Epoch: 432/500 \tTraining Loss: 0.017176\n",
      "Epoch: 433/500 \tTraining Loss: 0.014682\n",
      "Epoch: 434/500 \tTraining Loss: 0.014341\n",
      "Epoch: 435/500 \tTraining Loss: 0.015104\n",
      "Epoch: 436/500 \tTraining Loss: 0.014348\n",
      "Epoch: 437/500 \tTraining Loss: 0.015739\n",
      "Epoch: 438/500 \tTraining Loss: 0.015486\n",
      "Epoch: 439/500 \tTraining Loss: 0.014437\n",
      "Epoch: 440/500 \tTraining Loss: 0.014771\n",
      "Epoch: 441/500 \tTraining Loss: 0.015075\n",
      "Epoch: 442/500 \tTraining Loss: 0.014566\n",
      "Epoch: 443/500 \tTraining Loss: 0.013970\n",
      "Epoch: 444/500 \tTraining Loss: 0.014844\n",
      "Epoch: 445/500 \tTraining Loss: 0.017878\n",
      "Epoch: 446/500 \tTraining Loss: 0.017200\n",
      "Epoch: 447/500 \tTraining Loss: 0.016653\n",
      "Epoch: 448/500 \tTraining Loss: 0.016323\n",
      "Epoch: 449/500 \tTraining Loss: 0.015150\n",
      "Epoch: 450/500 \tTraining Loss: 0.014352\n",
      "Epoch: 451/500 \tTraining Loss: 0.014761\n",
      "Epoch: 452/500 \tTraining Loss: 0.013864\n",
      "Epoch: 453/500 \tTraining Loss: 0.013331\n",
      "Epoch: 454/500 \tTraining Loss: 0.012696\n",
      "Epoch: 455/500 \tTraining Loss: 0.013994\n",
      "Epoch: 456/500 \tTraining Loss: 0.013504\n",
      "Epoch: 457/500 \tTraining Loss: 0.015238\n",
      "Epoch: 458/500 \tTraining Loss: 0.013895\n",
      "Epoch: 459/500 \tTraining Loss: 0.014022\n",
      "Epoch: 460/500 \tTraining Loss: 0.014200\n",
      "Epoch: 461/500 \tTraining Loss: 0.016484\n",
      "Epoch: 462/500 \tTraining Loss: 0.015571\n",
      "Epoch: 463/500 \tTraining Loss: 0.016318\n",
      "Epoch: 464/500 \tTraining Loss: 0.017620\n",
      "Epoch: 465/500 \tTraining Loss: 0.017172\n",
      "Epoch: 466/500 \tTraining Loss: 0.016109\n",
      "Epoch: 467/500 \tTraining Loss: 0.025584\n",
      "Epoch: 468/500 \tTraining Loss: 0.026800\n",
      "Epoch: 469/500 \tTraining Loss: 0.019317\n",
      "Epoch: 470/500 \tTraining Loss: 0.022228\n",
      "Epoch: 471/500 \tTraining Loss: 0.019755\n",
      "Epoch: 472/500 \tTraining Loss: 0.016893\n",
      "Epoch: 473/500 \tTraining Loss: 0.016752\n",
      "Epoch: 474/500 \tTraining Loss: 0.015001\n",
      "Epoch: 475/500 \tTraining Loss: 0.016509\n",
      "Epoch: 476/500 \tTraining Loss: 0.018534\n",
      "Epoch: 477/500 \tTraining Loss: 0.017052\n",
      "Epoch: 478/500 \tTraining Loss: 0.015977\n",
      "Epoch: 479/500 \tTraining Loss: 0.015055\n",
      "Epoch: 480/500 \tTraining Loss: 0.013811\n",
      "Epoch: 481/500 \tTraining Loss: 0.014214\n",
      "Epoch: 482/500 \tTraining Loss: 0.013800\n",
      "Epoch: 483/500 \tTraining Loss: 0.015281\n",
      "Epoch: 484/500 \tTraining Loss: 0.014710\n",
      "Epoch: 485/500 \tTraining Loss: 0.014730\n",
      "Epoch: 486/500 \tTraining Loss: 0.015532\n",
      "Epoch: 487/500 \tTraining Loss: 0.020618\n",
      "Epoch: 488/500 \tTraining Loss: 0.020123\n",
      "Epoch: 489/500 \tTraining Loss: 0.016308\n",
      "Epoch: 490/500 \tTraining Loss: 0.014540\n",
      "Epoch: 491/500 \tTraining Loss: 0.015307\n",
      "Epoch: 492/500 \tTraining Loss: 0.017278\n",
      "Epoch: 493/500 \tTraining Loss: 0.014058\n",
      "Epoch: 494/500 \tTraining Loss: 0.016090\n",
      "Epoch: 495/500 \tTraining Loss: 0.015663\n",
      "Epoch: 496/500 \tTraining Loss: 0.015290\n",
      "Epoch: 497/500 \tTraining Loss: 0.015692\n",
      "Epoch: 498/500 \tTraining Loss: 0.015369\n",
      "Epoch: 499/500 \tTraining Loss: 0.014575\n",
      "Epoch: 500/500 \tTraining Loss: 0.016308\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 500 \n",
    "\n",
    "model.to(device)    # bring the model to gpu\n",
    "model.train()       # prep model for training\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #bring data and target to gpu\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print('Epoch: {}/{} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1,\n",
    "        n_epochs, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "\n",
    "# Save the model  -- I already saved this and submitted\n",
    "torch.save(model.state_dict(), 'PyTorch_Model/Multiclass_NN_mish_Drop_L2_Huber_500Epochs.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the saved state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.7392809  -1.9917363  -1.8193882  ...  0.35119608 -0.39305842\n",
      "  -0.21628276]\n",
      " [-1.5200003  -1.7321391  -1.5883858  ...  0.25510928 -0.32279378\n",
      "  -0.2683021 ]\n",
      " [-1.3420023  -1.5194428  -1.4016576  ...  0.15427521 -0.24441741\n",
      "  -0.32641724]\n",
      " ...\n",
      " [ 1.2999079   1.1495788   1.3066216  ... -0.6442714   0.710945\n",
      "  -0.6070192 ]\n",
      " [ 1.4580866   1.2939442   1.468566   ... -0.69298196  0.7492833\n",
      "  -0.63979334]\n",
      " [ 1.6404264   1.4652623   1.6569393  ... -0.74391663  0.78656\n",
      "  -0.6731756 ]]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('PyTorch_Model/Multiclass_NN_mish_Drop_L2_Huber_500Epochs.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval()           # prep model for *evaluation*\n",
    "model.to(device)\n",
    "with torch.no_grad():  # turn off gradient to save memory\n",
    "    y_predNN_torch = model(X_test_torch.to(device))\n",
    "\n",
    "y_predNN_normal = y_predNN_torch.cpu().numpy()     # convert to numpy array\n",
    "y_test_normal = y_test_torch.cpu().numpy()\n",
    "print(y_predNN_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network scores in normal distribution: r2 = 0.9603648674823635, mape = 0.9123709797859192\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test_normal, y_predNN_normal)\n",
    "r2 = r2_score(y_test_normal, y_predNN_normal)\n",
    "print(f\"Neural Network scores in normal distribution: r2 = {r2}, mape = {mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network scores in actual distribution: r2 = 0.9592284583532196, mape = 0.08364320607261552\n"
     ]
    }
   ],
   "source": [
    "y_predNN = quantile.inverse_transform(y_predNN_normal)\n",
    "mape = mean_absolute_percentage_error(y_test, y_predNN.astype('float64'))\n",
    "r2 = r2_score(y_test, y_predNN)\n",
    "\n",
    "print(f\"Neural Network scores in actual distribution: r2 = {r2}, mape = {mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.990974, 37.694412, 35.120922, 32.259705, 29.518648, 27.633831,\n",
       "       26.295216, 25.328756, 24.663584, 24.181011, 23.81377 , 23.411663,\n",
       "       23.016758, 22.492844, 21.927814, 21.298244, 20.605316, 19.832489,\n",
       "       19.048626, 18.303392, 17.591423, 16.89375 , 16.218763, 15.531129,\n",
       "       14.848038, 14.200279, 13.674687, 13.206299, 12.831106, 12.541457,\n",
       "       12.272652, 12.02084 , 11.772506, 11.490342, 11.118927, 82.8921  ,\n",
       "       76.16895 , 68.8919  , 61.497734, 55.746334], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.055485, 41.13142 , 37.34763 , 34.215847, 31.660479, 29.51226 ,\n",
       "       27.62623 , 25.996059, 24.593987, 23.341728, 22.203737, 21.178555,\n",
       "       20.26375 , 19.439846, 18.682037, 17.977852, 17.324688, 16.722097,\n",
       "       16.167007, 15.652895, 15.172283, 14.719731, 14.292322, 13.888784,\n",
       "       13.508397, 13.149973, 12.811902, 12.492044, 12.188312, 11.898917,\n",
       "       11.622511, 11.358176, 11.105268, 10.863276, 10.631696, 83.744408,\n",
       "       73.62957 , 65.149193, 58.173275, 52.403481])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:41,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.21143940e-02,  2.36260840e-02,  9.64583550e-03, ...,\n",
       "         2.50615600e-01, -1.13256240e-01,  5.26190380e+01],\n",
       "       [ 1.47982630e-02,  2.66367886e-02,  1.20925640e-02, ...,\n",
       "         2.00786950e-01, -1.03320270e-01,  4.60554850e+01],\n",
       "       [ 1.75325390e-02,  2.95875370e-02,  1.46107920e-02, ...,\n",
       "         1.66701170e-01, -9.43374630e-02,  4.11314200e+01],\n",
       "       ...,\n",
       "       [ 9.74210350e-02,  1.11182812e-01,  9.28768070e-02, ...,\n",
       "         9.06703620e-02, -5.40905860e-02,  3.56521530e+01],\n",
       "       [ 1.00227500e-01,  1.14051970e-01,  9.56180690e-02, ...,\n",
       "         8.74992310e-02, -5.23571000e-02,  3.46799510e+01],\n",
       "       [ 1.03034510e-01,  1.16930324e-01,  9.83653590e-02, ...,\n",
       "         8.45144470e-02, -5.04742410e-02,  3.37590220e+01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Pressure\n",
      "[0.18686691 0.16998251 0.15439068 ... 0.07497399 0.07170546 0.06859732]\n",
      "\n",
      "Negative Pressure\n",
      "[-0.11643808 -0.10752033 -0.09846211 -0.09056465 -0.08386255 -0.0777927\n",
      " -0.072277   -0.06794819 -0.06416631 -0.06058231]\n",
      "\n",
      "Positive Impulse\n",
      "[42.247078 39.990974 37.694412 35.120922 32.259705 29.518648 27.633831\n",
      " 26.295216 25.328756 24.663584]\n"
     ]
    }
   ],
   "source": [
    "# Positive Impulse\n",
    "print(\"Positive Pressure\")\n",
    "print(y_predNN[:,5])\n",
    "print()\n",
    "\n",
    "# Negative Pressure\n",
    "print(\"Negative Pressure\")\n",
    "print(y_predNN[1010:1020,6])\n",
    "print()\n",
    "\n",
    "\n",
    "# Positive Impulse\n",
    "print(\"Positive Impulse\")\n",
    "print(y_predNN[:10,7])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Peak Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.9954032549784757, mape = 0.0315407670771008, rmse = 0.0019472120292065415\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,0], y_predNN[:,0])\n",
    "r2 = r2_score(y_test[:,0], y_predNN[:,0])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,0], y_predNN[:,0]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Peak Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.9919365824456913, mape = 0.03680670409013907, rmse = 0.0026807592096860654\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,1], y_predNN[:,1])\n",
    "r2 = r2_score(y_test[:,1], y_predNN[:,1])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,1], y_predNN[:,1]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrival Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.9957003351149657, mape = 0.034762934390513714, rmse = 0.0018177980686660516\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,2], y_predNN[:,2])\n",
    "r2 = r2_score(y_test[:,2], y_predNN[:,2])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,2], y_predNN[:,2]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.9178151331381783, mape = 0.055868739725255696, rmse = 0.008326877258484851\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,3], y_predNN[:,3])\n",
    "r2 = r2_score(y_test[:,3], y_predNN[:,3])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,4], y_predNN[:,3]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.9154361324122297, mape = 0.08104769187904591, rmse = 0.00183052247246474\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,4], y_predNN[:,4])\n",
    "r2 = r2_score(y_test[:,4], y_predNN[:,4])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,4], y_predNN[:,4]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0070927 , 0.00708828, 0.00709008, 0.0070853 , 0.00707912,\n",
       "       0.00706785, 0.00706412, 0.00704504, 0.00988789, 0.01012937,\n",
       "       0.01037642, 0.01030135, 0.01078974, 0.01087129, 0.0107311 ,\n",
       "       0.01087087, 0.01152926, 0.0117134 , 0.01242085, 0.01263455])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[100:120, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01056505, 0.01052264, 0.01047505, 0.0104239 , 0.01037724,\n",
       "       0.01032534, 0.01029657, 0.01030937, 0.01064512, 0.0106506 ,\n",
       "       0.01075534, 0.01086623, 0.01097928, 0.01111607, 0.01123187,\n",
       "       0.01135368, 0.01146767, 0.01156835, 0.01166335, 0.01175111],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[100:120, 4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.9770077199104891, mape = 0.14746371332386893, rmse = 0.05060704632937593\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,5], y_predNN[:,5])\n",
    "r2 = r2_score(y_test[:,5], y_predNN[:,5])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,5], y_predNN[:,5]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2506156 , 0.20078695, 0.16670117, ..., 0.09067036, 0.08749923,\n",
       "       0.08451445])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18686691, 0.16998251, 0.15439068, ..., 0.07497399, 0.07170546,\n",
       "       0.06859732], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[:,5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.962559627176625, mape = 0.11060200905315168, rmse = 0.015175398734788957\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,6], y_predNN[:,6])\n",
    "r2 = r2_score(y_test[:,6], y_predNN[:,6])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,6], y_predNN[:,6]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13921224, -0.13253026, -0.12156035, -0.10836691, -0.09683013,\n",
       "       -0.09476076, -0.09015154, -0.08397743, -0.07669979, -0.06937373])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1010:1020, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11643808, -0.10752033, -0.09846211, -0.09056465, -0.08386255,\n",
       "       -0.0777927 , -0.072277  , -0.06794819, -0.06416631, -0.06058231],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[1010:1020, 6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Impulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores in actual distribution for arrival time: r2 = 0.9179688816491016, mape = 0.1710530890418475, rmse = 28.91891723519466\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test[:,7], y_predNN[:,7])\n",
    "r2 = r2_score(y_test[:,7], y_predNN[:,7])\n",
    "rmse = np.sqrt(mean_squared_error(y_test[:,7], y_predNN[:,7]))\n",
    "\n",
    "\n",
    "print(f\"Scores in actual distribution for arrival time: r2 = {r2}, mape = {mape}, rmse = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52.619038, 46.055485, 41.13142 , ..., 35.652153, 34.679951,\n",
       "       33.759022])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.247078, 39.990974, 37.694412, ..., 28.461514, 27.560621,\n",
       "       26.731874], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNN[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
